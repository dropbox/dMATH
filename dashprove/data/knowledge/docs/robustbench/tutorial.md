# RobustBench: a standardized adversarial robustness benchmark

**Francesco Croce* (University of TÃ¼bingen), Maksym Andriushchenko* (EPFL), Vikash Sehwag*
(Princeton University), Edoardo Debenedetti* (EPFL), Nicolas Flammarion (EPFL), Mung Chiang (Purdue
University), Prateek Mittal (Princeton University), Matthias Hein (University of TÃ¼bingen)**

**Leaderboard**: [https://robustbench.github.io/][1]

**Paper:** [https://arxiv.org/abs/2010.09670][2]

**â—Noteâ—: if you experience problems with the automatic downloading of the models from Google
Drive, install the latest version of `RobustBench` via `pip install
git+https://github.com/RobustBench/robustbench.git`.**




## News

* **May 2022**: We have extended the common corruptions leaderboard on ImageNet with [3D Common
  Corruptions][3] (ImageNet-3DCC). ImageNet-3DCC evaluation is interesting since (1) it includes
  more realistic corruptions and (2) it can be used to assess generalization of the existing models
  which may have overfitted to ImageNet-C. For a quickstart, click [here][4]. Note that the entries
  in leaderboard are still sorted according to ImageNet-C performance.
* **May 2022**: We fixed the preprocessing issue for ImageNet corruption evaluations: previously we
  used resize to 256x256 and central crop to 224x224 which wasn't necessary since the ImageNet-C
  images are already 224x224 (see [this issue][5]). Note that this changed the ranking between the
  top-1 and top-2 entries.

## Main idea

The goal of **`RobustBench`** is to systematically track the *real* progress in adversarial
robustness. There are already [more than 3'000 papers][6] on this topic, but it is still often
unclear which approaches really work and which only lead to [overestimated robustness][7]. We start
from benchmarking the Linf, L2, and common corruption robustness since these are the most studied
settings in the literature.

Evaluation of the robustness to Lp perturbations *in general* is not straightforward and requires
adaptive attacks ([Tramer et al., (2020)][8]). Thus, in order to establish a reliable *standardized*
benchmark, we need to impose some restrictions on the defenses we consider. In particular, **we
accept only defenses that are (1) have in general non-zero gradients wrt the inputs, (2) have a
fully deterministic forward pass (i.e. no randomness) that (3) does not have an optimization loop.**
Often, defenses that violate these 3 principles only make gradient-based attacks harder but do not
substantially improve robustness ([Carlini et al., (2019)][9]) except those that can present
concrete provable guarantees (e.g. [Cohen et al., (2019)][10]).

To prevent potential overadaptation of new defenses to AutoAttack, we also welcome external
evaluations based on **adaptive attacks**, especially where AutoAttack [flags][11] a potential
overestimation of robustness. For each model, we are interested in the best known robust accuracy
and see AutoAttack and adaptive attacks as complementary to each other.

**`RobustBench`** consists of two parts:

* a website [https://robustbench.github.io/][12] with the leaderboard based on many recent papers
  (plots below ðŸ‘‡)
* a collection of the most robust models, **Model Zoo**, which are easy to use for any downstream
  application (see the tutorial below after FAQ ðŸ‘‡)

## FAQ

**Q**: How does the RobustBench leaderboard differ from the [AutoAttack leaderboard][13]? ðŸ¤”
**A**: The [AutoAttack leaderboard][14] was the starting point of RobustBench. Now only the
[RobustBench leaderboard][15] is actively maintained.

**Q**: How does the RobustBench leaderboard differ from [robust-ml.org][16]? ðŸ¤”
**A**: [robust-ml.org][17] focuses on *adaptive* evaluations, but we provide a **standardized
benchmark**. Adaptive evaluations have been very useful (e.g., see [Tramer et al., 2020][18]) but
they are also very time-consuming and not standardized by definition. Instead, we argue that one can
estimate robustness accurately mostly *without* adaptive attacks but for this one has to introduce
some restrictions on the considered models. However, we do welcome adaptive evaluations and we are
always interested in showing the best known robust accuracy.

**Q**: How is it related to libraries like `foolbox` / `cleverhans` / `advertorch`? ðŸ¤”
**A**: These libraries provide implementations of different *attacks*. Besides the standardized
benchmark, **`RobustBench`** additionally provides a repository of the most robust models. So you
can start using the robust models in one line of code (see the tutorial below ðŸ‘‡).

**Q**: Why is Lp-robustness still interesting? ðŸ¤”
**A**: There are numerous interesting applications of Lp-robustness that span transfer learning
([Salman et al. (2020)][19], [Utrera et al. (2020)][20]), interpretability ([Tsipras et al.
(2018)][21], [Kaur et al. (2019)][22], [Engstrom et al. (2019)][23]), security ([TramÃ¨r et al.
(2018)][24], [Saadatpanah et al. (2019)][25]), generalization ([Xie et al. (2019)][26], [Zhu et al.
(2019)][27], [Bochkovskiy et al. (2020)][28]), robustness to unseen perturbations ([Xie et al.
(2019)][29], [Kang et al. (2019)][30]), stabilization of GAN training ([Zhong et al. (2020)][31]).

**Q**: What about verified adversarial robustness? ðŸ¤”
**A**: We mostly focus on defenses which improve empirical robustness, given the lack of clarity
regarding which approaches really improve robustness and which only make some particular attacks
unsuccessful. However, we do not restrict submissions of verifiably robust models (e.g., we have
[Zhang et al. (2019)][32] in our CIFAR-10 Linf leaderboard). For methods targeting verified
robustness, we encourage the readers to check out [Salman et al. (2019)][33] and [Li et al.
(2020)][34].

**Q**: What if I have a better attack than the one used in this benchmark? ðŸ¤”
**A**: We will be happy to add a better attack or any adaptive evaluation that would complement our
default standardized attacks.

## Model Zoo: quick tour

The goal of our **Model Zoo** is to simplify the usage of robust models as much as possible. Check
out our Colab notebook here ðŸ‘‰ [RobustBench: quick start][35] for a quick introduction. It is also
summarized below ðŸ‘‡.

First, install the latest version of **`RobustBench`** (recommended):

pip install git+https://github.com/RobustBench/robustbench.git

or the latest *stable* version of **`RobustBench`** (it is possible that automatic downloading of
the models may not work):

pip install git+https://github.com/RobustBench/robustbench.git@v1.0

Now let's try to load CIFAR-10 and some quite robust CIFAR-10 models from [Carmon2019Unlabeled][36]
that achieves 59.53% robust accuracy evaluated with AA under `eps=8/255`:

from robustbench.data import load_cifar10

x_test, y_test = load_cifar10(n_examples=50)

from robustbench.utils import load_model

model = load_model(model_name='Carmon2019Unlabeled', dataset='cifar10', threat_model='Linf')

Let's try to evaluate the robustness of this model. We can use any favourite library for this. For
example, [FoolBox][37] implements many different attacks. We can start from a simple PGD attack:

!pip install -q foolbox
import foolbox as fb
fmodel = fb.PyTorchModel(model, bounds=(0, 1))

_, advs, success = fb.attacks.LinfPGD()(fmodel, x_test.to('cuda:0'), y_test.to('cuda:0'), epsilons=[
8/255])
print('Robust accuracy: {:.1%}'.format(1 - success.float().mean()))
`>>> Robust accuracy: 58.0%
`

Wonderful! Can we do better with a more accurate attack?

Let's try to evaluate its robustness with a cheap version [AutoAttack][38] from ICML 2020 with 2/4
attacks (only APGD-CE and APGD-DLR):

# autoattack is installed as a dependency of robustbench so there is not need to install it separate
ly
from autoattack import AutoAttack
adversary = AutoAttack(model, norm='Linf', eps=8/255, version='custom', attacks_to_run=['apgd-ce', '
apgd-dlr'])
adversary.apgd.n_restarts = 1
x_adv = adversary.run_standard_evaluation(x_test, y_test)
`>>> initial accuracy: 92.00%
>>> apgd-ce - 1/1 - 19 out of 46 successfully perturbed
>>> robust accuracy after APGD-CE: 54.00% (total time 10.3 s)
>>> apgd-dlr - 1/1 - 1 out of 27 successfully perturbed
>>> robust accuracy after APGD-DLR: 52.00% (total time 17.0 s)
>>> max Linf perturbation: 0.03137, nan in tensor: 0, max: 1.00000, min: 0.00000
>>> robust accuracy: 52.00%
`

Note that for our standardized evaluation of Linf-robustness we use the *full* version of AutoAttack
which is slower but more accurate (for that just use `adversary = AutoAttack(model, norm='Linf',
eps=8/255)`).

What about other types of perturbations? Is Lp-robustness useful there? We can evaluate the
available models on more general perturbations. For example, let's take images corrupted by fog
perturbations from CIFAR-10-C with the highest level of severity (5). Are different Linf robust
models perform better on them?

from robustbench.data import load_cifar10c
from robustbench.utils import clean_accuracy

corruptions = ['fog']
x_test, y_test = load_cifar10c(n_examples=1000, corruptions=corruptions, severity=5)

for model_name in ['Standard', 'Engstrom2019Robustness', 'Rice2020Overfitting',
                   'Carmon2019Unlabeled']:
 model = load_model(model_name, dataset='cifar10', threat_model='Linf')
 acc = clean_accuracy(model, x_test, y_test)
 print(f'Model: {model_name}, CIFAR-10-C accuracy: {acc:.1%}')
`>>> Model: Standard, CIFAR-10-C accuracy: 74.4%
>>> Model: Engstrom2019Robustness, CIFAR-10-C accuracy: 38.8%
>>> Model: Rice2020Overfitting, CIFAR-10-C accuracy: 22.0%
>>> Model: Carmon2019Unlabeled, CIFAR-10-C accuracy: 31.1%
`

As we can see, **all** these Linf robust models perform considerably worse than the standard model
on this type of corruptions. This curious phenomenon was first noticed in [Adversarial Examples Are
a Natural Consequence of Test Error in Noise][39] and explained from the frequency perspective in [A
Fourier Perspective on Model Robustness in Computer Vision][40].

However, on average adversarial training *does* help on CIFAR-10-C. One can check this easily by
loading all types of corruptions via `load_cifar10c(n_examples=1000, severity=5)`, and repeating
evaluation on them.

### ***New***: Evaluating robustness of ImageNet models against 3D Common Corruptions
### (ImageNet-3DCC)

3D Common Corruptions (3DCC) is a recent benchmark by [Kar et al. (CVPR 2022)][41] using scene
geometry to generate realistic corruptions. You can evaluate robustness of a standard ResNet-50
against ImageNet-3DCC by following these steps:

1. Download the data from [here][42] using the provided tool. The data will be saved into a folder
   named `ImageNet-3DCC`.
2. Run the sample evaluation script to obtain accuracies and save them in a pickle file:
import torch 
from robustbench.data import load_imagenet3dcc
from robustbench.utils import clean_accuracy, load_model

corruptions_3dcc = ['near_focus', 'far_focus', 'bit_error', 'color_quant', 
                   'flash', 'fog_3d', 'h265_abr', 'h265_crf',
                   'iso_noise', 'low_light', 'xy_motion_blur', 'z_motion_blur'] # 12 corruptions in 
ImageNet-3DCC

device = torch.device("cuda:0")
model = load_model('Standard_R50', dataset='imagenet', threat_model='corruptions').to(device)
for corruption in corruptions_3dcc:
    for s in [1, 2, 3, 4, 5]:  # 5 severity levels
        x_test, y_test = load_imagenet3dcc(n_examples=5000, corruptions=[corruption], severity=s, da
ta_dir=$PATH_IMAGENET_3DCC)
        acc = clean_accuracy(model, x_test.to(device), y_test.to(device), device=device)
        print(f'Model: {model_name}, ImageNet-3DCC corruption: {corruption} severity: {s} accuracy: 
{acc:.1%}')

## Model Zoo

In order to use a model, you just need to know its ID, e.g. **Carmon2019Unlabeled**, and to run:

from robustbench import load_model

model = load_model(model_name='Carmon2019Unlabeled', dataset='cifar10', threat_model='Linf')

which automatically downloads the model (all models are defined in `model_zoo/models.py`).

Reproducing evaluation of models from the Model Zoo can be done directly from the command line. Here
is an example of an evaluation of `Salman2020Do_R18` model with AutoAttack on ImageNet for
`eps=4/255=0.0156862745`:

python -m robustbench.eval --n_ex=5000 --dataset=imagenet --threat_model=Linf --model_name=Salman202
0Do_R18 --data_dir=/tmldata1/andriush/imagenet --batch_size=128 --eps=0.0156862745

The CIFAR-10, CIFAR-10-C, CIFAR-100, and CIFAR-100-C datasets are downloaded automatically. However,
the ImageNet datasets should be downloaded manually due to their licensing:

* ImageNet: Obtain the download link [here][43] (requires just signing up from an academic email,
  the approval system there is automatic and happens instantly) and then follow the instructions
  [here][44] to extract the validation set in a pytorch-compatible format into folder `val`.
* ImageNet-C: Please visit [here][45] for the instructions.
* ImageNet-3DCC: Download the data from [here][46] using the provided tool. The data will be saved
  into a folder named `ImageNet-3DCC`.

In order to use the models from the Model Zoo, you can find all available model IDs in the tables
below. Note that the full [leaderboard][47] contains a bit more models which we either have not yet
added to the Model Zoo or their authors don't want them to appear in the Model Zoo.

### CIFAR-10

#### Linf, eps=8/255

â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â”‚Model ID      â”‚Paper                                     â”‚Cleanâ”‚Robusâ”‚Architecture     â”‚Venue    
  â”‚              â”‚                                          â”‚accurâ”‚t    â”‚                 â”‚         
  â”‚              â”‚                                          â”‚acy  â”‚accurâ”‚                 â”‚         
  â”‚              â”‚                                          â”‚     â”‚acy  â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Bartoldsonâ”‚*[Adversarial Robustness Limits via       â”‚93.68â”‚73.71â”‚WideResNet-94-16 â”‚ICML 2024
1*â”‚2024Adversariaâ”‚Scaling-Law and Human-Alignment           â”‚%    â”‚%    â”‚                 â”‚         
* â”‚l_WRN-94-16**}â”‚Studies][48]*                             â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Amini2024Mâ”‚*[MeanSparse: Post-Training Robustness    â”‚93.60â”‚73.10â”‚MeanSparse       â”‚arXiv,   
2*â”‚eanSparse_S-WRâ”‚Enhancement Through Mean-Centered Feature â”‚%    â”‚%    â”‚WideResNet-94-16 â”‚Jun 2024 
* â”‚N-94-16**}    â”‚Sparsification][49]*                      â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Bartoldsonâ”‚*[Adversarial Robustness Limits via       â”‚93.11â”‚71.59â”‚WideResNet-82-8  â”‚ICML 2024
3*â”‚2024Adversariaâ”‚Scaling-Law and Human-Alignment           â”‚%    â”‚%    â”‚                 â”‚         
* â”‚l_WRN-82-8**} â”‚Studies][50]*                             â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Peng2023Roâ”‚*[Robust Principles: Architectural Design â”‚93.27â”‚71.07â”‚RaWideResNet-70-1â”‚BMVC 2023
4*â”‚bust**}       â”‚Principles for Adversarially Robust       â”‚%    â”‚%    â”‚6                â”‚         
* â”‚              â”‚CNNs][51]*                                â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Wang2023Beâ”‚*[Better Diffusion Models Further Improve â”‚93.25â”‚70.69â”‚WideResNet-70-16 â”‚ICML 2023
5*â”‚tter_WRN-70-16â”‚Adversarial Training][52]*                â”‚%    â”‚%    â”‚                 â”‚         
* â”‚**}           â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Bai2024Mixâ”‚*[MixedNUTS: Training-Free                â”‚95.19â”‚69.71â”‚ResNet-152 +     â”‚TMLR, Aug
6*â”‚edNUTS**}     â”‚Accuracy-Robustness Balance via           â”‚%    â”‚%    â”‚WideResNet-70-16 â”‚2024     
* â”‚              â”‚Nonlinearly Mixed Classifiers][53]*       â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Amini2024Mâ”‚*[MeanSparse: Post-Training Robustness    â”‚93.24â”‚68.94â”‚MeanSparse       â”‚arXiv,   
7*â”‚eanSparse_Ra_Wâ”‚Enhancement Through Mean-Centered Feature â”‚%    â”‚%    â”‚RaWideResNet-70-1â”‚Jun 2024 
* â”‚RN_70_16**}   â”‚Sparsification][54]*                      â”‚     â”‚     â”‚6                â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Bai2023Impâ”‚*[Improving the Accuracy-Robustness       â”‚95.23â”‚68.06â”‚ResNet-152 +     â”‚SIMODS   
8*â”‚roving_edm**} â”‚Trade-off of Classifiers via Adaptive     â”‚%    â”‚%    â”‚WideResNet-70-16 â”‚2024     
* â”‚              â”‚Smoothing][55]*                           â”‚     â”‚     â”‚+ mixing network â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Cui2023Decâ”‚*[Decoupled Kullback-Leibler Divergence   â”‚92.16â”‚67.73â”‚WideResNet-28-10 â”‚NeurIPS  
9*â”‚oupled_WRN-28-â”‚Loss][56]*                                â”‚%    â”‚%    â”‚                 â”‚2024     
* â”‚10**}         â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Wang2023Beâ”‚*[Better Diffusion Models Further Improve â”‚92.44â”‚67.31â”‚WideResNet-28-10 â”‚ICML 2023
10â”‚tter_WRN-28-10â”‚Adversarial Training][57]*                â”‚%    â”‚%    â”‚                 â”‚         
**â”‚**}           â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rebuffi202â”‚*[Fixing Data Augmentation to Improve     â”‚92.23â”‚66.56â”‚WideResNet-70-16 â”‚arXiv,   
11â”‚1Fixing_70_16_â”‚Adversarial Robustness][58]*              â”‚%    â”‚%    â”‚                 â”‚Mar 2021 
**â”‚cutmix_extra**â”‚                                          â”‚     â”‚     â”‚                 â”‚         
  â”‚}             â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Gowal2021Iâ”‚*[Improving Robustness using Generated    â”‚88.74â”‚66.10â”‚WideResNet-70-16 â”‚NeurIPS  
12â”‚mproving_70_16â”‚Data][59]*                                â”‚%    â”‚%    â”‚                 â”‚2021     
**â”‚_ddpm_100m**} â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Gowal2020Uâ”‚*[Uncovering the Limits of Adversarial    â”‚91.10â”‚65.87â”‚WideResNet-70-16 â”‚arXiv,   
13â”‚ncovering_70_1â”‚Training against Norm-Bounded Adversarial â”‚%    â”‚%    â”‚                 â”‚Oct 2020 
**â”‚6_extra**}    â”‚Examples][60]*                            â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Huang2022Râ”‚*[Revisiting Residual Networks for        â”‚91.58â”‚65.79â”‚WideResNet-A4    â”‚arXiv,   
14â”‚evisiting_WRN-â”‚Adversarial Robustness: An Architectural  â”‚%    â”‚%    â”‚                 â”‚Dec. 2022
**â”‚A4**}         â”‚Perspective][61]*                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rebuffi202â”‚*[Fixing Data Augmentation to Improve     â”‚88.50â”‚64.58â”‚WideResNet-106-16â”‚arXiv,   
15â”‚1Fixing_106_16â”‚Adversarial Robustness][62]*              â”‚%    â”‚%    â”‚                 â”‚Mar 2021 
**â”‚_cutmix_ddpm**â”‚                                          â”‚     â”‚     â”‚                 â”‚         
  â”‚}             â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rebuffi202â”‚*[Fixing Data Augmentation to Improve     â”‚88.54â”‚64.20â”‚WideResNet-70-16 â”‚arXiv,   
16â”‚1Fixing_70_16_â”‚Adversarial Robustness][63]*              â”‚%    â”‚%    â”‚                 â”‚Mar 2021 
**â”‚cutmix_ddpm**}â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Kang2021Stâ”‚*[Stable Neural ODE with Lyapunov-Stable  â”‚93.73â”‚64.20â”‚WideResNet-70-16,â”‚NeurIPS  
17â”‚able**}       â”‚Equilibrium Points for Defending Against  â”‚%    â”‚%    â”‚Neural ODE block â”‚2021     
**â”‚              â”‚Adversarial Attacks][64]*                 â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Xu2023Explâ”‚*[Exploring and Exploiting Decision       â”‚93.69â”‚63.89â”‚WideResNet-28-10 â”‚ICLR 2023
18â”‚oring_WRN-28-1â”‚Boundary Dynamics for Adversarial         â”‚%    â”‚%    â”‚                 â”‚         
**â”‚0**}          â”‚Robustness][65]*                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Gowal2021Iâ”‚*[Improving Robustness using Generated    â”‚87.50â”‚63.38â”‚WideResNet-28-10 â”‚NeurIPS  
19â”‚mproving_28_10â”‚Data][66]*                                â”‚%    â”‚%    â”‚                 â”‚2021     
**â”‚_ddpm_100m**} â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Pang2022Roâ”‚*[ Robustness and Accuracy Could Be       â”‚89.01â”‚63.35â”‚WideResNet-70-16 â”‚ICML 2022
20â”‚bustness_WRN70â”‚Reconcilable by (Proper) Definition][67]* â”‚%    â”‚%    â”‚                 â”‚         
**â”‚_16**}        â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rade2021Heâ”‚*[Helper-based Adversarial Training:      â”‚91.47â”‚62.83â”‚WideResNet-34-10 â”‚OpenRevie
21â”‚lper_extra**} â”‚Reducing Excessive Margin to Achieve a    â”‚%    â”‚%    â”‚                 â”‚w, Jun   
**â”‚              â”‚Better Accuracy vs. Robustness            â”‚     â”‚     â”‚                 â”‚2021     
  â”‚              â”‚Trade-off][68]*                           â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Sehwag2021â”‚*[Robust Learning Meets Generative Models:â”‚87.30â”‚62.79â”‚ResNest152       â”‚ICLR 2022
22â”‚Proxy_ResNest1â”‚Can Proxy Distributions Improve           â”‚%    â”‚%    â”‚                 â”‚         
**â”‚52**}         â”‚Adversarial Robustness?][69]*             â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Gowal2020Uâ”‚*[Uncovering the Limits of Adversarial    â”‚89.48â”‚62.76â”‚WideResNet-28-10 â”‚arXiv,   
23â”‚ncovering_28_1â”‚Training against Norm-Bounded Adversarial â”‚%    â”‚%    â”‚                 â”‚Oct 2020 
**â”‚0_extra**}    â”‚Examples][70]*                            â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Huang2021Eâ”‚*[Exploring Architectural Ingredients of  â”‚91.23â”‚62.54â”‚WideResNet-34-R  â”‚NeurIPS  
24â”‚xploring_ema**â”‚Adversarially Robust Deep Neural          â”‚%    â”‚%    â”‚                 â”‚2021     
**â”‚}             â”‚Networks][71]*                            â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Huang2021Eâ”‚*[Exploring Architectural Ingredients of  â”‚90.56â”‚61.56â”‚WideResNet-34-R  â”‚NeurIPS  
25â”‚xploring**}   â”‚Adversarially Robust Deep Neural          â”‚%    â”‚%    â”‚                 â”‚2021     
**â”‚              â”‚Networks][72]*                            â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Dai2021Parâ”‚*[Parameterizing Activation Functions for â”‚87.02â”‚61.55â”‚WideResNet-28-10-â”‚arXiv,   
26â”‚ameterizing**}â”‚Adversarial Robustness][73]*              â”‚%    â”‚%    â”‚PSSiLU           â”‚Oct 2021 
**â”‚              â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Pang2022Roâ”‚*[ Robustness and Accuracy Could Be       â”‚88.61â”‚61.04â”‚WideResNet-28-10 â”‚ICML 2022
27â”‚bustness_WRN28â”‚Reconcilable by (Proper) Definition][74]* â”‚%    â”‚%    â”‚                 â”‚         
**â”‚_10**}        â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rade2021Heâ”‚*[Helper-based Adversarial Training:      â”‚88.16â”‚60.97â”‚WideResNet-28-10 â”‚OpenRevie
28â”‚lper_ddpm**}  â”‚Reducing Excessive Margin to Achieve a    â”‚%    â”‚%    â”‚                 â”‚w, Jun   
**â”‚              â”‚Better Accuracy vs. Robustness            â”‚     â”‚     â”‚                 â”‚2021     
  â”‚              â”‚Trade-off][75]*                           â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rebuffi202â”‚*[Fixing Data Augmentation to Improve     â”‚87.33â”‚60.73â”‚WideResNet-28-10 â”‚arXiv,   
29â”‚1Fixing_28_10_â”‚Adversarial Robustness][76]*              â”‚%    â”‚%    â”‚                 â”‚Mar 2021 
**â”‚cutmix_ddpm**}â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Sridhar202â”‚*[Improving Neural Network Robustness via â”‚86.53â”‚60.41â”‚WideResNet-34-15 â”‚ACC 2022 
30â”‚1Robust_34_15*â”‚Persistency of Excitation][77]*           â”‚%    â”‚%    â”‚                 â”‚         
**â”‚*}            â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Sehwag2021â”‚*[Robust Learning Meets Generative Models:â”‚86.68â”‚60.27â”‚WideResNet-34-10 â”‚ICLR 2022
31â”‚Proxy**}      â”‚Can Proxy Distributions Improve           â”‚%    â”‚%    â”‚                 â”‚         
**â”‚              â”‚Adversarial Robustness?][78]*             â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Wu2020Adveâ”‚*[Adversarial Weight Perturbation Helps   â”‚88.25â”‚60.04â”‚WideResNet-28-10 â”‚NeurIPS  
32â”‚rsarial_extra*â”‚Robust Generalization][79]*               â”‚%    â”‚%    â”‚                 â”‚2020     
**â”‚*}            â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Sridhar202â”‚*[Improving Neural Network Robustness via â”‚89.46â”‚59.66â”‚WideResNet-28-10 â”‚ACC 2022 
33â”‚1Robust**}    â”‚Persistency of Excitation][80]*           â”‚%    â”‚%    â”‚                 â”‚         
**â”‚              â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Zhang2020Gâ”‚*[Geometry-aware Instance-reweighted      â”‚89.36â”‚59.64â”‚WideResNet-28-10 â”‚ICLR 2021
34â”‚eometry**}    â”‚Adversarial Training][81]*                â”‚%    â”‚%    â”‚                 â”‚         
**â”‚              â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Carmon2019â”‚*[Unlabeled Data Improves Adversarial     â”‚89.69â”‚59.53â”‚WideResNet-28-10 â”‚NeurIPS  
35â”‚Unlabeled**}  â”‚Robustness][82]*                          â”‚%    â”‚%    â”‚                 â”‚2019     
**â”‚              â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Gowal2021Iâ”‚*[Improving Robustness using Generated    â”‚87.35â”‚58.50â”‚PreActResNet-18  â”‚NeurIPS  
36â”‚mproving_R18_dâ”‚Data][83]*                                â”‚%    â”‚%    â”‚                 â”‚2021     
**â”‚dpm_100m**}   â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Chen2024Daâ”‚*[Data filtering for efficient adversarialâ”‚86.10â”‚58.09â”‚WideResNet-34-20 â”‚Pattern  
37â”‚ta_WRN_34_20**â”‚training][84]*                            â”‚%    â”‚%    â”‚                 â”‚Recogniti
**â”‚}             â”‚                                          â”‚     â”‚     â”‚                 â”‚on 2024  
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Addepalli2â”‚*[Scaling Adversarial Training to Large   â”‚85.32â”‚58.04â”‚WideResNet-34-10 â”‚ECCV 2022
38â”‚021Towards_WRNâ”‚Perturbation Bounds][85]*                 â”‚%    â”‚%    â”‚                 â”‚         
**â”‚34**}         â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Addepalli2â”‚*[Efficient and Effective Augmentation    â”‚88.71â”‚57.81â”‚WideResNet-34-10 â”‚NeurIPS  
39â”‚022Efficient_Wâ”‚Strategy for Adversarial Training][86]*   â”‚%    â”‚%    â”‚                 â”‚2022     
**â”‚RN_34_10**}   â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Chen2021LTâ”‚*[LTD: Low Temperature Distillation for   â”‚86.03â”‚57.71â”‚WideResNet-34-20 â”‚arXiv,   
40â”‚D_WRN34_20**} â”‚Robust Adversarial Training][87]*         â”‚%    â”‚%    â”‚                 â”‚Nov 2021 
**â”‚              â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rade2021Heâ”‚*[Helper-based Adversarial Training:      â”‚89.02â”‚57.67â”‚PreActResNet-18  â”‚OpenRevie
41â”‚lper_R18_extraâ”‚Reducing Excessive Margin to Achieve a    â”‚%    â”‚%    â”‚                 â”‚w, Jun   
**â”‚**}           â”‚Better Accuracy vs. Robustness            â”‚     â”‚     â”‚                 â”‚2021     
  â”‚              â”‚Trade-off][88]*                           â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Jia2022LASâ”‚*[LAS-AT: Adversarial Training with       â”‚85.66â”‚57.61â”‚WideResNet-70-16 â”‚arXiv,   
42â”‚-AT_70_16**}  â”‚Learnable Attack Strategy][89]*           â”‚%    â”‚%    â”‚                 â”‚Mar 2022 
**â”‚              â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Debenedettâ”‚*[A Light Recipe to Train Robust Vision   â”‚91.73â”‚57.58â”‚XCiT-L12         â”‚arXiv,   
43â”‚i2022Light_XCiâ”‚Transformers][90]*                        â”‚%    â”‚%    â”‚                 â”‚Sep 2022 
**â”‚T-L12**}      â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Chen2024Daâ”‚*[Data filtering for efficient adversarialâ”‚86.54â”‚57.30â”‚WideResNet-34-10 â”‚Pattern  
44â”‚ta_WRN_34_10**â”‚training][91]*                            â”‚%    â”‚%    â”‚                 â”‚Recogniti
**â”‚}             â”‚                                          â”‚     â”‚     â”‚                 â”‚on 2024  
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Debenedettâ”‚*[A Light Recipe to Train Robust Vision   â”‚91.30â”‚57.27â”‚XCiT-M12         â”‚arXiv,   
45â”‚i2022Light_XCiâ”‚Transformers][92]*                        â”‚%    â”‚%    â”‚                 â”‚Sep 2022 
**â”‚T-M12**}      â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Sehwag2020â”‚*[HYDRA: Pruning Adversarially Robust     â”‚88.98â”‚57.14â”‚WideResNet-28-10 â”‚NeurIPS  
46â”‚Hydra**}      â”‚Neural Networks][93]*                     â”‚%    â”‚%    â”‚                 â”‚2020     
**â”‚              â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Gowal2020Uâ”‚*[Uncovering the Limits of Adversarial    â”‚85.29â”‚57.14â”‚WideResNet-70-16 â”‚arXiv,   
47â”‚ncovering_70_1â”‚Training against Norm-Bounded Adversarial â”‚%    â”‚%    â”‚                 â”‚Oct 2020 
**â”‚6**}          â”‚Examples][94]*                            â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rade2021Heâ”‚*[Helper-based Adversarial Training:      â”‚86.86â”‚57.09â”‚PreActResNet-18  â”‚OpenRevie
48â”‚lper_R18_ddpm*â”‚Reducing Excessive Margin to Achieve a    â”‚%    â”‚%    â”‚                 â”‚w, Jun   
**â”‚*}            â”‚Better Accuracy vs. Robustness            â”‚     â”‚     â”‚                 â”‚2021     
  â”‚              â”‚Trade-off][95]*                           â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Cui2023Decâ”‚*[Decoupled Kullback-Leibler Divergence   â”‚85.31â”‚57.09â”‚WideResNet-34-10 â”‚NeurIPS  
49â”‚oupled_WRN-34-â”‚Loss][96]*                                â”‚%    â”‚%    â”‚                 â”‚2024     
**â”‚10**}         â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Chen2021LTâ”‚*[LTD: Low Temperature Distillation for   â”‚85.21â”‚56.94â”‚WideResNet-34-10 â”‚arXiv,   
50â”‚D_WRN34_10**} â”‚Robust Adversarial Training][97]*         â”‚%    â”‚%    â”‚                 â”‚Nov 2021 
**â”‚              â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Gowal2020Uâ”‚*[Uncovering the Limits of Adversarial    â”‚85.64â”‚56.82â”‚WideResNet-34-20 â”‚arXiv,   
51â”‚ncovering_34_2â”‚Training against Norm-Bounded Adversarial â”‚%    â”‚%    â”‚                 â”‚Oct 2020 
**â”‚0**}          â”‚Examples][98]*                            â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rebuffi202â”‚*[Fixing Data Augmentation to Improve     â”‚83.53â”‚56.66â”‚PreActResNet-18  â”‚arXiv,   
52â”‚1Fixing_R18_ddâ”‚Adversarial Robustness][99]*              â”‚%    â”‚%    â”‚                 â”‚Mar 2021 
**â”‚pm**}         â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Wang2020Imâ”‚*[Improving Adversarial Robustness        â”‚87.50â”‚56.29â”‚WideResNet-28-10 â”‚ICLR 2020
53â”‚proving**}    â”‚Requires Revisiting Misclassified         â”‚%    â”‚%    â”‚                 â”‚         
**â”‚              â”‚Examples][100]*                           â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Jia2022LASâ”‚*[LAS-AT: Adversarial Training with       â”‚84.98â”‚56.26â”‚WideResNet-34-10 â”‚arXiv,   
54â”‚-AT_34_10**}  â”‚Learnable Attack Strategy][101]*          â”‚%    â”‚%    â”‚                 â”‚Mar 2022 
**â”‚              â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Wu2020Adveâ”‚*[Adversarial Weight Perturbation Helps   â”‚85.36â”‚56.17â”‚WideResNet-34-10 â”‚NeurIPS  
55â”‚rsarial**}    â”‚Robust Generalization][102]*              â”‚%    â”‚%    â”‚                 â”‚2020     
**â”‚              â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Debenedettâ”‚*[A Light Recipe to Train Robust Vision   â”‚90.06â”‚56.14â”‚XCiT-S12         â”‚arXiv,   
56â”‚i2022Light_XCiâ”‚Transformers][103]*                       â”‚%    â”‚%    â”‚                 â”‚Sep 2022 
**â”‚T-S12**}      â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Sehwag2021â”‚*[Robust Learning Meets Generative Models:â”‚84.59â”‚55.54â”‚ResNet-18        â”‚ICLR 2022
57â”‚Proxy_R18**}  â”‚Can Proxy Distributions Improve           â”‚%    â”‚%    â”‚                 â”‚         
**â”‚              â”‚Adversarial Robustness?][104]*            â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Hendrycks2â”‚*[Using Pre-Training Can Improve Model    â”‚87.11â”‚54.92â”‚WideResNet-28-10 â”‚ICML 2019
58â”‚019Using**}   â”‚Robustness and Uncertainty][105]*         â”‚%    â”‚%    â”‚                 â”‚         
**â”‚              â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Pang2020Boâ”‚*[Boosting Adversarial Training with      â”‚85.14â”‚53.74â”‚WideResNet-34-20 â”‚NeurIPS  
59â”‚osting**}     â”‚Hypersphere Embedding][106]*              â”‚%    â”‚%    â”‚                 â”‚2020     
**â”‚              â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Cui2020Leaâ”‚*[Learnable Boundary Guided Adversarial   â”‚88.70â”‚53.57â”‚WideResNet-34-20 â”‚ICCV 2021
60â”‚rnable_34_20**â”‚Training][107]*                           â”‚%    â”‚%    â”‚                 â”‚         
**â”‚}             â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Zhang2020Aâ”‚*[Attacks Which Do Not Kill Training Make â”‚84.52â”‚53.51â”‚WideResNet-34-10 â”‚ICML 2020
61â”‚ttacks**}     â”‚Adversarial Learning Stronger][108]*      â”‚%    â”‚%    â”‚                 â”‚         
**â”‚              â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rice2020Ovâ”‚*[Overfitting in adversarially robust deepâ”‚85.34â”‚53.42â”‚WideResNet-34-20 â”‚ICML 2020
62â”‚erfitting**}  â”‚learning][109]*                           â”‚%    â”‚%    â”‚                 â”‚         
**â”‚              â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Huang2020Sâ”‚*[Self-Adaptive Training: beyond Empiricalâ”‚83.48â”‚53.34â”‚WideResNet-34-10 â”‚NeurIPS  
63â”‚elf**}        â”‚Risk Minimization][110]*                  â”‚%    â”‚%    â”‚                 â”‚2020     
**â”‚              â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Zhang2019Tâ”‚*[Theoretically Principled Trade-off      â”‚84.92â”‚53.08â”‚WideResNet-34-10 â”‚ICML 2019
64â”‚heoretically**â”‚between Robustness and Accuracy][111]*    â”‚%    â”‚%    â”‚                 â”‚         
**â”‚}             â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Cui2020Leaâ”‚*[Learnable Boundary Guided Adversarial   â”‚88.22â”‚52.86â”‚WideResNet-34-10 â”‚ICCV 2021
65â”‚rnable_34_10**â”‚Training][112]*                           â”‚%    â”‚%    â”‚                 â”‚         
**â”‚}             â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Addepalli2â”‚*[Efficient and Effective Augmentation    â”‚85.71â”‚52.48â”‚ResNet-18        â”‚NeurIPS  
66â”‚022Efficient_Râ”‚Strategy for Adversarial Training][113]*  â”‚%    â”‚%    â”‚                 â”‚2022     
**â”‚N18**}        â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Chen2020Adâ”‚*[Adversarial Robustness: From            â”‚86.04â”‚51.56â”‚ResNet-50        â”‚CVPR 2020
67â”‚versarial**}  â”‚Self-Supervised Pre-Training to           â”‚%    â”‚%    â”‚(3x ensemble)    â”‚         
**â”‚              â”‚Fine-Tuning][114]*                        â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Chen2020Efâ”‚*[Efficient Robust Training via Backward  â”‚85.32â”‚51.12â”‚WideResNet-34-10 â”‚arXiv,   
68â”‚ficient**}    â”‚Smoothing][115]*                          â”‚%    â”‚%    â”‚                 â”‚Oct 2020 
**â”‚              â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Addepalli2â”‚*[Scaling Adversarial Training to Large   â”‚80.24â”‚51.06â”‚ResNet-18        â”‚ECCV 2022
69â”‚021Towards_RN1â”‚Perturbation Bounds][116]*                â”‚%    â”‚%    â”‚                 â”‚         
**â”‚8**}          â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Sitawarin2â”‚*[Improving Adversarial Robustness Throughâ”‚86.84â”‚50.72â”‚WideResNet-34-10 â”‚arXiv,   
70â”‚020Improving**â”‚Progressive Hardening][117]*              â”‚%    â”‚%    â”‚                 â”‚Mar 2020 
**â”‚}             â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Engstrom20â”‚*[Robustness library][118]*               â”‚87.03â”‚49.25â”‚ResNet-50        â”‚GitHub,  
71â”‚19Robustness**â”‚                                          â”‚%    â”‚%    â”‚                 â”‚Oct 2019 
**â”‚}             â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Zhang2019Yâ”‚*[You Only Propagate Once: Accelerating   â”‚87.20â”‚44.83â”‚WideResNet-34-10 â”‚NeurIPS  
72â”‚ou**}         â”‚Adversarial Training via Maximal          â”‚%    â”‚%    â”‚                 â”‚2019     
**â”‚              â”‚Principle][119]*                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Andriushchâ”‚*[Understanding and Improving Fast        â”‚79.84â”‚43.93â”‚PreActResNet-18  â”‚NeurIPS  
73â”‚enko2020Undersâ”‚Adversarial Training][120]*               â”‚%    â”‚%    â”‚                 â”‚2020     
**â”‚tanding**}    â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Wong2020Faâ”‚*[Fast is better than free: Revisiting    â”‚83.34â”‚43.21â”‚PreActResNet-18  â”‚ICLR 2020
74â”‚st**}         â”‚adversarial training][121]*               â”‚%    â”‚%    â”‚                 â”‚         
**â”‚              â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Ding2020MMâ”‚*[MMA Training: Direct Input Space Margin â”‚84.36â”‚41.44â”‚WideResNet-28-4  â”‚ICLR 2020
75â”‚A**}          â”‚Maximization through Adversarial          â”‚%    â”‚%    â”‚                 â”‚         
**â”‚              â”‚Training][122]*                           â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Standard**â”‚*[Standardly trained model][123]*         â”‚94.78â”‚0.00%â”‚WideResNet-28-10 â”‚N/A      
76â”‚}             â”‚                                          â”‚%    â”‚     â”‚                 â”‚         
**â”‚              â”‚                                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€

#### L2, eps=0.5

â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€
# â”‚Model ID       â”‚Paper                                         â”‚Clean â”‚Robustâ”‚Architecturâ”‚Venue   
  â”‚               â”‚                                              â”‚accuraâ”‚accuraâ”‚e          â”‚        
  â”‚               â”‚                                              â”‚cy    â”‚cy    â”‚           â”‚        
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Wang2023Betâ”‚*[Better Diffusion Models Further Improve     â”‚95.54%â”‚84.97%â”‚WideResNet-â”‚arXiv,  
1*â”‚ter_WRN-70-16**â”‚Adversarial Training][124]*                   â”‚      â”‚      â”‚70-16      â”‚Feb 2023
* â”‚}              â”‚                                              â”‚      â”‚      â”‚           â”‚        
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Amini2024Meâ”‚*[MeanSparse: Post-Training Robustness        â”‚95.51%â”‚84.33%â”‚MeanSparse â”‚arXiv,  
2*â”‚anSparse_S-WRN-â”‚Enhancement Through Mean-Centered Feature     â”‚      â”‚      â”‚WideResNet-â”‚Jun 2024
* â”‚70-16**}       â”‚Sparsification][125]*                         â”‚      â”‚      â”‚70-16      â”‚        
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Wang2023Betâ”‚*[Better Diffusion Models Further Improve     â”‚95.16%â”‚83.68%â”‚WideResNet-â”‚ICML    
3*â”‚ter_WRN-28-10**â”‚Adversarial Training][126]*                   â”‚      â”‚      â”‚28-10      â”‚2023    
* â”‚}              â”‚                                              â”‚      â”‚      â”‚           â”‚        
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rebuffi2021â”‚*[Fixing Data Augmentation to Improve         â”‚95.74%â”‚82.32%â”‚WideResNet-â”‚arXiv,  
4*â”‚Fixing_70_16_cuâ”‚Adversarial Robustness][127]*                 â”‚      â”‚      â”‚70-16      â”‚Mar 2021
* â”‚tmix_extra**}  â”‚                                              â”‚      â”‚      â”‚           â”‚        
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Gowal2020Unâ”‚*[Uncovering the Limits of Adversarial        â”‚94.74%â”‚80.53%â”‚WideResNet-â”‚arXiv,  
5*â”‚covering_extra*â”‚Training against Norm-Bounded Adversarial     â”‚      â”‚      â”‚70-16      â”‚Oct 2020
* â”‚*}             â”‚Examples][128]*                               â”‚      â”‚      â”‚           â”‚        
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rebuffi2021â”‚*[Fixing Data Augmentation to Improve         â”‚92.41%â”‚80.42%â”‚WideResNet-â”‚arXiv,  
6*â”‚Fixing_70_16_cuâ”‚Adversarial Robustness][129]*                 â”‚      â”‚      â”‚70-16      â”‚Mar 2021
* â”‚tmix_ddpm**}   â”‚                                              â”‚      â”‚      â”‚           â”‚        
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rebuffi2021â”‚*[Fixing Data Augmentation to Improve         â”‚91.79%â”‚78.80%â”‚WideResNet-â”‚arXiv,  
7*â”‚Fixing_28_10_cuâ”‚Adversarial Robustness][130]*                 â”‚      â”‚      â”‚28-10      â”‚Mar 2021
* â”‚tmix_ddpm**}   â”‚                                              â”‚      â”‚      â”‚           â”‚        
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Augustin202â”‚*[Adversarial Robustness on In- and           â”‚93.96%â”‚78.79%â”‚WideResNet-â”‚ECCV    
8*â”‚0Adversarial_34â”‚Out-Distribution Improves                     â”‚      â”‚      â”‚34-10      â”‚2020    
* â”‚_10_extra**}   â”‚Explainability][131]*                         â”‚      â”‚      â”‚           â”‚        
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Sehwag2021Pâ”‚*[Robust Learning Meets Generative Models: Canâ”‚90.93%â”‚77.24%â”‚WideResNet-â”‚ICLR    
9*â”‚roxy**}        â”‚Proxy Distributions Improve Adversarial       â”‚      â”‚      â”‚34-10      â”‚2022    
* â”‚               â”‚Robustness?][132]*                            â”‚      â”‚      â”‚           â”‚        
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Augustin202â”‚*[Adversarial Robustness on In- and           â”‚92.23%â”‚76.25%â”‚WideResNet-â”‚ECCV    
10â”‚0Adversarial_34â”‚Out-Distribution Improves                     â”‚      â”‚      â”‚34-10      â”‚2020    
**â”‚_10**}         â”‚Explainability][133]*                         â”‚      â”‚      â”‚           â”‚        
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rade2021Helâ”‚*[Helper-based Adversarial Training: Reducing â”‚90.57%â”‚76.15%â”‚PreActResNeâ”‚OpenRevi
11â”‚per_R18_ddpm**}â”‚Excessive Margin to Achieve a Better Accuracy â”‚      â”‚      â”‚t-18       â”‚ew, Jun 
**â”‚               â”‚vs. Robustness Trade-off][134]*               â”‚      â”‚      â”‚           â”‚2021    
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rebuffi2021â”‚*[Fixing Data Augmentation to Improve         â”‚90.33%â”‚75.86%â”‚PreActResNeâ”‚arXiv,  
12â”‚Fixing_R18_cutmâ”‚Adversarial Robustness][135]*                 â”‚      â”‚      â”‚t-18       â”‚Mar 2021
**â”‚ix_ddpm**}     â”‚                                              â”‚      â”‚      â”‚           â”‚        
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Gowal2020Unâ”‚*[Uncovering the Limits of Adversarial        â”‚90.90%â”‚74.50%â”‚WideResNet-â”‚arXiv,  
13â”‚covering**}    â”‚Training against Norm-Bounded Adversarial     â”‚      â”‚      â”‚70-16      â”‚Oct 2020
**â”‚               â”‚Examples][136]*                               â”‚      â”‚      â”‚           â”‚        
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Sehwag2021Pâ”‚*[Robust Learning Meets Generative Models: Canâ”‚89.76%â”‚74.41%â”‚ResNet-18  â”‚ICLR    
14â”‚roxy_R18**}    â”‚Proxy Distributions Improve Adversarial       â”‚      â”‚      â”‚           â”‚2022    
**â”‚               â”‚Robustness?][137]*                            â”‚      â”‚      â”‚           â”‚        
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Wu2020Adverâ”‚*[Adversarial Weight Perturbation Helps Robustâ”‚88.51%â”‚73.66%â”‚WideResNet-â”‚NeurIPS 
15â”‚sarial**}      â”‚Generalization][138]*                         â”‚      â”‚      â”‚34-10      â”‚2020    
**â”‚               â”‚                                              â”‚      â”‚      â”‚           â”‚        
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Augustin202â”‚*[Adversarial Robustness on In- and           â”‚91.08%â”‚72.91%â”‚ResNet-50  â”‚ECCV    
16â”‚0Adversarial**}â”‚Out-Distribution Improves                     â”‚      â”‚      â”‚           â”‚2020    
**â”‚               â”‚Explainability][139]*                         â”‚      â”‚      â”‚           â”‚        
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Engstrom201â”‚*[Robustness library][140]*                   â”‚90.83%â”‚69.24%â”‚ResNet-50  â”‚GitHub, 
17â”‚9Robustness**} â”‚                                              â”‚      â”‚      â”‚           â”‚Sep 2019
**â”‚               â”‚                                              â”‚      â”‚      â”‚           â”‚        
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rice2020Oveâ”‚*[Overfitting in adversarially robust deep    â”‚88.67%â”‚67.68%â”‚PreActResNeâ”‚ICML    
18â”‚rfitting**}    â”‚learning][141]*                               â”‚      â”‚      â”‚t-18       â”‚2020    
**â”‚               â”‚                                              â”‚      â”‚      â”‚           â”‚        
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rony2019Decâ”‚*[Decoupling Direction and Norm for Efficient â”‚89.05%â”‚66.44%â”‚WideResNet-â”‚CVPR    
19â”‚oupling**}     â”‚Gradient-Based L2 Adversarial Attacks and     â”‚      â”‚      â”‚28-10      â”‚2019    
**â”‚               â”‚Defenses][142]*                               â”‚      â”‚      â”‚           â”‚        
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Ding2020MMAâ”‚*[MMA Training: Direct Input Space Margin     â”‚88.02%â”‚66.09%â”‚WideResNet-â”‚ICLR    
20â”‚**}            â”‚Maximization through Adversarial              â”‚      â”‚      â”‚28-4       â”‚2020    
**â”‚               â”‚Training][143]*                               â”‚      â”‚      â”‚           â”‚        
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Standard**}â”‚*[Standardly trained model][144]*             â”‚94.78%â”‚0.00% â”‚WideResNet-â”‚N/A     
21â”‚               â”‚                                              â”‚      â”‚      â”‚28-10      â”‚        
**â”‚               â”‚                                              â”‚      â”‚      â”‚           â”‚        
â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€

#### Common Corruptions

â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€
# â”‚Model ID             â”‚Paper                                     â”‚Clean  â”‚Robust â”‚Architecâ”‚Venue  
  â”‚                     â”‚                                          â”‚accuracâ”‚accuracâ”‚ture    â”‚       
  â”‚                     â”‚                                          â”‚y      â”‚y      â”‚        â”‚       
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Diffenderfer2021Wâ”‚*[A Winning Hand: Compressing Deep        â”‚96.56% â”‚92.78% â”‚WideResNâ”‚NeurIPS
1*â”‚inning_LRR_CARD_Deck*â”‚Networks Can Improve Out-Of-Distribution  â”‚       â”‚       â”‚et-18-2 â”‚2021   
* â”‚*}                   â”‚Robustness][145]*                         â”‚       â”‚       â”‚        â”‚       
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Diffenderfer2021Wâ”‚*[A Winning Hand: Compressing Deep        â”‚96.66% â”‚90.94% â”‚WideResNâ”‚NeurIPS
2*â”‚inning_LRR**}        â”‚Networks Can Improve Out-Of-Distribution  â”‚       â”‚       â”‚et-18-2 â”‚2021   
* â”‚                     â”‚Robustness][146]*                         â”‚       â”‚       â”‚        â”‚       
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Diffenderfer2021Wâ”‚*[A Winning Hand: Compressing Deep        â”‚95.09% â”‚90.15% â”‚WideResNâ”‚NeurIPS
3*â”‚inning_Binary_CARD_Deâ”‚Networks Can Improve Out-Of-Distribution  â”‚       â”‚       â”‚et-18-2 â”‚2021   
* â”‚ck**}                â”‚Robustness][147]*                         â”‚       â”‚       â”‚        â”‚       
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Kireev2021Effectiâ”‚*[On the effectiveness of adversarial     â”‚94.75% â”‚89.60% â”‚ResNet-1â”‚arXiv, 
4*â”‚veness_RLATAugMix**} â”‚training against common corruptions][148]*â”‚       â”‚       â”‚8       â”‚Mar    
* â”‚                     â”‚                                          â”‚       â”‚       â”‚        â”‚2021   
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Hendrycks2020AugMâ”‚*[AugMix: A Simple Data Processing Method â”‚95.83% â”‚89.09% â”‚ResNeXt2â”‚ICLR   
5*â”‚ix_ResNeXt**}        â”‚to Improve Robustness and                 â”‚       â”‚       â”‚9_32x4d â”‚2020   
* â”‚                     â”‚Uncertainty][149]*                        â”‚       â”‚       â”‚        â”‚       
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Modas2021PRIMEResâ”‚*[PRIME: A Few Primitives Can Boost       â”‚93.06% â”‚89.05% â”‚ResNet-1â”‚arXiv, 
6*â”‚Net18**}             â”‚Robustness to Common Corruptions][150]*   â”‚       â”‚       â”‚8       â”‚Dec    
* â”‚                     â”‚                                          â”‚       â”‚       â”‚        â”‚2021   
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Hendrycks2020AugMâ”‚*[AugMix: A Simple Data Processing Method â”‚95.08% â”‚88.82% â”‚WideResNâ”‚ICLR   
7*â”‚ix_WRN**}            â”‚to Improve Robustness and                 â”‚       â”‚       â”‚et-40-2 â”‚2020   
* â”‚                     â”‚Uncertainty][151]*                        â”‚       â”‚       â”‚        â”‚       
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Kireev2021Effectiâ”‚*[On the effectiveness of adversarial     â”‚94.77% â”‚88.53% â”‚PreActReâ”‚arXiv, 
8*â”‚veness_RLATAugMixNoJSâ”‚training against common corruptions][152]*â”‚       â”‚       â”‚sNet-18 â”‚Mar    
* â”‚D**}                 â”‚                                          â”‚       â”‚       â”‚        â”‚2021   
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Diffenderfer2021Wâ”‚*[A Winning Hand: Compressing Deep        â”‚94.87% â”‚88.32% â”‚WideResNâ”‚NeurIPS
9*â”‚inning_Binary**}     â”‚Networks Can Improve Out-Of-Distribution  â”‚       â”‚       â”‚et-18-2 â”‚2021   
* â”‚                     â”‚Robustness][153]*                         â”‚       â”‚       â”‚        â”‚       
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rebuffi2021Fixingâ”‚*[Fixing Data Augmentation to Improve     â”‚95.74% â”‚88.23% â”‚WideResNâ”‚arXiv, 
10â”‚_70_16_cutmix_extra_Lâ”‚Adversarial Robustness][154]*             â”‚       â”‚       â”‚et-70-16â”‚Mar    
**â”‚2**}                 â”‚                                          â”‚       â”‚       â”‚        â”‚2021   
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Kireev2021Effectiâ”‚*[On the effectiveness of adversarial     â”‚94.97% â”‚86.60% â”‚PreActReâ”‚arXiv, 
11â”‚veness_AugMixNoJSD**}â”‚training against common corruptions][155]*â”‚       â”‚       â”‚sNet-18 â”‚Mar    
**â”‚                     â”‚                                          â”‚       â”‚       â”‚        â”‚2021   
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Kireev2021Effectiâ”‚*[On the effectiveness of adversarial     â”‚93.24% â”‚85.04% â”‚PreActReâ”‚arXiv, 
12â”‚veness_Gauss50percentâ”‚training against common corruptions][156]*â”‚       â”‚       â”‚sNet-18 â”‚Mar    
**â”‚**}                  â”‚                                          â”‚       â”‚       â”‚        â”‚2021   
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Kireev2021Effectiâ”‚*[On the effectiveness of adversarial     â”‚93.10% â”‚84.10% â”‚PreActReâ”‚arXiv, 
13â”‚veness_RLAT**}       â”‚training against common corruptions][157]*â”‚       â”‚       â”‚sNet-18 â”‚Mar    
**â”‚                     â”‚                                          â”‚       â”‚       â”‚        â”‚2021   
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rebuffi2021Fixingâ”‚*[Fixing Data Augmentation to Improve     â”‚92.23% â”‚82.82% â”‚WideResNâ”‚arXiv, 
14â”‚_70_16_cutmix_extra_Lâ”‚Adversarial Robustness][158]*             â”‚       â”‚       â”‚et-70-16â”‚Mar    
**â”‚inf**}               â”‚                                          â”‚       â”‚       â”‚        â”‚2021   
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Addepalli2022Effiâ”‚*[Efficient and Effective Augmentation    â”‚88.71% â”‚80.12% â”‚WideResNâ”‚CVPRW  
15â”‚cient_WRN_34_10**}   â”‚Strategy for Adversarial Training][159]*  â”‚       â”‚       â”‚et-34-10â”‚2022   
**â”‚                     â”‚                                          â”‚       â”‚       â”‚        â”‚       
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Addepalli2021Towaâ”‚*[Towards Achieving Adversarial Robustnessâ”‚85.32% â”‚76.78% â”‚WideResNâ”‚arXiv, 
16â”‚rds_WRN34**}         â”‚Beyond Perceptual Limits][160]*           â”‚       â”‚       â”‚et-34-10â”‚Apr    
**â”‚                     â”‚                                          â”‚       â”‚       â”‚        â”‚2021   
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Standard**}      â”‚*[Standardly trained model][161]*         â”‚94.78% â”‚73.46% â”‚WideResNâ”‚N/A    
17â”‚                     â”‚                                          â”‚       â”‚       â”‚et-28-10â”‚       
**â”‚                     â”‚                                          â”‚       â”‚       â”‚        â”‚       
â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€

### CIFAR-100

#### Linf, eps=8/255

â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â”‚Model ID       â”‚Paper                                    â”‚Cleanâ”‚Robusâ”‚Architecture     â”‚Venue    
  â”‚               â”‚                                         â”‚accurâ”‚t    â”‚                 â”‚         
  â”‚               â”‚                                         â”‚acy  â”‚accurâ”‚                 â”‚         
  â”‚               â”‚                                         â”‚     â”‚acy  â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Wang2023Betâ”‚*[Better Diffusion Models Further Improveâ”‚75.22â”‚42.66â”‚WideResNet-70-16 â”‚ICML 2023
1*â”‚ter_WRN-70-16**â”‚Adversarial Training][162]*              â”‚%    â”‚%    â”‚                 â”‚         
* â”‚}              â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Amini2024Meâ”‚*[MeanSparse: Post-Training Robustness   â”‚75.13â”‚42.25â”‚MeanSparse       â”‚arXiv,   
2*â”‚anSparse_S-WRN-â”‚Enhancement Through Mean-Centered Featureâ”‚%    â”‚%    â”‚WideResNet-70-16 â”‚Jun 2024 
* â”‚70-16**}       â”‚Sparsification][163]*                    â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Bai2024Mixeâ”‚*[MixedNUTS: Training-Free               â”‚83.08â”‚41.80â”‚ResNet-152 +     â”‚TMLR, Aug
3*â”‚dNUTS**}       â”‚Accuracy-Robustness Balance via          â”‚%    â”‚%    â”‚WideResNet-70-16 â”‚2024     
* â”‚               â”‚Nonlinearly Mixed Classifiers][164]*     â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Cui2023Decoâ”‚*[Decoupled Kullback-Leibler Divergence  â”‚73.85â”‚39.18â”‚WideResNet-28-10 â”‚NeurIPS  
4*â”‚upled_WRN-28-10â”‚Loss][165]*                              â”‚%    â”‚%    â”‚                 â”‚2024     
* â”‚**}            â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Wang2023Betâ”‚*[Better Diffusion Models Further Improveâ”‚72.58â”‚38.77â”‚WideResNet-28-10 â”‚ICML 2023
5*â”‚ter_WRN-28-10**â”‚Adversarial Training][166]*              â”‚%    â”‚%    â”‚                 â”‚         
* â”‚}              â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Bai2023Imprâ”‚*[Improving the Accuracy-Robustness      â”‚85.21â”‚38.72â”‚ResNet-152 +     â”‚SIMODS   
6*â”‚oving_edm**}   â”‚Trade-off of Classifiers via Adaptive    â”‚%    â”‚%    â”‚WideResNet-70-16 â”‚2024     
* â”‚               â”‚Smoothing][167]*                         â”‚     â”‚     â”‚+ mixing network â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Gowal2020Unâ”‚*[Uncovering the Limits of Adversarial   â”‚69.15â”‚36.88â”‚WideResNet-70-16 â”‚arXiv,   
7*â”‚covering_extra*â”‚Training against Norm-Bounded Adversarialâ”‚%    â”‚%    â”‚                 â”‚Oct 2020 
* â”‚*}             â”‚Examples][168]*                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Bai2023Imprâ”‚*[Improving the Accuracy-Robustness      â”‚80.18â”‚35.15â”‚ResNet-152 +     â”‚SIMODS   
8*â”‚oving_trades**}â”‚Trade-off of Classifiers via Adaptive    â”‚%    â”‚%    â”‚WideResNet-70-16 â”‚2024     
* â”‚               â”‚Smoothing][169]*                         â”‚     â”‚     â”‚+ mixing network â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Debenedettiâ”‚*[A Light Recipe to Train Robust Vision  â”‚70.76â”‚35.08â”‚XCiT-L12         â”‚arXiv,   
9*â”‚2022Light_XCiT-â”‚Transformers][170]*                      â”‚%    â”‚%    â”‚                 â”‚Sep 2022 
* â”‚L12**}         â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rebuffi2021â”‚*[Fixing Data Augmentation to Improve    â”‚63.56â”‚34.64â”‚WideResNet-70-16 â”‚arXiv,   
10â”‚Fixing_70_16_cuâ”‚Adversarial Robustness][171]*            â”‚%    â”‚%    â”‚                 â”‚Mar 2021 
**â”‚tmix_ddpm**}   â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Debenedettiâ”‚*[A Light Recipe to Train Robust Vision  â”‚69.21â”‚34.21â”‚XCiT-M12         â”‚arXiv,   
11â”‚2022Light_XCiT-â”‚Transformers][172]*                      â”‚%    â”‚%    â”‚                 â”‚Sep 2022 
**â”‚M12**}         â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Pang2022Robâ”‚*[ Robustness and Accuracy Could Be      â”‚65.56â”‚33.05â”‚WideResNet-70-16 â”‚ICML 2022
12â”‚ustness_WRN70_1â”‚Reconcilable by (Proper)                 â”‚%    â”‚%    â”‚                 â”‚         
**â”‚6**}           â”‚Definition][173]*                        â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Cui2023Decoâ”‚*[Decoupled Kullback-Leibler Divergence  â”‚65.93â”‚32.52â”‚WideResNet-34-10 â”‚NeurIPS  
13â”‚upled_WRN-34-10â”‚Loss][174]*                              â”‚%    â”‚%    â”‚                 â”‚2024     
**â”‚_autoaug**}    â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Debenedettiâ”‚*[A Light Recipe to Train Robust Vision  â”‚67.34â”‚32.19â”‚XCiT-S12         â”‚arXiv,   
14â”‚2022Light_XCiT-â”‚Transformers][175]*                      â”‚%    â”‚%    â”‚                 â”‚Sep 2022 
**â”‚S12**}         â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rebuffi2021â”‚*[Fixing Data Augmentation to Improve    â”‚62.41â”‚32.06â”‚WideResNet-28-10 â”‚arXiv,   
15â”‚Fixing_28_10_cuâ”‚Adversarial Robustness][176]*            â”‚%    â”‚%    â”‚                 â”‚Mar 2021 
**â”‚tmix_ddpm**}   â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Jia2022LAS-â”‚*[LAS-AT: Adversarial Training with      â”‚67.31â”‚31.91â”‚WideResNet-34-20 â”‚arXiv,   
16â”‚AT_34_20**}    â”‚Learnable Attack Strategy][177]*         â”‚%    â”‚%    â”‚                 â”‚Mar 2022 
**â”‚               â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Cui2023Decoâ”‚*[Decoupled Kullback-Leibler Divergence  â”‚65.76â”‚31.91â”‚WideResNet-34-10 â”‚NeurIPS  
17â”‚upled_WRN-34-10â”‚Loss][178]*                              â”‚%    â”‚%    â”‚                 â”‚2024     
**â”‚**}            â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Addepalli20â”‚*[Efficient and Effective Augmentation   â”‚68.75â”‚31.85â”‚WideResNet-34-10 â”‚NeurIPS  
18â”‚22Efficient_WRNâ”‚Strategy for Adversarial Training][179]* â”‚%    â”‚%    â”‚                 â”‚2022     
**â”‚_34_10**}      â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Cui2020Learâ”‚*[Learnable Boundary Guided Adversarial  â”‚62.99â”‚31.20â”‚WideResNet-34-10 â”‚ICCV 2021
19â”‚nable_34_10_LBGâ”‚Training][180]*                          â”‚%    â”‚%    â”‚                 â”‚         
**â”‚AT9_eps_8_255**â”‚                                         â”‚     â”‚     â”‚                 â”‚         
  â”‚}              â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Sehwag2021Pâ”‚*[Robust Learning Meets Generative       â”‚65.93â”‚31.15â”‚WideResNet-34-10 â”‚ICLR 2022
20â”‚roxy**}        â”‚Models: Can Proxy Distributions Improve  â”‚%    â”‚%    â”‚                 â”‚         
**â”‚               â”‚Adversarial Robustness?][181]*           â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Chen2024Datâ”‚*[Data filtering for efficient           â”‚64.32â”‚31.13â”‚WideResNet-34-10 â”‚Pattern  
21â”‚a_WRN_34_10**} â”‚adversarial training][182]*              â”‚%    â”‚%    â”‚                 â”‚Recogniti
**â”‚               â”‚                                         â”‚     â”‚     â”‚                 â”‚on 2024  
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Pang2022Robâ”‚*[ Robustness and Accuracy Could Be      â”‚63.66â”‚31.08â”‚WideResNet-28-10 â”‚ICML 2022
22â”‚ustness_WRN28_1â”‚Reconcilable by (Proper)                 â”‚%    â”‚%    â”‚                 â”‚         
**â”‚0**}           â”‚Definition][183]*                        â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Jia2022LAS-â”‚*[LAS-AT: Adversarial Training with      â”‚64.89â”‚30.77â”‚WideResNet-34-10 â”‚arXiv,   
23â”‚AT_34_10**}    â”‚Learnable Attack Strategy][184]*         â”‚%    â”‚%    â”‚                 â”‚Mar 2022 
**â”‚               â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Chen2021LTDâ”‚*[LTD: Low Temperature Distillation for  â”‚64.07â”‚30.59â”‚WideResNet-34-10 â”‚arXiv,   
24â”‚_WRN34_10**}   â”‚Robust Adversarial Training][185]*       â”‚%    â”‚%    â”‚                 â”‚Nov 2021 
**â”‚               â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Addepalli20â”‚*[Scaling Adversarial Training to Large  â”‚65.73â”‚30.35â”‚WideResNet-34-10 â”‚ECCV 2022
25â”‚21Towards_WRN34â”‚Perturbation Bounds][186]*               â”‚%    â”‚%    â”‚                 â”‚         
**â”‚**}            â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Cui2020Learâ”‚*[Learnable Boundary Guided Adversarial  â”‚62.55â”‚30.20â”‚WideResNet-34-20 â”‚ICCV 2021
26â”‚nable_34_20_LBGâ”‚Training][187]*                          â”‚%    â”‚%    â”‚                 â”‚         
**â”‚AT6**}         â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Gowal2020Unâ”‚*[Uncovering the Limits of Adversarial   â”‚60.86â”‚30.03â”‚WideResNet-70-16 â”‚arXiv,   
27â”‚covering**}    â”‚Training against Norm-Bounded Adversarialâ”‚%    â”‚%    â”‚                 â”‚Oct 2020 
**â”‚               â”‚Examples][188]*                          â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Cui2020Learâ”‚*[Learnable Boundary Guided Adversarial  â”‚60.64â”‚29.33â”‚WideResNet-34-10 â”‚ICCV 2021
28â”‚nable_34_10_LBGâ”‚Training][189]*                          â”‚%    â”‚%    â”‚                 â”‚         
**â”‚AT6**}         â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rade2021Helâ”‚*[Helper-based Adversarial Training:     â”‚61.50â”‚28.88â”‚PreActResNet-18  â”‚OpenRevie
29â”‚per_R18_ddpm**}â”‚Reducing Excessive Margin to Achieve a   â”‚%    â”‚%    â”‚                 â”‚w, Jun   
**â”‚               â”‚Better Accuracy vs. Robustness           â”‚     â”‚     â”‚                 â”‚2021     
  â”‚               â”‚Trade-off][190]*                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Wu2020Adverâ”‚*[Adversarial Weight Perturbation Helps  â”‚60.38â”‚28.86â”‚WideResNet-34-10 â”‚NeurIPS  
30â”‚sarial**}      â”‚Robust Generalization][191]*             â”‚%    â”‚%    â”‚                 â”‚2020     
**â”‚               â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rebuffi2021â”‚*[Fixing Data Augmentation to Improve    â”‚56.87â”‚28.50â”‚PreActResNet-18  â”‚arXiv,   
31â”‚Fixing_R18_ddpmâ”‚Adversarial Robustness][192]*            â”‚%    â”‚%    â”‚                 â”‚Mar 2021 
**â”‚**}            â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Hendrycks20â”‚*[Using Pre-Training Can Improve Model   â”‚59.23â”‚28.42â”‚WideResNet-28-10 â”‚ICML 2019
32â”‚19Using**}     â”‚Robustness and Uncertainty][193]*        â”‚%    â”‚%    â”‚                 â”‚         
**â”‚               â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Addepalli20â”‚*[Efficient and Effective Augmentation   â”‚65.45â”‚27.67â”‚ResNet-18        â”‚NeurIPS  
33â”‚22Efficient_RN1â”‚Strategy for Adversarial Training][194]* â”‚%    â”‚%    â”‚                 â”‚2022     
**â”‚8**}           â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Cui2020Learâ”‚*[Learnable Boundary Guided Adversarial  â”‚70.25â”‚27.16â”‚WideResNet-34-10 â”‚ICCV 2021
34â”‚nable_34_10_LBGâ”‚Training][195]*                          â”‚%    â”‚%    â”‚                 â”‚         
**â”‚AT0**}         â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Addepalli20â”‚*[Scaling Adversarial Training to Large  â”‚62.02â”‚27.14â”‚PreActResNet-18  â”‚ECCV 2022
35â”‚21Towards_PARN1â”‚Perturbation Bounds][196]*               â”‚%    â”‚%    â”‚                 â”‚         
**â”‚8**}           â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Chen2020Effâ”‚*[Efficient Robust Training via Backward â”‚62.15â”‚26.94â”‚WideResNet-34-10 â”‚arXiv,   
36â”‚icient**}      â”‚Smoothing][197]*                         â”‚%    â”‚%    â”‚                 â”‚Oct 2020 
**â”‚               â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Sitawarin20â”‚*[Improving Adversarial Robustness       â”‚62.82â”‚24.57â”‚WideResNet-34-10 â”‚arXiv,   
37â”‚20Improving**} â”‚Through Progressive Hardening][198]*     â”‚%    â”‚%    â”‚                 â”‚Mar 2020 
**â”‚               â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Rice2020Oveâ”‚*[Overfitting in adversarially robust    â”‚53.83â”‚18.95â”‚PreActResNet-18  â”‚ICML 2020
38â”‚rfitting**}    â”‚deep learning][199]*                     â”‚%    â”‚%    â”‚                 â”‚         
**â”‚               â”‚                                         â”‚     â”‚     â”‚                 â”‚         
â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€

#### Corruptions

â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â”‚Model ID            â”‚Paper                                   â”‚Clean  â”‚Robust â”‚Architecâ”‚Venue     
  â”‚                    â”‚                                        â”‚accuracâ”‚accuracâ”‚ture    â”‚          
  â”‚                    â”‚                                        â”‚y      â”‚y      â”‚        â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Diffenderfer2021â”‚*[A Winning Hand: Compressing Deep      â”‚79.93% â”‚71.08% â”‚WideResNâ”‚NeurIPS   
1*â”‚Winning_LRR_CARD_Decâ”‚Networks Can Improve Out-Of-Distributionâ”‚       â”‚       â”‚et-18-2 â”‚2021      
* â”‚k**}                â”‚Robustness][200]*                       â”‚       â”‚       â”‚        â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Diffenderfer2021â”‚*[A Winning Hand: Compressing Deep      â”‚78.50% â”‚69.09% â”‚WideResNâ”‚NeurIPS   
2*â”‚Winning_Binary_CARD_â”‚Networks Can Improve Out-Of-Distributionâ”‚       â”‚       â”‚et-18-2 â”‚2021      
* â”‚Deck**}             â”‚Robustness][201]*                       â”‚       â”‚       â”‚        â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Modas2021PRIMEReâ”‚*[PRIME: A Few Primitives Can Boost     â”‚77.60% â”‚68.28% â”‚ResNet-1â”‚arXiv, Dec
3*â”‚sNet18**}           â”‚Robustness to Common Corruptions][202]* â”‚       â”‚       â”‚8       â”‚2021      
* â”‚                    â”‚                                        â”‚       â”‚       â”‚        â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Diffenderfer2021â”‚*[A Winning Hand: Compressing Deep      â”‚78.41% â”‚66.45% â”‚WideResNâ”‚NeurIPS   
4*â”‚Winning_LRR**}      â”‚Networks Can Improve Out-Of-Distributionâ”‚       â”‚       â”‚et-18-2 â”‚2021      
* â”‚                    â”‚Robustness][203]*                       â”‚       â”‚       â”‚        â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Diffenderfer2021â”‚*[A Winning Hand: Compressing Deep      â”‚77.69% â”‚65.26% â”‚WideResNâ”‚NeurIPS   
5*â”‚Winning_Binary**}   â”‚Networks Can Improve Out-Of-Distributionâ”‚       â”‚       â”‚et-18-2 â”‚2021      
* â”‚                    â”‚Robustness][204]*                       â”‚       â”‚       â”‚        â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Hendrycks2020Augâ”‚*[AugMix: A Simple Data Processing      â”‚78.90% â”‚65.14% â”‚ResNeXt2â”‚ICLR 2020 
6*â”‚Mix_ResNeXt**}      â”‚Method to Improve Robustness and        â”‚       â”‚       â”‚9_32x4d â”‚          
* â”‚                    â”‚Uncertainty][205]*                      â”‚       â”‚       â”‚        â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Hendrycks2020Augâ”‚*[AugMix: A Simple Data Processing      â”‚76.28% â”‚64.11% â”‚WideResNâ”‚ICLR 2020 
7*â”‚Mix_WRN**}          â”‚Method to Improve Robustness and        â”‚       â”‚       â”‚et-40-2 â”‚          
* â”‚                    â”‚Uncertainty][206]*                      â”‚       â”‚       â”‚        â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Addepalli2022Effâ”‚*[Efficient and Effective Augmentation  â”‚68.75% â”‚56.95% â”‚WideResNâ”‚CVPRW 2022
8*â”‚icient_WRN_34_10**} â”‚Strategy for Adversarial Training][207]*â”‚       â”‚       â”‚et-34-10â”‚          
* â”‚                    â”‚                                        â”‚       â”‚       â”‚        â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Gowal2020Uncoverâ”‚*[Uncovering the Limits of Adversarial  â”‚69.15% â”‚56.00% â”‚WideResNâ”‚arXiv, Oct
9*â”‚ing_extra_Linf**}   â”‚Training against Norm-Bounded           â”‚       â”‚       â”‚et-70-16â”‚2020      
* â”‚                    â”‚Adversarial Examples][208]*             â”‚       â”‚       â”‚        â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Addepalli2021Towâ”‚*[Towards Achieving Adversarial         â”‚65.73% â”‚54.88% â”‚WideResNâ”‚OpenReview
10â”‚ards_WRN34**}       â”‚Robustness Beyond Perceptual            â”‚       â”‚       â”‚et-34-10â”‚, Jun 2021
**â”‚                    â”‚Limits][209]*                           â”‚       â”‚       â”‚        â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Addepalli2021Towâ”‚*[Towards Achieving Adversarial         â”‚62.02% â”‚51.77% â”‚PreActReâ”‚OpenReview
11â”‚ards_PARN18**}      â”‚Robustness Beyond Perceptual            â”‚       â”‚       â”‚sNet-18 â”‚, Jun 2021
**â”‚                    â”‚Limits][210]*                           â”‚       â”‚       â”‚        â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Gowal2020Uncoverâ”‚*[Uncovering the Limits of Adversarial  â”‚60.86% â”‚49.46% â”‚WideResNâ”‚arXiv, Oct
12â”‚ing_Linf**}         â”‚Training against Norm-Bounded           â”‚       â”‚       â”‚et-70-16â”‚2020      
**â”‚                    â”‚Adversarial Examples][211]*             â”‚       â”‚       â”‚        â”‚          
â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

### ImageNet

*Note:* the values (even clean accuracy) might have small fluctuations depending on the version of
the packages e.g. `torchvision`.

#### Linf, eps=4/255

â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â”‚Model ID         â”‚Paper                                       â”‚Clean â”‚Robustâ”‚Architectâ”‚Venue     
  â”‚                 â”‚                                            â”‚accuraâ”‚accuraâ”‚ure      â”‚          
  â”‚                 â”‚                                            â”‚cy    â”‚cy    â”‚         â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Xu2024MIMIR_Sâ”‚*[MIMIR: Masked Image Modeling for Mutual   â”‚78.62%â”‚59.68%â”‚Swin-L   â”‚arXiv, Dec
1*â”‚win-L**}         â”‚Information-based Adversarial               â”‚      â”‚      â”‚         â”‚2023      
* â”‚                 â”‚Robustness][212]*                           â”‚      â”‚      â”‚         â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Liu2023Compreâ”‚*[A Comprehensive Study on Robustness of    â”‚78.92%â”‚59.56%â”‚Swin-L   â”‚arXiv, Feb
2*â”‚hensive_Swin-L**}â”‚Image Classification Models: Benchmarking   â”‚      â”‚      â”‚         â”‚2023      
* â”‚                 â”‚and Rethinking][213]*                       â”‚      â”‚      â”‚         â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Amini2024Meanâ”‚*[MeanSparse: Post-Training Robustness      â”‚78.80%â”‚58.92%â”‚MeanSparsâ”‚arXiv, Jun
3*â”‚Sparse_Swin-L**} â”‚Enhancement Through Mean-Centered Feature   â”‚      â”‚      â”‚e Swin-L â”‚2024      
* â”‚                 â”‚Sparsification][214]*                       â”‚      â”‚      â”‚         â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Bai2024MixedNâ”‚*[MixedNUTS: Training-Free                  â”‚81.48%â”‚58.50%â”‚ConvNeXtVâ”‚TMLR, Aug 
4*â”‚UTS**}           â”‚Accuracy-Robustness Balance via Nonlinearly â”‚      â”‚      â”‚2-L +    â”‚2024      
* â”‚                 â”‚Mixed Classifiers][215]*                    â”‚      â”‚      â”‚Swin-L   â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Liu2023Compreâ”‚*[A Comprehensive Study on Robustness of    â”‚78.02%â”‚58.48%â”‚ConvNeXt-â”‚arXiv, Feb
5*â”‚hensive_ConvNeXt-â”‚Image Classification Models: Benchmarking   â”‚      â”‚      â”‚L        â”‚2023      
* â”‚L**}             â”‚and Rethinking][216]*                       â”‚      â”‚      â”‚         â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Amini2024Meanâ”‚*[MeanSparse: Post-Training Robustness      â”‚77.92%â”‚58.22%â”‚MeanSparsâ”‚arXiv, Jun
6*â”‚Sparse_ConvNeXt-Lâ”‚Enhancement Through Mean-Centered Feature   â”‚      â”‚      â”‚e        â”‚2024      
* â”‚**}              â”‚Sparsification][217]*                       â”‚      â”‚      â”‚ConvNeXt-â”‚          
  â”‚                 â”‚                                            â”‚      â”‚      â”‚L        â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Singh2023Reviâ”‚*[Revisiting Adversarial Training for       â”‚77.00%â”‚57.70%â”‚ConvNeXt-â”‚NeurIPS   
7*â”‚siting_ConvNeXt-Lâ”‚ImageNet: Architectures, Training and       â”‚      â”‚      â”‚L +      â”‚2023      
* â”‚-ConvStem**}     â”‚Generalization across Threat Models][218]*  â”‚      â”‚      â”‚ConvStem â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Liu2023Compreâ”‚*[A Comprehensive Study on Robustness of    â”‚76.16%â”‚56.16%â”‚Swin-B   â”‚arXiv, Feb
8*â”‚hensive_Swin-B**}â”‚Image Classification Models: Benchmarking   â”‚      â”‚      â”‚         â”‚2023      
* â”‚                 â”‚and Rethinking][219]*                       â”‚      â”‚      â”‚         â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Singh2023Reviâ”‚*[Revisiting Adversarial Training for       â”‚75.90%â”‚56.14%â”‚ConvNeXt-â”‚NeurIPS   
9*â”‚siting_ConvNeXt-Bâ”‚ImageNet: Architectures, Training and       â”‚      â”‚      â”‚B +      â”‚2023      
* â”‚-ConvStem**}     â”‚Generalization across Threat Models][220]*  â”‚      â”‚      â”‚ConvStem â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Xu2024MIMIR_Sâ”‚*[MIMIR: Masked Image Modeling for Mutual   â”‚76.62%â”‚55.90%â”‚Swin-B   â”‚arXiv, Dec
10â”‚win-B**}         â”‚Information-based Adversarial               â”‚      â”‚      â”‚         â”‚2023      
**â”‚                 â”‚Robustness][221]*                           â”‚      â”‚      â”‚         â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Liu2023Compreâ”‚*[A Comprehensive Study on Robustness of    â”‚76.02%â”‚55.82%â”‚ConvNeXt-â”‚arXiv, Feb
11â”‚hensive_ConvNeXt-â”‚Image Classification Models: Benchmarking   â”‚      â”‚      â”‚B        â”‚2023      
**â”‚B**}             â”‚and Rethinking][222]*                       â”‚      â”‚      â”‚         â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Singh2023Reviâ”‚*[Revisiting Adversarial Training for       â”‚76.30%â”‚54.66%â”‚ViT-B +  â”‚NeurIPS   
12â”‚siting_ViT-B-Convâ”‚ImageNet: Architectures, Training and       â”‚      â”‚      â”‚ConvStem â”‚2023      
**â”‚Stem**}          â”‚Generalization across Threat Models][223]*  â”‚      â”‚      â”‚         â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**RodriguezMunoâ”‚*[Characterizing Model Robustness via       â”‚79.36%â”‚53.82%â”‚Swin-L   â”‚arXiv, Sep
13â”‚z2024Characteriziâ”‚Natural Input Gradients][224]*              â”‚      â”‚      â”‚         â”‚2024      
**â”‚ng_Swin-L**}     â”‚                                            â”‚      â”‚      â”‚         â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Singh2023Reviâ”‚*[Revisiting Adversarial Training for       â”‚74.10%â”‚52.42%â”‚ConvNeXt-â”‚NeurIPS   
14â”‚siting_ConvNeXt-Sâ”‚ImageNet: Architectures, Training and       â”‚      â”‚      â”‚S +      â”‚2023      
**â”‚-ConvStem**}     â”‚Generalization across Threat Models][225]*  â”‚      â”‚      â”‚ConvStem â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**RodriguezMunoâ”‚*[Characterizing Model Robustness via       â”‚77.76%â”‚51.56%â”‚Swin-B   â”‚arXiv, Sep
15â”‚z2024Characteriziâ”‚Natural Input Gradients][226]*              â”‚      â”‚      â”‚         â”‚2024      
**â”‚ng_Swin-B**}     â”‚                                            â”‚      â”‚      â”‚         â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Singh2023Reviâ”‚*[Revisiting Adversarial Training for       â”‚72.72%â”‚49.46%â”‚ConvNeXt-â”‚NeurIPS   
16â”‚siting_ConvNeXt-Tâ”‚ImageNet: Architectures, Training and       â”‚      â”‚      â”‚T +      â”‚2023      
**â”‚-ConvStem**}     â”‚Generalization across Threat Models][227]*  â”‚      â”‚      â”‚ConvStem â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Peng2023Robusâ”‚*[Robust Principles: Architectural Design   â”‚73.44%â”‚48.94%â”‚RaWideResâ”‚BMVC 2023 
17â”‚t**}             â”‚Principles for Adversarially Robust         â”‚      â”‚      â”‚Net-101-2â”‚          
**â”‚                 â”‚CNNs][228]*                                 â”‚      â”‚      â”‚         â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Singh2023Reviâ”‚*[Revisiting Adversarial Training for       â”‚72.56%â”‚48.08%â”‚ViT-S +  â”‚NeurIPS   
18â”‚siting_ViT-S-Convâ”‚ImageNet: Architectures, Training and       â”‚      â”‚      â”‚ConvStem â”‚2023      
**â”‚Stem**}          â”‚Generalization across Threat Models][229]*  â”‚      â”‚      â”‚         â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Debenedetti20â”‚*[A Light Recipe to Train Robust Vision     â”‚73.76%â”‚47.60%â”‚XCiT-L12 â”‚arXiv, Sep
19â”‚22Light_XCiT-L12*â”‚Transformers][230]*                         â”‚      â”‚      â”‚         â”‚2022      
**â”‚*}               â”‚                                            â”‚      â”‚      â”‚         â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Debenedetti20â”‚*[A Light Recipe to Train Robust Vision     â”‚74.04%â”‚45.24%â”‚XCiT-M12 â”‚arXiv, Sep
20â”‚22Light_XCiT-M12*â”‚Transformers][231]*                         â”‚      â”‚      â”‚         â”‚2022      
**â”‚*}               â”‚                                            â”‚      â”‚      â”‚         â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Debenedetti20â”‚*[A Light Recipe to Train Robust Vision     â”‚72.34%â”‚41.78%â”‚XCiT-S12 â”‚arXiv, Sep
21â”‚22Light_XCiT-S12*â”‚Transformers][232]*                         â”‚      â”‚      â”‚         â”‚2022      
**â”‚*}               â”‚                                            â”‚      â”‚      â”‚         â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Chen2024Data_â”‚*[Data filtering for efficient adversarial  â”‚68.76%â”‚40.60%â”‚WideResNeâ”‚Pattern   
22â”‚WRN_50_2**}      â”‚training][233]*                             â”‚      â”‚      â”‚t-50-2   â”‚Recognitio
**â”‚                 â”‚                                            â”‚      â”‚      â”‚         â”‚n 2024    
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Mo2022When_Swâ”‚*[When Adversarial Training Meets Vision    â”‚74.66%â”‚38.30%â”‚Swin-B   â”‚NeurIPS   
23â”‚in-B**}          â”‚Transformers: Recipes from Training to      â”‚      â”‚      â”‚         â”‚2022      
**â”‚                 â”‚Architecture][234]*                         â”‚      â”‚      â”‚         â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Salman2020Do_â”‚*[Do Adversarially Robust ImageNet Models   â”‚68.46%â”‚38.14%â”‚WideResNeâ”‚NeurIPS   
24â”‚50_2**}          â”‚Transfer Better?][235]*                     â”‚      â”‚      â”‚t-50-2   â”‚2020      
**â”‚                 â”‚                                            â”‚      â”‚      â”‚         â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Salman2020Do_â”‚*[Do Adversarially Robust ImageNet Models   â”‚64.02%â”‚34.96%â”‚ResNet-50â”‚NeurIPS   
25â”‚R50**}           â”‚Transfer Better?][236]*                     â”‚      â”‚      â”‚         â”‚2020      
**â”‚                 â”‚                                            â”‚      â”‚      â”‚         â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Mo2022When_Viâ”‚*[When Adversarial Training Meets Vision    â”‚68.38%â”‚34.40%â”‚ViT-B    â”‚NeurIPS   
26â”‚T-B**}           â”‚Transformers: Recipes from Training to      â”‚      â”‚      â”‚         â”‚2022      
**â”‚                 â”‚Architecture][237]*                         â”‚      â”‚      â”‚         â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Engstrom2019Râ”‚*[Robustness library][238]*                 â”‚62.56%â”‚29.22%â”‚ResNet-50â”‚GitHub,   
27â”‚obustness**}     â”‚                                            â”‚      â”‚      â”‚         â”‚Oct 2019  
**â”‚                 â”‚                                            â”‚      â”‚      â”‚         â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Wong2020Fast*â”‚*[Fast is better than free: Revisiting      â”‚55.62%â”‚26.24%â”‚ResNet-50â”‚ICLR 2020 
28â”‚*}               â”‚adversarial training][239]*                 â”‚      â”‚      â”‚         â”‚          
**â”‚                 â”‚                                            â”‚      â”‚      â”‚         â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Salman2020Do_â”‚*[Do Adversarially Robust ImageNet Models   â”‚52.92%â”‚25.32%â”‚ResNet-18â”‚NeurIPS   
29â”‚R18**}           â”‚Transfer Better?][240]*                     â”‚      â”‚      â”‚         â”‚2020      
**â”‚                 â”‚                                            â”‚      â”‚      â”‚         â”‚          
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Standard_R50*â”‚*[Standardly trained model][241]*           â”‚76.52%â”‚0.00% â”‚ResNet-50â”‚N/A       
30â”‚*}               â”‚                                            â”‚      â”‚      â”‚         â”‚          
**â”‚                 â”‚                                            â”‚      â”‚      â”‚         â”‚          
â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

#### Corruptions (ImageNet-C & ImageNet-3DCC)

â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€
# â”‚Model ID    â”‚Paper                                               â”‚Clean  â”‚Robust â”‚Architeâ”‚Venue  
  â”‚            â”‚                                                    â”‚accuracâ”‚accuracâ”‚cture  â”‚       
  â”‚            â”‚                                                    â”‚y      â”‚y      â”‚       â”‚       
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Tian2022â”‚*[Deeper Insights into the Robustness of ViTs       â”‚81.38% â”‚67.55% â”‚DeiT   â”‚arXiv, 
1*â”‚Deeper_DeiT-â”‚towards Common Corruptions][242]*                   â”‚       â”‚       â”‚Base   â”‚Apr    
* â”‚B**}        â”‚                                                    â”‚       â”‚       â”‚       â”‚2022   
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Tian2022â”‚*[Deeper Insights into the Robustness of ViTs       â”‚79.76% â”‚62.91% â”‚DeiT   â”‚arXiv, 
2*â”‚Deeper_DeiT-â”‚towards Common Corruptions][243]*                   â”‚       â”‚       â”‚Small  â”‚Apr    
* â”‚S**}        â”‚                                                    â”‚       â”‚       â”‚       â”‚2022   
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Erichsonâ”‚*[NoisyMix: Boosting Robustness by Combining Data   â”‚76.90% â”‚53.28% â”‚ResNet-â”‚arXiv, 
3*â”‚2022NoisyMixâ”‚Augmentations, Stability Training, and Noise        â”‚       â”‚       â”‚50     â”‚Feb    
* â”‚_new**}     â”‚Injections][244]*                                   â”‚       â”‚       â”‚       â”‚2022   
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Hendryckâ”‚*[The Many Faces of Robustness: A Critical Analysis â”‚76.86% â”‚52.90% â”‚ResNet-â”‚ICCV   
4*â”‚s2020Many**}â”‚of Out-of-Distribution Generalization][245]*        â”‚       â”‚       â”‚50     â”‚2021   
* â”‚            â”‚                                                    â”‚       â”‚       â”‚       â”‚       
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Erichsonâ”‚*[NoisyMix: Boosting Robustness by Combining Data   â”‚76.98% â”‚52.47% â”‚ResNet-â”‚arXiv, 
5*â”‚2022NoisyMixâ”‚Augmentations, Stability Training, and Noise        â”‚       â”‚       â”‚50     â”‚Feb    
* â”‚**}         â”‚Injections][246]*                                   â”‚       â”‚       â”‚       â”‚2022   
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Hendryckâ”‚*[AugMix: A Simple Data Processing Method to Improveâ”‚77.34% â”‚49.33% â”‚ResNet-â”‚ICLR   
6*â”‚s2020AugMix*â”‚Robustness and Uncertainty][247]*                   â”‚       â”‚       â”‚50     â”‚2020   
* â”‚*}          â”‚                                                    â”‚       â”‚       â”‚       â”‚       
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Geirhos2â”‚*[ImageNet-trained CNNs are biased towards texture; â”‚74.98% â”‚45.76% â”‚ResNet-â”‚ICLR   
7*â”‚018_SIN_IN**â”‚increasing shape bias improves accuracy and         â”‚       â”‚       â”‚50     â”‚2019   
* â”‚}           â”‚robustness][248]*                                   â”‚       â”‚       â”‚       â”‚       
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Geirhos2â”‚*[ImageNet-trained CNNs are biased towards texture; â”‚77.56% â”‚42.00% â”‚ResNet-â”‚ICLR   
8*â”‚018_SIN_IN_Iâ”‚increasing shape bias improves accuracy and         â”‚       â”‚       â”‚50     â”‚2019   
* â”‚N**}        â”‚robustness][249]*                                   â”‚       â”‚       â”‚       â”‚       
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Geirhos2â”‚*[ImageNet-trained CNNs are biased towards texture; â”‚60.08% â”‚39.92% â”‚ResNet-â”‚ICLR   
9*â”‚018_SIN**}  â”‚increasing shape bias improves accuracy and         â”‚       â”‚       â”‚50     â”‚2019   
* â”‚            â”‚robustness][250]*                                   â”‚       â”‚       â”‚       â”‚       
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Standardâ”‚*[Standardly trained model][251]*                   â”‚76.72% â”‚39.48% â”‚ResNet-â”‚N/A    
10â”‚_R50**}     â”‚                                                    â”‚       â”‚       â”‚50     â”‚       
**â”‚            â”‚                                                    â”‚       â”‚       â”‚       â”‚       
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**Salman20â”‚*[Do Adversarially Robust ImageNet Models Transfer  â”‚68.64% â”‚36.09% â”‚WideResâ”‚NeurIPS
11â”‚20Do_50_2_Liâ”‚Better?][252]*                                      â”‚       â”‚       â”‚Net-50-â”‚2020   
**â”‚nf**}       â”‚                                                    â”‚       â”‚       â”‚2      â”‚       
â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
**â”‚^{**AlexNet*â”‚*[ImageNet Classification with Deep Convolutional   â”‚56.24% â”‚21.12% â”‚AlexNetâ”‚NeurIPS
12â”‚*}          â”‚Neural Networks][253]*                              â”‚       â”‚       â”‚       â”‚2012   
**â”‚            â”‚                                                    â”‚       â”‚       â”‚       â”‚       
â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€

## Notebooks

We host all the notebooks at Google Colab:

* [RobustBench: quick start][254]: a quick tutorial to get started that illustrates the main
  features of **`RobustBench`**.
* [RobustBench: json stats][255]: various plots based on the jsons from `model_info` (robustness
  over venues, robustness vs accuracy, etc).

Feel free to suggest a new notebook based on the **Model Zoo** or the jsons from `model_info`. We
are very interested in collecting new insights about benefits and tradeoffs between different
perturbation types.

## How to contribute

Contributions to **`RobustBench`** are very welcome! You can help to improve **`RobustBench`**:

* Are you an author of a recent paper focusing on improving adversarial robustness? Consider adding
  new models (see the instructions below ðŸ‘‡).
* Do you have in mind some better *standardized* attack? Do you want to extend **`RobustBench`** to
  other threat models? We'll be glad to discuss that!
* Do you have an idea how to make the existing codebase better? Just open a pull request or create
  an issue and we'll be happy to discuss potential changes.

## Adding a new evaluation

In case you have some new (potentially, adaptive) evaluation that leads to a *lower* robust accuracy
than AutoAttack, we will be happy to add it to the leaderboard. The easiest way is to **open an
issue with the "New external evaluation(s)" template** and fill in all the fields.

## Adding a new model

#### Public model submission (Leaderboard + Model Zoo)

The easiest way to add new models to the leaderboard and/or to the model zoo, is by **opening an
issue with the "New Model(s)" template** and fill in all the fields.

In the following sections there are some tips on how to prepare the claim.

Claim

The claim can be computed in the following way (example for `cifar10`, `Linf` threat model):

import torch

from robustbench import benchmark
from myrobust model import MyRobustModel

threat_model = "Linf"  # one of {"Linf", "L2", "corruptions"}
dataset = "cifar10"  # one of {"cifar10", "cifar100", "imagenet"}

model = MyRobustModel()
model_name = "<Name><Year><FirstWordOfTheTitle>"
device = torch.device("cuda:0")

clean_acc, robust_acc = benchmark(model, model_name=model_name, n_examples=10000, dataset=dataset,
                                  threat_model=threat_model, eps=8/255, device=device,
                                  to_disk=True)

In particular, the `to_disk` argument, if `True`, generates a json file at the path
`model_info/<dataset>/<threat_model>/<Name><Year><FirstWordOfTheTitle>.json` which is structured in
the following way (example from `model_info/cifar10/Linf/Rice2020Overfitting.json`):

{
  "link": "https://arxiv.org/abs/2002.11569",
  "name": "Overfitting in adversarially robust deep learning",
  "authors": "Leslie Rice, Eric Wong, J. Zico Kolter",
  "additional_data": false,
  "number_forward_passes": 1,
  "dataset": "cifar10",
  "venue": "ICML 2020",
  "architecture": "WideResNet-34-20",
  "eps": "8/255",
  "clean_acc": "85.34",
  "reported": "58",
  "autoattack_acc": "53.42"
}

The only difference is that the generated json will have only the fields `"clean_acc"` and
`"autoattack_acc"` (for `"Linf"` and `"L2"` threat models) or `"corruptions_acc"` (for the
`"corruptions"` threat model) already specified. The other fields have to be filled manually.

If the given `threat_model` is `corruptions`, we also save unaggregated results on the different
combinations of corruption types and severities in [this csv file][256] (for CIFAR-10).

For ImageNet benchmarks, the users should specify what preprocessing should be used (e.g. resize and
crop to the needed resolution). There are some preprocessings already defined in
[`robustbench.data.PREPROCESSINGS`][257], which can be used by specifying the key as the
`preprocessing` parameter of `benchmark`. Otherwise, it's possible to pass an arbitrary torchvision
transform (or torchvision-compatible transform), e.g.:

transform = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor()
    ])
clean_acc, robust_acc = benchmark(model, model_name=model_name, n_examples=10000, dataset=dataset,
                                  threat_model=threat_model, eps=8/255, device=device,
                                  to_disk=True, preprocessing=transform)
Model definition

In case you want to add a model in the Model Zoo by yourself, then you should also open a PR with
the new model(s) you would like to add. All the models of each `<dataset>` are saved in
`robustbench/model_zoo/<dataset>.py`. Each file contains a dictionary for every threat model, where
the keys are the identifiers of each model, and the values are either class constructors, for models
that have to change standard architectures, or `lambda` functions that return the constructed model.

If your model is a standard architecture (e.g., `WideResNet`), does not apply any normalization to
the input nor has to do things differently from the standard architecture, consider adding your
model as a lambda function, e.g.

('Cui2020Learnable_34_10', {
    'model': lambda: WideResNet(depth=34, widen_factor=10, sub_block1=True),
    'gdrive_id': '16s9pi_1QgMbFLISVvaVUiNfCzah6g2YV'
})

If your model is a standard architecture, but you need to do something differently (e.g. applying
normalization), consider inheriting the class defined in `wide_resnet.py` or `resnet.py`. For
example:

class Rice2020OverfittingNet(WideResNet):
    def __init__(self, depth, widen_factor):
        super(Rice2020OverfittingNet, self).__init__(depth=depth, widen_factor=widen_factor,
                                                     sub_block1=False)
        self.mu = torch.Tensor([0.4914, 0.4822, 0.4465]).float().view(3, 1, 1).cuda()
        self.sigma = torch.Tensor([0.2471, 0.2435, 0.2616]).float().view(3, 1, 1).cuda()

    def forward(self, x):
        x = (x - self.mu) / self.sigma
        return super(Rice2020OverfittingNet, self).forward(x)

If instead you need to create a new architecture, please put it in
`robustbench/model_zoo/archietectures/<my_architecture>.py`.

Model checkpoint

You should also add your model entry in the corresponding `<threat_model>` dict in the file
`robustbench/model_zoo/<dataset>.py`. For instance, let's say your model is robust against common
corruptions in CIFAR-10 (i.e. CIFAR-10-C), then you should add your model to the
`common_corruptions` dict in [`robustbench/model_zoo/cifar10.py`][258].

The model should also contain the *Google Drive ID* with your PyTorch model so that it can be
downloaded automatically from Google Drive:

    ('Rice2020Overfitting', {
        'model': Rice2020OverfittingNet(34, 20),
        'gdrive_id': '1vC_Twazji7lBjeMQvAD9uEQxi9Nx2oG-',
})

#### Private model submission (leaderboard only)

In case you want to keep your checkpoints private for some reasons, you can also submit your claim
by opening an issue with the same "New Model(s)" template, specifying that the submission is
private, and sharing the checkpoints with the email address `adversarial.benchmark@gmail.com`. In
this case, we will add your model to the leaderboard but not to the Model Zoo and will not share
your checkpoints publicly.

#### License of the models

By default, the models are released under the MIT license, but you can also tell us if you want to
release your model under a customized license.

## Automatic tests

In order to run the tests, run:

* `python -m unittest discover tests -t . -v` for fast testing
* `RUN_SLOW=true python -m unittest discover tests -t . -v` for slower testing

For example, one can test if the clean accuracy on 200 examples exceeds some threshold (70%) or if
clean accuracy on 10'000 examples for each model matches the ones from the jsons located at
`robustbench/model_info`.

Note that one can specify some configurations like `batch_size`, `data_dir`, `model_dir` in
`tests/config.py` for running the tests.

## Citation

Would you like to reference the **`RobustBench`** leaderboard or you are using models from the
**Model Zoo**?
Then consider citing our [whitepaper][259]:

@inproceedings{croce2021robustbench,
  title     = {RobustBench: a standardized adversarial robustness benchmark},
  author    = {Croce, Francesco and Andriushchenko, Maksym and Sehwag, Vikash and Debenedetti, Edoar
do and Flammarion, Nicolas and Chiang, Mung and Mittal, Prateek and Matthias Hein},
  booktitle = {Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchma
rks Track},
  year      = {2021},
  url       = {https://openreview.net/forum?id=SSKZPJCt7B}
}

## Contact

Feel free to contact us about anything related to **`RobustBench`** by creating an issue, a pull
request or by email at `adversarial.benchmark@gmail.com`.

[1]: https://robustbench.github.io/
[2]: https://arxiv.org/abs/2010.09670
[3]: https://3dcommoncorruptions.epfl.ch/
[4]: #new-evaluating-robustness-of-imagenet-models-against-3d-common-corruptions-imagenet-3dcc
[5]: https://github.com/RobustBench/robustbench/issues/59
[6]: https://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html
[7]: https://arxiv.org/abs/1802.00420
[8]: https://arxiv.org/abs/2002.08347
[9]: https://arxiv.org/abs/1902.06705
[10]: https://arxiv.org/abs/1902.02918
[11]: https://github.com/fra31/auto-attack/blob/master/flags_doc.md
[12]: https://robustbench.github.io/
[13]: https://github.com/fra31/auto-attack
[14]: https://github.com/fra31/auto-attack
[15]: https://robustbench.github.io/
[16]: https://www.robust-ml.org/
[17]: https://www.robust-ml.org/
[18]: https://arxiv.org/abs/2002.08347
[19]: https://arxiv.org/abs/2007.08489
[20]: https://arxiv.org/abs/2007.05869
[21]: https://arxiv.org/abs/1805.12152
[22]: https://arxiv.org/abs/1910.08640
[23]: https://arxiv.org/abs/1906.00945
[24]: https://arxiv.org/abs/1811.03194
[25]: https://arxiv.org/abs/1906.07153
[26]: https://arxiv.org/abs/1911.09665
[27]: https://arxiv.org/abs/1909.11764
[28]: https://arxiv.org/abs/2004.10934
[29]: https://arxiv.org/abs/1911.09665
[30]: https://arxiv.org/abs/1905.01034
[31]: https://arxiv.org/abs/2008.03364
[32]: https://arxiv.org/abs/1906.06316
[33]: https://arxiv.org/abs/1902.08722
[34]: https://arxiv.org/abs/2009.04131
[35]: https://colab.research.google.com/drive/1MQY_7O9vj7ixD5ilVRbdQwlNPFvxifHV
[36]: https://arxiv.org/abs/1905.13736
[37]: https://github.com/bethgelab/foolbox
[38]: https://arxiv.org/abs/2003.01690
[39]: https://arxiv.org/abs/1901.10513
[40]: https://arxiv.org/abs/1906.08988
[41]: https://3dcommoncorruptions.epfl.ch/
[42]: https://github.com/EPFL-VILAB/3DCommonCorruptions#3dcc-data
[43]: https://image-net.org/download.php
[44]: https://github.com/soumith/imagenet-multiGPU.torch#data-processing
[45]: https://github.com/hendrycks/robustness#imagenet-c
[46]: https://github.com/EPFL-VILAB/3DCommonCorruptions#3dcc-data
[47]: https://robustbench.github.io/
[48]: https://arxiv.org/abs/2404.09349
[49]: https://arxiv.org/abs/2406.05927
[50]: https://arxiv.org/abs/2404.09349
[51]: https://arxiv.org/abs/2308.16258
[52]: https://arxiv.org/abs/2302.04638
[53]: https://arxiv.org/abs/2402.02263
[54]: https://arxiv.org/abs/2406.05927
[55]: https://arxiv.org/abs/2301.12554
[56]: https://arxiv.org/abs/2305.13948
[57]: https://arxiv.org/abs/2302.04638
[58]: https://arxiv.org/abs/2103.01946
[59]: https://arxiv.org/abs/2110.09468
[60]: https://arxiv.org/abs/2010.03593
[61]: https://arxiv.org/abs/2212.11005
[62]: https://arxiv.org/abs/2103.01946
[63]: https://arxiv.org/abs/2103.01946
[64]: https://arxiv.org/abs/2110.12976
[65]: https://arxiv.org/abs/2302.03015
[66]: https://arxiv.org/abs/2110.09468
[67]: https://arxiv.org/pdf/2202.10103.pdf
[68]: https://openreview.net/forum?id=BuD2LmNaU3a
[69]: https://arxiv.org/abs/2104.09425
[70]: https://arxiv.org/abs/2010.03593
[71]: https://arxiv.org/abs/2110.03825
[72]: https://arxiv.org/abs/2110.03825
[73]: https://arxiv.org/abs/2110.05626
[74]: https://arxiv.org/pdf/2202.10103.pdf
[75]: https://openreview.net/forum?id=BuD2LmNaU3a
[76]: https://arxiv.org/abs/2103.01946
[77]: https://arxiv.org/abs/2106.02078
[78]: https://arxiv.org/abs/2104.09425
[79]: https://arxiv.org/abs/2004.05884
[80]: https://arxiv.org/abs/2106.02078
[81]: https://arxiv.org/abs/2010.01736
[82]: https://arxiv.org/abs/1905.13736
[83]: https://arxiv.org/abs/2110.09468
[84]: https://doi.org/10.1016/j.patcog.2024.110394
[85]: https://arxiv.org/abs/2210.09852
[86]: https://arxiv.org/abs/2210.15318
[87]: https://arxiv.org/abs/2111.02331
[88]: https://openreview.net/forum?id=BuD2LmNaU3a
[89]: https://arxiv.org/abs/2203.06616
[90]: https://arxiv.org/abs/2209.07399
[91]: https://doi.org/10.1016/j.patcog.2024.110394
[92]: https://arxiv.org/abs/2209.07399
[93]: https://arxiv.org/abs/2002.10509
[94]: https://arxiv.org/abs/2010.03593
[95]: https://openreview.net/forum?id=BuD2LmNaU3a
[96]: https://arxiv.org/abs/2305.13948
[97]: https://arxiv.org/abs/2111.02331
[98]: https://arxiv.org/abs/2010.03593
[99]: https://arxiv.org/abs/2103.01946
[100]: https://openreview.net/forum?id=rklOg6EFwS
[101]: https://arxiv.org/abs/2203.06616
[102]: https://arxiv.org/abs/2004.05884
[103]: https://arxiv.org/abs/2209.07399
[104]: https://arxiv.org/abs/2104.09425
[105]: https://arxiv.org/abs/1901.09960
[106]: https://arxiv.org/abs/2002.08619
[107]: https://arxiv.org/abs/2011.11164
[108]: https://arxiv.org/abs/2002.11242
[109]: https://arxiv.org/abs/2002.11569
[110]: https://arxiv.org/abs/2002.10319
[111]: https://arxiv.org/abs/1901.08573
[112]: https://arxiv.org/abs/2011.11164
[113]: https://arxiv.org/abs/2210.15318
[114]: https://arxiv.org/abs/2003.12862
[115]: https://arxiv.org/abs/2010.01278
[116]: https://arxiv.org/abs/2210.09852
[117]: https://arxiv.org/abs/2003.09347
[118]: https://github.com/MadryLab/robustness
[119]: https://arxiv.org/abs/1905.00877
[120]: https://arxiv.org/abs/2007.02617
[121]: https://arxiv.org/abs/2001.03994
[122]: https://openreview.net/forum?id=HkeryxBtPB
[123]: https://github.com/RobustBench/robustbench/
[124]: https://arxiv.org/abs/2302.04638
[125]: https://arxiv.org/abs/2406.05927
[126]: https://arxiv.org/abs/2302.04638
[127]: https://arxiv.org/abs/2103.01946
[128]: https://arxiv.org/abs/2010.03593
[129]: https://arxiv.org/abs/2103.01946
[130]: https://arxiv.org/abs/2103.01946
[131]: https://arxiv.org/abs/2003.09461
[132]: https://arxiv.org/abs/2104.09425
[133]: https://arxiv.org/abs/2003.09461
[134]: https://openreview.net/forum?id=BuD2LmNaU3a
[135]: https://arxiv.org/abs/2103.01946
[136]: https://arxiv.org/abs/2010.03593
[137]: https://arxiv.org/abs/2104.09425
[138]: https://arxiv.org/abs/2004.05884
[139]: https://arxiv.org/abs/2003.09461
[140]: https://github.com/MadryLab/robustness
[141]: https://arxiv.org/abs/2002.11569
[142]: https://arxiv.org/abs/1811.09600
[143]: https://openreview.net/forum?id=HkeryxBtPB
[144]: https://github.com/RobustBench/robustbench/
[145]: https://arxiv.org/abs/2106.09129
[146]: https://arxiv.org/abs/2106.09129
[147]: https://arxiv.org/abs/2106.09129
[148]: https://arxiv.org/abs/2103.02325
[149]: https://arxiv.org/abs/1912.02781
[150]: https://arxiv.org/abs/2112.13547
[151]: https://arxiv.org/abs/1912.02781
[152]: https://arxiv.org/abs/2103.02325
[153]: https://arxiv.org/abs/2106.09129
[154]: https://arxiv.org/abs/2103.01946
[155]: https://arxiv.org/abs/2103.02325
[156]: https://arxiv.org/abs/2103.02325
[157]: https://arxiv.org/abs/2103.02325
[158]: https://arxiv.org/abs/2103.01946
[159]: https://artofrobust.github.io/short_paper/31.pdf
[160]: https://openreview.net/forum?id=SHB_znlW5G7
[161]: https://github.com/RobustBench/robustbench/
[162]: https://arxiv.org/abs/2302.04638
[163]: https://arxiv.org/abs/2406.05927
[164]: https://arxiv.org/abs/2402.02263
[165]: https://arxiv.org/abs/2305.13948
[166]: https://arxiv.org/abs/2302.04638
[167]: https://arxiv.org/abs/2301.12554
[168]: https://arxiv.org/abs/2010.03593
[169]: https://arxiv.org/abs/2301.12554
[170]: https://arxiv.org/abs/2209.07399
[171]: https://arxiv.org/abs/2103.01946
[172]: https://arxiv.org/abs/2209.07399
[173]: https://arxiv.org/pdf/2202.10103.pdf
[174]: https://arxiv.org/abs/2305.13948
[175]: https://arxiv.org/abs/2209.07399
[176]: https://arxiv.org/abs/2103.01946
[177]: https://arxiv.org/abs/2203.06616
[178]: https://arxiv.org/abs/2305.13948
[179]: https://arxiv.org/abs/2210.15318
[180]: https://arxiv.org/abs/2011.11164
[181]: https://arxiv.org/abs/2104.09425
[182]: https://doi.org/10.1016/j.patcog.2024.110394
[183]: https://arxiv.org/pdf/2202.10103.pdf
[184]: https://arxiv.org/abs/2203.06616
[185]: https://arxiv.org/abs/2111.02331
[186]: https://arxiv.org/abs/2210.09852
[187]: https://arxiv.org/abs/2011.11164
[188]: https://arxiv.org/abs/2010.03593
[189]: https://arxiv.org/abs/2011.11164
[190]: https://openreview.net/forum?id=BuD2LmNaU3a
[191]: https://arxiv.org/abs/2004.05884
[192]: https://arxiv.org/abs/2103.01946
[193]: https://arxiv.org/abs/1901.09960
[194]: https://arxiv.org/abs/2210.15318
[195]: https://arxiv.org/abs/2011.11164
[196]: https://arxiv.org/abs/2210.09852
[197]: https://arxiv.org/abs/2010.01278
[198]: https://arxiv.org/abs/2003.09347
[199]: https://arxiv.org/abs/2002.11569
[200]: https://arxiv.org/abs/2106.09129
[201]: https://arxiv.org/abs/2106.09129
[202]: https://arxiv.org/abs/2112.13547
[203]: https://arxiv.org/abs/2106.09129
[204]: https://arxiv.org/abs/2106.09129
[205]: https://arxiv.org/abs/1912.02781
[206]: https://arxiv.org/abs/1912.02781
[207]: https://artofrobust.github.io/short_paper/31.pdf
[208]: https://arxiv.org/abs/2010.03593
[209]: https://openreview.net/forum?id=SHB_znlW5G7
[210]: https://openreview.net/forum?id=SHB_znlW5G7
[211]: https://arxiv.org/abs/2010.03593
[212]: https://arxiv.org/abs/2312.04960
[213]: https://arxiv.org/abs/2302.14301
[214]: https://arxiv.org/abs/2406.05927
[215]: https://arxiv.org/abs/2402.02263
[216]: https://arxiv.org/abs/2302.14301
[217]: https://arxiv.org/abs/2406.05927
[218]: https://arxiv.org/abs/2303.01870
[219]: https://arxiv.org/abs/2302.14301
[220]: https://arxiv.org/abs/2303.01870
[221]: https://arxiv.org/abs/2312.04960
[222]: https://arxiv.org/abs/2302.14301
[223]: https://arxiv.org/abs/2303.01870
[224]: https://arxiv.org/abs/2409.20139
[225]: https://arxiv.org/abs/2303.01870
[226]: https://arxiv.org/abs/2409.20139
[227]: https://arxiv.org/abs/2303.01870
[228]: https://arxiv.org/abs/2308.16258
[229]: https://arxiv.org/abs/2303.01870
[230]: https://arxiv.org/abs/2209.07399
[231]: https://arxiv.org/abs/2209.07399
[232]: https://arxiv.org/abs/2209.07399
[233]: https://doi.org/10.1016/j.patcog.2024.110394
[234]: https://arxiv.org/abs/2210.07540
[235]: https://arxiv.org/abs/2007.08489
[236]: https://arxiv.org/abs/2007.08489
[237]: https://arxiv.org/abs/2210.07540
[238]: https://github.com/MadryLab/robustness
[239]: https://arxiv.org/abs/2001.03994
[240]: https://arxiv.org/abs/2007.08489
[241]: https://github.com/RobustBench/robustbench/
[242]: https://arxiv.org/abs/2204.12143
[243]: https://arxiv.org/abs/2204.12143
[244]: https://arxiv.org/pdf/2202.01263.pdf
[245]: https://arxiv.org/abs/2006.16241
[246]: https://arxiv.org/pdf/2202.01263.pdf
[247]: https://arxiv.org/abs/1912.02781
[248]: https://arxiv.org/abs/1811.12231
[249]: https://arxiv.org/abs/1811.12231
[250]: https://arxiv.org/abs/1811.12231
[251]: https://github.com/RobustBench/robustbench/
[252]: https://arxiv.org/abs/2007.08489
[253]: https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html
[254]: https://colab.research.google.com/drive/1MQY_7O9vj7ixD5ilVRbdQwlNPFvxifHV
[255]: https://colab.research.google.com/drive/19tgblr13SvaCpG8hoOTv6QCULVJbCec6
[256]: /RobustBench/robustbench/blob/master/model_info/cifar10/corruptions/unaggregated_results.csv
[257]: https://github.com/RobustBench/robustbench/blob/imagenet-preprocessing/robustbench/data.py#L1
8
[258]: /RobustBench/robustbench/blob/master/robustbench/model_zoo/cifar10.py
[259]: https://arxiv.org/abs/2010.09670
