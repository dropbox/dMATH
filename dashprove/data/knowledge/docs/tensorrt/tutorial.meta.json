{
  "tool_id": "tensorrt",
  "tool_name": "NVIDIA TensorRT",
  "source_url": "https://docs.nvidia.com/deeplearning/tensorrt/quick-start-guide/",
  "doc_type": "tutorial",
  "fetched_at": "2025-12-23T04:30:03.451200+00:00",
  "http_status": 200,
  "content_type_header": "text/html",
  "word_count": 3672,
  "sections": [
    "Quick Start Guide#",
    "Introduction#",
    "Installing TensorRT#",
    "Container Installation#",
    "Debian Installation#",
    "Python Package Index Installation#",
    "The TensorRT Ecosystem#",
    "Basic TensorRT Workflow#",
    "Conversion and Deployment Options#",
    "Selecting the Correct Workflow#",
    "Example Deployment Using ONNX#",
    "Export the Model#",
    "Select a Precision#",
    "Convert the Model#",
    "Deploy the Model#",
    "ONNX Conversion and Deployment#",
    "Exporting with ONNX#",
    "Converting ONNX to a TensorRT Engine#",
    "Deploying a TensorRT Engine to the Python Runtime API#",
    "Using the TensorRT Runtime API#",
    "Setting Up the Test Container and Building the TensorRT Engine#",
    "Running an Engine in C++#",
    "Running an Engine in Python#"
  ],
  "code_block_count": 24
}