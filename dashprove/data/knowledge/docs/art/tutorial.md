[ Trusted-AI ][1] / ** [adversarial-robustness-toolbox][2] ** Public

* [ Notifications ][3] You must be signed in to change notification settings
* [ Fork 1.3k ][4]
* [ Star 5.7k ][5]

* [ Code ][6]
* [ Issues 2 ][7]
* [ Pull requests 11 ][8]
* [ Discussions ][9]
* [ Actions ][10]
* [ Projects 1 ][11]
* [ Wiki ][12]
* [ Security ][13]
  [
  
  ### Uh oh!
  
  
  ][14]
* [ Insights ][15]
Additional navigation options

* [ Code ][16]
* [ Issues ][17]
* [ Pull requests ][18]
* [ Discussions ][19]
* [ Actions ][20]
* [ Projects ][21]
* [ Wiki ][22]
* [ Security ][23]
* [ Insights ][24]

# Home

[Jump to bottom][25]
Beat Buesser edited this page May 21, 2021 Â· [21 revisions][26]

**Welcome to the Adversarial Robustness Toolbox**

Adversarial Robustness Toolbox (ART) is a Python library for Machine Learning Security. ART provides
tools that enable developers and researchers to evaluate, defend, certify and verify Machine
Learning models and applications against the adversarial threats of Evasion, Poisoning, Extraction,
and Inference. ART supports all popular machine learning frameworks (TensorFlow, Keras, PyTorch,
MXNet, scikit-learn, XGBoost, LightGBM, CatBoost, GPy, etc.), all data types (images, tables, audio,
video, etc.) and machine learning tasks (classification, object detection, speech recognition,
generation, certification, etc.).

## Adversarial Threats


## ART for Red and Blue Teams (selection)


## Supported Machine Learning Libraries

* TensorFlow (v1 and v2) ([www.tensorflow.org][27])
* Keras ([www.keras.io][28])
* PyTorch ([www.pytorch.org][29])
* MXNet ([https://mxnet.apache.org][30])
* Scikit-learn ([www.scikit-learn.org][31])
* XGBoost ([www.xgboost.ai][32])
* LightGBM ([https://lightgbm.readthedocs.io][33])
* CatBoost ([www.catboost.ai][34])
* GPy ([https://sheffieldml.github.io/GPy/][35])

## Toggle table of contents Pages 15

* Loading [
  Home
  ][36]
  
  * [Adversarial Threats][37]
  * [ART for Red and Blue Teams (selection)][38]
  * [Supported Machine Learning Libraries][39]
* Loading [
  ART Architecture and Roadmap
  ][40]
  
  ### Uh oh!
  
  
  There was an error while loading. [Please reload this page][41].
* Loading [
  ART Attacks
  ][42]
  
  ### Uh oh!
  
  
  There was an error while loading. [Please reload this page][43].
* Loading [
  ART Defences
  ][44]
  
  ### Uh oh!
  
  
  There was an error while loading. [Please reload this page][45].
* Loading [
  ART Docker Images
  ][46]
  
  ### Uh oh!
  
  
  There was an error while loading. [Please reload this page][47].
* Loading [
  ART Estimators
  ][48]
  
  ### Uh oh!
  
  
  There was an error while loading. [Please reload this page][49].
* Loading [
  ART Expectation over Transformation (EoT)
  ][50]
  
  ### Uh oh!
  
  
  There was an error while loading. [Please reload this page][51].
* Loading [
  ART Metrics
  ][52]
  
  ### Uh oh!
  
  
  There was an error while loading. [Please reload this page][53].
* Loading [
  ART Summary Writer
  ][54]
  
  ### Uh oh!
  
  
  There was an error while loading. [Please reload this page][55].
* Loading [
  ART Unit Testing
  ][56]
  
  ### Uh oh!
  
  
  There was an error while loading. [Please reload this page][57].
* Loading [
  Code Reviews
  ][58]
  
  ### Uh oh!
  
  
  There was an error while loading. [Please reload this page][59].
* Loading [
  Contributing
  ][60]
  
  ### Uh oh!
  
  
  There was an error while loading. [Please reload this page][61].
* Loading [
  FAQ
  ][62]
  
  ### Uh oh!
  
  
  There was an error while loading. [Please reload this page][63].
* Loading [
  Get Started
  ][64]
  
  ### Uh oh!
  
  
  There was an error while loading. [Please reload this page][65].
* Loading [
  Releasing ART
  ][66]
  
  ### Uh oh!
  
  
  There was an error while loading. [Please reload this page][67].

### Clone this wiki locally

[1]: /Trusted-AI
[2]: /Trusted-AI/adversarial-robustness-toolbox
[3]: /login?return_to=%2FTrusted-AI%2Fadversarial-robustness-toolbox
[4]: /login?return_to=%2FTrusted-AI%2Fadversarial-robustness-toolbox
[5]: /login?return_to=%2FTrusted-AI%2Fadversarial-robustness-toolbox
[6]: /Trusted-AI/adversarial-robustness-toolbox
[7]: /Trusted-AI/adversarial-robustness-toolbox/issues
[8]: /Trusted-AI/adversarial-robustness-toolbox/pulls
[9]: /Trusted-AI/adversarial-robustness-toolbox/discussions
[10]: /Trusted-AI/adversarial-robustness-toolbox/actions
[11]: /Trusted-AI/adversarial-robustness-toolbox/projects
[12]: /Trusted-AI/adversarial-robustness-toolbox/wiki
[13]: /Trusted-AI/adversarial-robustness-toolbox/security
[14]: /Trusted-AI/adversarial-robustness-toolbox/security
[15]: /Trusted-AI/adversarial-robustness-toolbox/pulse
[16]: /Trusted-AI/adversarial-robustness-toolbox
[17]: /Trusted-AI/adversarial-robustness-toolbox/issues
[18]: /Trusted-AI/adversarial-robustness-toolbox/pulls
[19]: /Trusted-AI/adversarial-robustness-toolbox/discussions
[20]: /Trusted-AI/adversarial-robustness-toolbox/actions
[21]: /Trusted-AI/adversarial-robustness-toolbox/projects
[22]: /Trusted-AI/adversarial-robustness-toolbox/wiki
[23]: /Trusted-AI/adversarial-robustness-toolbox/security
[24]: /Trusted-AI/adversarial-robustness-toolbox/pulse
[25]: #wiki-pages-box
[26]: /Trusted-AI/adversarial-robustness-toolbox/wiki/Home/_history
[27]: http://www.tensorflow.org
[28]: http://www.keras.io
[29]: http://www.pytorch.org
[30]: https://mxnet.apache.org
[31]: http://www.scikit-learn.org
[32]: http://www.xgboost.ai
[33]: https://lightgbm.readthedocs.io
[34]: http://www.catboost.ai
[35]: https://sheffieldml.github.io/GPy/
[36]: /Trusted-AI/adversarial-robustness-toolbox/wiki
[37]: /Trusted-AI/adversarial-robustness-toolbox/wiki#adversarial-threats
[38]: /Trusted-AI/adversarial-robustness-toolbox/wiki#art-for-red-and-blue-teams-selection
[39]: /Trusted-AI/adversarial-robustness-toolbox/wiki#supported-machine-learning-libraries
[40]: /Trusted-AI/adversarial-robustness-toolbox/wiki/ART-Architecture-and-Roadmap
[41]: 
[42]: /Trusted-AI/adversarial-robustness-toolbox/wiki/ART-Attacks
[43]: 
[44]: /Trusted-AI/adversarial-robustness-toolbox/wiki/ART-Defences
[45]: 
[46]: /Trusted-AI/adversarial-robustness-toolbox/wiki/ART-Docker-Images
[47]: 
[48]: /Trusted-AI/adversarial-robustness-toolbox/wiki/ART-Estimators
[49]: 
[50]: /Trusted-AI/adversarial-robustness-toolbox/wiki/ART-Expectation-over-Transformation-(EoT)
[51]: 
[52]: /Trusted-AI/adversarial-robustness-toolbox/wiki/ART-Metrics
[53]: 
[54]: /Trusted-AI/adversarial-robustness-toolbox/wiki/ART-Summary-Writer
[55]: 
[56]: /Trusted-AI/adversarial-robustness-toolbox/wiki/ART-Unit-Testing
[57]: 
[58]: /Trusted-AI/adversarial-robustness-toolbox/wiki/Code-Reviews
[59]: 
[60]: /Trusted-AI/adversarial-robustness-toolbox/wiki/Contributing
[61]: 
[62]: /Trusted-AI/adversarial-robustness-toolbox/wiki/FAQ
[63]: 
[64]: /Trusted-AI/adversarial-robustness-toolbox/wiki/Get-Started
[65]: 
[66]: /Trusted-AI/adversarial-robustness-toolbox/wiki/Releasing-ART
[67]: 
