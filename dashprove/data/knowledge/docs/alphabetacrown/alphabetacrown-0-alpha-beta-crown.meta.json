{
  "id": "alphabetacrown-0-alpha-beta-crown",
  "source": "https://github.com/Verified-Intelligence/alpha-beta-CROWN",
  "backend": "AlphaBetaCrown",
  "title": "GitHub - Verified-Intelligence/alpha-beta-CROWN: alpha-beta-CROWN: An Efficient, Scalable and GPU Accelerated Neural Network Verifier (winner of VNN-COMP 2021, 2022, 2023, 2024, 2025)",
  "content": "# α,β-CROWN (alpha-beta-CROWN): A Fast and Scalable Neural Network Verifier with\n# Efficient Bound Propagation\n\n\nα,β-CROWN (alpha-beta-CROWN) is a neural network verifier based on an efficient\nlinear bound propagation framework and branch and bound. It can be accelerated\nefficiently on **GPUs** and can scale to relatively large convolutional networks\n(e.g., millions of parameters). It also supports a wide range of neural network\narchitectures (e.g., **CNN**, **ResNet**, and various activation functions),\nthanks to the versatile **[auto_LiRPA][1] library developed by us**. α,β-CROWN\ncan provide provable robustness guarantees against adversarial attacks and can\nalso verify other general properties of neural networks, such as [Lyapunov\nstability][2] in control.\n\nα,β-CROWN is the **winning verifier** in [VNN-COMP 2021][3], [VNN-COMP 2022][4],\n[VNN-COMP 2023][5], [VNN-COMP 2024][6], and [VNN-COMP 2025][7] (International\nVerification of Neural Networks Competition) with the highest total score,\noutperforming many other neural network verifiers on a wide range of benchmarks\nover 5 years. Details of competition results can be found in [VNN-COMP 2021\nslides][8], [report][9], [VNN-COMP 2022 report][10], [VNN-COMP 2023 slides][11]\nand [report][12], and [VNN-COMP 2024 slides][13] and [report][14], [VNN-COMP\n2025 slides][15].\n\nThe α,β-CROWN team is created and led by Prof. [Huan Zhang][16] at UIUC with\ncontributions from multiple institutions. See the **list of contributors**\n[below][17]. α,β-CROWN combines our efforts in neural network verification in a\nseries of papers building up the bound propagation framework since 2018. See\n[Publications][18] below.\n\n## News (2025 - )\n\n* α,β-CROWN now provides a **new Python API** that allows users to run the\n  verifier programmatically in Python **without** manually exporting ONNX\n  models, writing VNNLIB specifications, or preparing config files. A good set\n  of **default configuration automatically handles diverse verification\n  scenarios**, while all options remain fully customizable through the API.\n  (**See [API documentation][19]**).\n* α,β-CROWN is the winner of [VNN-COMP 2025][20] and is **ranked top-1** in all\n  [scored benchmarks][21]. (08/2025)\n* Bounding of computation graphs containing Jacobian operators now supports more\n  nonlinear operators (e.g., `tanh`, `sigmoid`), enabling verification of\n  [continuous-time Lyapunov stability][22]. (12/2025)\n* Clip-and-Verify ([Zhou et al., NeurIPS 2025][23]) efficiently handles linear\n  constraints and can significantly reduce the number of subproblems handled\n  during BaB. It consistently tightens bounds across multiple benchmarks.\n  (12/2025)\n\n## Supported Features\n\n\nOur verifier consists of the following core algorithms:\n\n* **CROWN** ([Zhang et al., 2018][24]): the basic linear bound propagation\n  framework for neural networks.\n* **auto_LiRPA** ([Xu et al. 2020][25]): linear bound propagation for general\n  computational graphs.\n* **α-CROWN** ([Xu et al., 2021][26]): incomplete verification with gradient\n  optimized bound propagation.\n* **β-CROWN** ([Wang et al., 2021][27]): complete verification with bound\n  propagation and branch and bound for ReLU networks.\n* **GenBaB** ([Shi et al., 2024][28]): Branch and bound for general nonlinear\n  functions.\n* **GCP-CROWN** ([Zhang et al., 2022][29]): CROWN-like bound propagation with\n  general cutting plane constraints.\n* **BaB-Attack** ([Zhang et al., 2022][30]): Branch and bound based adversarial\n  attack for tackling hard instances.\n* **MIP** ([Tjeng et al., 2017][31]): mixed integer programming (slow but can be\n  useful on small models).\n* **INVPROP** ([Kotha et al., 2023][32]): tightens bounds with constraints on\n  model outputs, and computes provable preimages for neural networks.\n* **BICCOS** ([Zhou et al., 2024][33]): an effective cutting plane generation\n  method outperforming the MIP-based cuts in GCP-CROWN.\n\nThe bound propagation engine in α,β-CROWN is implemented as a separate library,\n**[auto_LiRPA][34] ([Xu et al. 2020][35])**, for computing symbolic bounds for\ngeneral computational graphs. We support these neural network architectures:\n\n* Layers: fully connected (FC), convolutional (CNN), pooling (average pool and\n  max pool), transposed convolution\n* Activation functions or nonlinear functions: ReLU, sigmoid, tanh, arctan, sin,\n  cos, tan, gelu, pow, multiplication and self-attention\n* Residual connections, Transformers, LSTMs, and other irregular graphs\n\nWe support the following verification specifications:\n\n* Lp norm perturbation (p=1,2,infinity, as often used in robustness\n  verification)\n* VNNLIB format input (at most two layers of AND/OR clause, as used in VNN-COMP)\n* Any linear specifications on neural network output (which can be added as a\n  linear layer)\n\nWe provide many example configurations in [`complete_verifier/exp_configs`][36]\ndirectory to start with:\n\n* MNIST: MLP and CNN models (small models to help you get started)\n* CIFAR-10, CIFAR-100, TinyImageNet: CNN and ResNet models with high dimensional\n  inputs\n* ACASXu, NN4sys, ML4ACOPF and other low input dimension models\n\nAnd more examples in other repositories:\n\n* Stability verification of NN controllers for discrete-time systems:\n  [Verified-Intelligence/Lyapunov_Stable_NN_Controllers][37] and continuous-time\n  systems: [Verified-Intelligence/Two-Stage_Neural_Controller_Training][38].\n* Branch-and-bound for models with non-ReLU nonlinearities and high dimensional\n  inputs: [GenBaB][39]\n\nSee the [Guide on Algorithm Selection][40] to find the most suitable example to\nget started.\n\n## Installation and Setup\n\nα,β-CROWN is tested on Python 3.11 and PyTorch 2.8.0 (recent versions may also\nwork). It can be installed easily into a conda environment. If you don't have\nconda, you can install [miniconda][41].\n\nClone our verifier including the [auto_LiRPA][42] submodule:\n\ngit clone --recursive https://github.com/Verified-Intelligence/alpha-beta-CROWN.\ngit\n\nSetup the conda environment from [`environment.yaml`][43] with pinned\ndependencies versions (CUDA>=12.8 is required):\n\n# Remove the old environment, if necessary.\nconda deactivate; conda env remove --name alpha-beta-crown\n# install all dependents into the alpha-beta-crown environment\nconda env create -f complete_verifier/environment.yaml --name alpha-beta-crown\n# activate the environment\nconda activate alpha-beta-crown\n\nAlternatively, you may use `pip` (if you want to add α,β-CROWN to your existing\nenvironment, or if your system is not compatible with [`environment.yaml`][44]).\nIt is highly recommended to have a pre-installed PyTorch that matches your\nsystem and our version requirement (see [PyTorch Get Started][45]). Then, you\ncan run:\n\n(cd auto_LiRPA; pip install -e .)\npip install -r complete_verifier/requirements.txt\n\nUnless you use MIP-based verification algorithms, a Gurobi license is *not\nneeded* (in most use cases). If you want to use MIP-based verification\nalgorithms (which are feasible only for small models), you need to install a\nGurobi license with the `grbgetkey` command. If you don't have access to a\nlicense, by default, the above installation procedure includes a free and\nrestricted license, which is actually sufficient for many relatively small NNs.\nIf you use the GCP-CROWN verifier, an installation of IBM CPlex solver is\nrequired. Instructions to install the CPlex solver can be found in the [VNN-COMP\nbenchmark instructions][46].\n\nIf you want to run α,β-CROWN verifier on the VNN-COMP benchmarks (e.g., to make\na comparison to a new verifier), you can follow [this guide][47].\n\n## Instructions\n\nThe verifier can be invoked through the **[new Python API][48]** or through the\ncommand-line interface with configuration files. Checkout the [API\ndocumentation][49] for API usage. For the command-line interface, we provide a\nunified front-end for the verifier, `abcrown.py`. All parameters for the\nverifier are defined in a `yaml` config file. For example, to run robustness\nverification on a CIFAR-10 ResNet network, you just run:\n\nconda activate alpha-beta-crown  # activate the conda environment\ncd complete_verifier\npython abcrown.py --config exp_configs/tutorial_examples/cifar_resnet_2b.yaml\n\nYou can find explanations for the most useful parameters in [this example config\nfile][50]. For detailed usage and tutorial examples, please see the [Usage\nDocumentation][51]. We also provide a large range of examples in the\n[`complete_verifier/exp_configs`][52] folder.\n\n## Publications\n\nIf you use our verifier in your work, **please kindly cite our papers**:\n\n* **CROWN** ([Zhang et al., 2018][53]), **auto_LiRPA** ([Xu et al., 2020][54]),\n  **α-CROWN** ([Xu et al., 2021][55]), **β-CROWN** ([Wang et al., 2021][56]),\n  **GenBaB** ([Shi et al. 2024][57]), **GCP-CROWN** ([Zhang et al., 2022][58]),\n  and **BICCOS** ([Zhou et al., NeurIPS 2024][59]).\n* **[Kotha et al., 2023][60]** if you use constraints on the outputs of neural\n  networks.\n* **[Salman et al., 2019][61]**, if your work involves the convex relaxation of\n  the NN verification.\n* **[Zhang et al. 2022][62]**, if you use our branch-and-bound based adversarial\n  attack (falsifier). We provide bibtex entries at the end of this section.\n\nα,β-CROWN represents our continued efforts on neural network verification:\n\n* **CROWN** ([Zhang et al. NeurIPS 2018][63]) is a very efficient bound\n  propagation based verification algorithm. CROWN propagates a linear inequality\n  backward through the network and utilizes linear bounds to relax activation\n  functions.\n* The **\"convex relaxation barrier\"** ([Salman et al., NeurIPS 2019][64]) paper\n  concludes that optimizing the ReLU relaxation allows CROWN (referred to as a\n  \"greedy\" primal space solver) to achieve the same solution as linear\n  programming (LP) based verifiers.\n* **auto_LiRPA** ([Xu et al., NeurIPS 2020][65]) is a generalization of CROWN on\n  general computational graphs and we also provide an efficient GPU\n  implementation, the [auto_LiRPA][66] library.\n* **α-CROWN** (sometimes referred to as optimized CROWN or optimized LiRPA) is\n  used in the Fast-and-Complete verifier ([Xu et al., ICLR 2021][67]), which\n  jointly optimizes intermediate layer bounds and final layer bounds in CROWN\n  via variable α. α-CROWN typically has greater power than LP since LP cannot\n  cheaply tighten intermediate layer bounds.\n* **β-CROWN** ([Wang et al., NeurIPS 2021][68]) incorporates ReLU split\n  constraints in branch and bound (BaB) into the CROWN bound propagation\n  procedure via an additional optimizable parameter β. The combination of\n  efficient and GPU-accelerated bound propagation with branch and bound produces\n  a powerful and scalable neural network verifier.\n* **BaB-Attack** ([Zhang et al., ICML 2022][69]) is a strong falsifier\n  (adversarial attack) based on branch and bound, which can find adversarial\n  examples for hard instances where gradient or input-space-search based methods\n  cannot succeed.\n* **GCP-CROWN** ([Zhang et al., NeurIPS 2022][70]) enables the use of general\n  cutting planes methods for neural network verification in a GPU-accelerated\n  and very efficient bound propagation framework. Cutting planes can\n  significantly strengthen bound tightness.\n* **INVPROP** ([Kotha et al., NeurIPS 2023][71]) handles constraints on the\n  outputs of neural networks which enables tight and provable bounds on the\n  preimage of a neural network. We demonstrated several applications, including\n  OOD detection, backward reachability analysis for NN-controlled systems, and\n  tightening bounds for robustness verification.\n* **BICCOS** ([Zhou et al., NeurIPS 2024][72]) generates effective cutting\n  planes during branch-and-bound to tighten verification bounds. The cutting\n  plane generation process is efficient and scalable and does not require a MIP\n  solver.\n* **GenBaB** ([Shi et al., TACAS 2025][73]) enables branch-and-bound based\n  verification for general nonlinear functions, achieving significant\n  improvements on verifying neural networks with non-ReLU nonlinearties (such as\n  Transformers), and enabling new applications that contain complicated\n  nonlinear functions on the output of neural networks, such as [ML for AC\n  Optimal Power Flow][74].\n* **Clip-and-Verify** ([Zhou et al., NeurIPS 2025][75]) efficiently handles\n  linear constraints and can significantly reduce the number of subproblems\n  handled during BaB. It consistently tightens bounds across multiple\n  benchmarks, significantly accelerating challenging verification tasks from\n  research on [provably stable neural network control systems][76].\n`@article{zhang2018efficient,\n  title={Efficient Neural Network Robustness Certification with General Activati\non Functions},\n  author={Zhang, Huan and Weng, Tsui-Wei and Chen, Pin-Yu and Hsieh, Cho-Jui and\n Daniel, Luca},\n  journal={Advances in Neural Information Processing Systems},\n  volume={31},\n  pages={4939--4948},\n  year={2018},\n  url={https://arxiv.org/pdf/1811.00866.pdf}\n}\n\n@article{xu2020automatic,\n  title={Automatic perturbation analysis for scalable certified robustness and b\neyond},\n  author={Xu, Kaidi and Shi, Zhouxing and Zhang, Huan and Wang, Yihan and Chang,\n Kai-Wei and Huang, Minlie and Kailkhura, Bhavya and Lin, Xue and Hsieh, Cho-Jui\n},\n  journal={Advances in Neural Information Processing Systems},\n  volume={33},\n  year={2020}\n}\n\n@article{salman2019convex,\n  title={A Convex Relaxation Barrier to Tight Robustness Verification of Neural \nNetworks},\n  author={Salman, Hadi and Yang, Greg and Zhang, Huan and Hsieh, Cho-Jui and Zha\nng, Pengchuan},\n  journal={Advances in Neural Information Processing Systems},\n  volume={32},\n  pages={9835--9846},\n  year={2019}\n}\n\n@inproceedings{xu2021fast,\n    title={{Fast and Complete}: Enabling Complete Neural Network Verification wi\nth Rapid and Massively Parallel Incomplete Verifiers},\n    author={Kaidi Xu and Huan Zhang and Shiqi Wang and Yihan Wang and Suman Jana\n and Xue Lin and Cho-Jui Hsieh},\n    booktitle={International Conference on Learning Representations},\n    year={2021},\n    url={https://openreview.net/forum?id=nVZtXBI6LNn}\n}\n\n@article{wang2021beta,\n  title={{Beta-CROWN}: Efficient bound propagation with per-neuron split constra\nints for complete and incomplete neural network verification},\n  author={Wang, Shiqi and Zhang, Huan and Xu, Kaidi and Lin, Xue and Jana, Suman\n and Hsieh, Cho-Jui and Kolter, J Zico},\n  journal={Advances in Neural Information Processing Systems},\n  volume={34},\n  year={2021}\n}\n\n@InProceedings{zhang22babattack,\n  title =        {A Branch and Bound Framework for Stronger Adversarial Attacks \nof {R}e{LU} Networks},\n  author =       {Zhang, Huan and Wang, Shiqi and Xu, Kaidi and Wang, Yihan and \nJana, Suman and Hsieh, Cho-Jui and Kolter, Zico},\n  booktitle =    {Proceedings of the 39th International Conference on Machine Le\narning},\n  volume =       {162},\n  pages =        {26591--26604},\n  year =         {2022},\n}\n\n@article{zhang2022general,\n  title={General Cutting Planes for Bound-Propagation-Based Neural Network Verif\nication},\n  author={Zhang, Huan and Wang, Shiqi and Xu, Kaidi and Li, Linyi and Li, Bo and\n Jana, Suman and Hsieh, Cho-Jui and Kolter, J Zico},\n  journal={Advances in Neural Information Processing Systems},\n  year={2022}\n}\n\n@inproceedings{kotha2023provably,\n author = {Kotha, Suhas and Brix, Christopher and Kolter, J. Zico and Dvijotham,\n Krishnamurthy and Zhang, Huan},\n booktitle = {Advances in Neural Information Processing Systems},\n editor = {A. Oh and T. Neumann and A. Globerson and K. Saenko and M. Hardt and \nS. Levine},\n pages = {80270--80290},\n publisher = {Curran Associates, Inc.},\n title = {Provably Bounding Neural Network Preimages},\n url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/fe061ec0ae03c\n5cf5b5323a2b9121bfd-Paper-Conference.pdf},\n volume = {36},\n year = {2023}\n}\n\n@inproceedings{zhou2024scalable,\n  title={Scalable Neural Network Verification with Branch-and-bound Inferred Cut\nting Planes},\n  author={Zhou, Duo and Brix, Christopher and Hanasusanto, Grani A and Zhang, Hu\nan},\n  booktitle={The Thirty-eighth Annual Conference on Neural Information Processin\ng Systems},\n  year={2024}\n}\n\n@inproceedings{shi2024genbab,\n  title={Neural Network Verification with Branch-and-Bound for General Nonlinear\nities},\n  author={Shi, Zhouxing and Jin, Qirui and Kolter, Zico and Jana, Suman and Hsie\nh, Cho-Jui and Zhang, Huan},\n  booktitle={International Conference on Tools and Algorithms for the Constructi\non and Analysis of Systems},\n  year={2025}\n}\n\n@inproceedings{zhou2025clip,\n  title={Clip-and-Verify: Linear Constraint-Driven Domain Clipping for Accelerat\ning Neural Network Verification},\n  author={Zhou, Duo and Chavez, Jorge and Chen, Hesun and Hanasusanto, Grani A a\nnd Zhang, Huan},\n  booktitle={The Thirty-ninth Annual Conference on Neural Information Processing\n Systems},\n  year={2025}\n}\n`\n\n## Developers and Copyright\n\nTeam leaders:\n\n* Faculty: Huan Zhang ([huan@huan-zhang.com][77]), UIUC\n* Student: Xiangru Zhong ([xiangru4@illinois.edu][78]), UIUC\n\nCurrent developers (* indicates members of VNN-COMP 2025 team):\n\n* *Duo Zhou ([duozhou2@illinois.edu][79]), UIUC\n* *Keyi Shen ([keyis2@illinois.edu][80]), UIUC (graduated, now at Georgia Tech)\n* *Hesun Chen ([hesunc2@illinois.edu][81]), UIUC\n* *Haoyu Li ([haoyuli5@illinois.edu][82]), UIUC\n* *Ruize Gao ([ruizeg2@illinois.edu][83]), UIUC\n* *Hao Cheng ([haoc539@illinois.edu][84]), UIUC\n* Zhouxing Shi ([zhouxingshichn@gmail.com][85]), UCLA/UC Riverside\n* Lei Huang ([leih5@illinois.edu][86]), UIUC\n* Taobo Liao ([taobol2@illinois.edu][87]), UIUC\n* Jorge Chavez ([jorgejc2@illinois.edu][88]), UIUC\n\nPast developers:\n\n* Hongji Xu ([hx84@duke.edu][89]), Duke University (intern with Prof. Huan\n  Zhang)\n* Christopher Brix ([brix@cs.rwth-aachen.de][90]), RWTH Aachen University\n* Hao Chen ([haoc8@illinois.edu][91]), UIUC\n* Keyu Lu ([keyulu2@illinois.edu][92]), UIUC\n* Kaidi Xu ([kx46@drexel.edu][93]), Drexel University\n* Sanil Chawla ([schawla7@illinois.edu][94]), UIUC\n* Linyi Li ([linyi2@illinois.edu][95]), UIUC\n* Zhuolin Yang ([zhuolin5@illinois.edu][96]), UIUC\n* Zhuowen Yuan ([realzhuowen@gmail.com][97]), UIUC\n* Qirui Jin ([qiruijin@umich.edu][98]), University of Michigan\n* Shiqi Wang ([sw3215@columbia.edu][99]), Columbia University\n* Yihan Wang ([yihanwang@ucla.edu][100]), UCLA\n* Jinqi (Kathryn) Chen ([jinqic@cs.cmu.edu][101]), CMU\n\nα,β-CROWN is currently supported in part by the National Science Foundation\n(NSF; award 2331967, 2525287), the AI2050 program at Schmidt Science, the\nVirtual Institute for Scientific Software (VISS) at Georgia Tech, the University\nResearch Program at Toyota Research Institute (TRI), and a Mathworks research\naward.\n\nThe team acknowledges the financial and advisory support (2021 - 2023) from\nProf. Zico Kolter ([zkolter@cs.cmu.edu][102]), Prof. Cho-Jui Hsieh\n([chohsieh@cs.ucla.edu][103]), Prof. Suman Jana ([suman@cs.columbia.edu][104]),\nProf. Bo Li ([lbo@illinois.edu][105]), and Prof. Xue Lin\n([xue.lin@northeastern.edu][106]) during the years 2021 - 2023.\n\nOur library is released under the BSD 3-Clause license. A copy of the license is\nincluded [here][107].\n\n[1]: http://github.com/Verified-Intelligence/auto_LiRPA\n[2]: https://arxiv.org/pdf/2404.07956\n[3]: https://sites.google.com/view/vnn2021\n[4]: https://sites.google.com/view/vnn2022\n[5]: https://sites.google.com/view/vnn2023\n[6]: https://sites.google.com/view/vnn2024\n[7]: https://sites.google.com/view/vnn2025\n[8]: https://docs.google.com/presentation/d/1oM3NqqU03EUqgQVc3bGK2ENgHa57u-W6Q63\nVflkv000/edit#slide=id.ge4496ad360_14_21\n[9]: https://arxiv.org/abs/2109.00498\n[10]: https://arxiv.org/pdf/2212.10376.pdf\n[11]: https://github.com/ChristopherBrix/vnncomp2023_results/blob/main/SCORING/s\nlides.pdf\n[12]: https://arxiv.org/abs/2312.16760\n[13]: https://docs.google.com/presentation/d/1RvZWeAdTfRC3bNtCqt84O6IIPoJBnF4jns\nEvhTTxsPE/edit\n[14]: https://www.arxiv.org/pdf/2412.19985\n[15]: https://docs.google.com/presentation/d/1ep-hGGotgWQF6SA0JIpQ6nFqs2lXoyuLMM\n-bORzNvrQ/edit?slide=id.p#slide=id.p\n[16]: https://huan-zhang.com/\n[17]: #developers-and-copyright\n[18]: #publications\n[19]: /Verified-Intelligence/alpha-beta-CROWN/blob/main/complete_verifier/docs/a\nbcrown_api.md\n[20]: https://sites.google.com/view/vnn2025\n[21]: https://github.com/VNN-COMP/vnncomp2025_results/blob/main/SCORING-SMALL-TO\nL/latex/main.pdf\n[22]: https://github.com/Verified-Intelligence/Two-Stage_Neural_Controller_Train\ning\n[23]: https://openreview.net/pdf?id=HuSSR12Yot\n[24]: https://arxiv.org/pdf/1811.00866.pdf\n[25]: https://arxiv.org/pdf/2002.12920.pdf\n[26]: https://arxiv.org/pdf/2011.13824.pdf\n[27]: https://arxiv.org/pdf/2103.06624.pdf\n[28]: https://arxiv.org/pdf/2405.21063.pdf\n[29]: https://arxiv.org/pdf/2208.05740.pdf\n[30]: https://proceedings.mlr.press/v162/zhang22ae/zhang22ae.pdf\n[31]: https://arxiv.org/pdf/1711.07356.pdf\n[32]: https://arxiv.org/pdf/2302.01404.pdf\n[33]: https://openreview.net/pdf?id=FwhM1Zpyft\n[34]: https://github.com/Verified-Intelligence/auto_LiRPA\n[35]: https://arxiv.org/pdf/2002.12920.pdf\n[36]: /Verified-Intelligence/alpha-beta-CROWN/blob/main/complete_verifier/exp_co\nnfigs\n[37]: https://github.com/Verified-Intelligence/Lyapunov_Stable_NN_Controllers\n[38]: https://github.com/Verified-Intelligence/Two-Stage_Neural_Controller_Train\ning\n[39]: https://huggingface.co/datasets/zhouxingshi/GenBaB\n[40]: /Verified-Intelligence/alpha-beta-CROWN/blob/main/complete_verifier/docs/a\nbcrown_usage.md#guide-on-algorithm-selection\n[41]: https://docs.conda.io/en/latest/miniconda.html\n[42]: https://github.com/Verified-Intelligence/auto_LiRPA\n[43]: /Verified-Intelligence/alpha-beta-CROWN/blob/main/complete_verifier/enviro\nnment.yaml\n[44]: /Verified-Intelligence/alpha-beta-CROWN/blob/main/complete_verifier/enviro\nnment.yaml\n[45]: https://pytorch.org/get-started\n[46]: /Verified-Intelligence/alpha-beta-CROWN/blob/main/complete_verifier/docs/v\nnn_comp.md#installation\n[47]: /Verified-Intelligence/alpha-beta-CROWN/blob/main/complete_verifier/docs/v\nnn_comp.md\n[48]: /Verified-Intelligence/alpha-beta-CROWN/blob/main/complete_verifier/docs/a\nbcrown_api.md\n[49]: /Verified-Intelligence/alpha-beta-CROWN/blob/main/complete_verifier/docs/a\nbcrown_api.md\n[50]: /Verified-Intelligence/alpha-beta-CROWN/blob/main/complete_verifier/exp_co\nnfigs/tutorial_examples/cifar_resnet_2b.yaml\n[51]: /Verified-Intelligence/alpha-beta-CROWN/blob/main/complete_verifier/docs/a\nbcrown_usage.md\n[52]: /Verified-Intelligence/alpha-beta-CROWN/blob/main/complete_verifier/exp_co\nnfigs\n[53]: https://arxiv.org/pdf/1811.00866.pdf\n[54]: https://arxiv.org/pdf/2002.12920.pdf\n[55]: https://arxiv.org/pdf/2011.13824.pdf\n[56]: https://arxiv.org/pdf/2103.06624.pdf\n[57]: https://arxiv.org/pdf/2405.21063.pdf\n[58]: https://arxiv.org/pdf/2208.05740.pdf\n[59]: https://openreview.net/pdf?id=FwhM1Zpyft\n[60]: https://arxiv.org/pdf/2302.01404.pdf\n[61]: https://arxiv.org/pdf/1902.08722\n[62]: https://proceedings.mlr.press/v162/zhang22ae/zhang22ae.pdf\n[63]: https://arxiv.org/pdf/1811.00866.pdf\n[64]: https://arxiv.org/pdf/1902.08722\n[65]: https://arxiv.org/pdf/2002.12920.pdf\n[66]: https://github.com/Verified-Intelligence/auto_LiRPA\n[67]: https://arxiv.org/pdf/2011.13824.pdf\n[68]: https://arxiv.org/pdf/2103.06624.pdf\n[69]: https://proceedings.mlr.press/v162/zhang22ae/zhang22ae.pdf\n[70]: https://arxiv.org/pdf/2208.05740.pdf\n[71]: https://arxiv.org/pdf/2302.01404.pdf\n[72]: https://openreview.net/pdf?id=FwhM1Zpyft\n[73]: https://arxiv.org/pdf/2405.21063.pdf\n[74]: https://github.com/AI4OPT/ml4acopf_benchmark\n[75]: https://openreview.net/pdf?id=HuSSR12Yot\n[76]: https://github.com/Verified-Intelligence/Two-Stage_Neural_Controller_Train\ning\n[77]: mailto:huan@huan-zhang.com\n[78]: mailto:xiangru4@illinois.edu\n[79]: mailto:duozhou2@illinois.edu\n[80]: mailto:keyis2@illinois.edu\n[81]: mailto:hesunc2@illinois.edu\n[82]: mailto:haoyuli5@illinois.edu\n[83]: mailto:ruizeg2@illinois.edu\n[84]: mailto:haoc539@illinois.edu\n[85]: mailto:zhouxingshichn@gmail.com\n[86]: mailto:leih5@illinois.edu\n[87]: mailto:taobol2@illinois.edu\n[88]: mailto:jorgejc2@illinois.edu\n[89]: mailto:hx84@duke.edu\n[90]: mailto:brix@cs.rwth-aachen.de\n[91]: mailto:haoc8@illinois.edu\n[92]: mailto:keyulu2@illinois.edu\n[93]: mailto:kx46@drexel.edu\n[94]: mailto:schawla7@illinois.edu\n[95]: mailto:linyi2@illinois.edu\n[96]: mailto:zhuolin5@illinois.edu\n[97]: mailto:realzhuowen@gmail.com\n[98]: mailto:qiruijin@umich.edu\n[99]: mailto:sw3215@columbia.edu\n[100]: mailto:yihanwang@ucla.edu\n[101]: mailto:jinqic@cs.cmu.edu\n[102]: mailto:zkolter@cs.cmu.edu\n[103]: mailto:chohsieh@cs.ucla.edu\n[104]: mailto:suman@cs.columbia.edu\n[105]: mailto:lbo@illinois.edu\n[106]: mailto:xue.lin@northeastern.edu\n[107]: /Verified-Intelligence/alpha-beta-CROWN/blob/main/LICENSE\n",
  "content_type": "Reference",
  "fetched_at": "2025-12-19T17:31:54.356607Z",
  "metadata": {
    "sections": [
      "Navigation Menu",
      "Search code, repositories, users, issues, pull requests...",
      "\n        Provide feedback\n      ",
      "\n        Saved searches\n      ",
      "Use saved searches to filter your results more quickly",
      "License",
      "        Uh oh!\n",
      "Verified-Intelligence/alpha-beta-CROWN",
      "Folders and files",
      "Latest commit",
      "History",
      "Repository files navigation",
      "α,β-CROWN (alpha-beta-CROWN): A Fast and Scalable Neural Network Verifier with Efficient Bound Propagation",
      "News (2025 - )",
      "Supported Features",
      "Installation and Setup",
      "Instructions",
      "Publications",
      "Developers and Copyright",
      "About",
      "Topics",
      "Resources",
      "License",
      "        Uh oh!\n",
      "Stars",
      "Watchers",
      "Forks",
      "\n  Releases",
      "\n  Packages\n      0",
      "        Uh oh!\n",
      "\n  Contributors\n      25",
      "Languages",
      "Footer",
      "Footer navigation"
    ],
    "tags": [],
    "code_blocks": [
      {
        "language": "text",
        "code": "git clone --recursive https://github.com/Verified-Intelligence/alpha-beta-CROWN.git",
        "description": null
      },
      {
        "language": "text",
        "code": "# Remove the old environment, if necessary.\nconda deactivate; conda env remove --name alpha-beta-crown\n# install all dependents into the alpha-beta-crown environment\nconda env create -f complete_verifier/environment.yaml --name alpha-beta-crown\n# activate the environment\nconda activate alpha-beta-crown",
        "description": null
      },
      {
        "language": "text",
        "code": "(cd auto_LiRPA; pip install -e .)\npip install -r complete_verifier/requirements.txt",
        "description": null
      },
      {
        "language": "text",
        "code": "conda activate alpha-beta-crown  # activate the conda environment\ncd complete_verifier\npython abcrown.py --config exp_configs/tutorial_examples/cifar_resnet_2b.yaml",
        "description": null
      },
      {
        "language": "text",
        "code": "@article{zhang2018efficient,\n  title={Efficient Neural Network Robustness Certification with General Activation Functions},\n  author={Zhang, Huan and Weng, Tsui-Wei and Chen, Pin-Yu and Hsieh, Cho-Jui and Daniel, Luca},\n  journal={Advances in Neural Information Processing Systems},\n  volume={31},\n  pages={4939--4948},\n  year={2018},\n  url={https://arxiv.org/pdf/1811.00866.pdf}\n}\n\n@article{xu2020automatic,\n  title={Automatic perturbation analysis for scalable certified robustness and beyond},\n  author={Xu, Kaidi and Shi, Zhouxing and Zhang, Huan and Wang, Yihan and Chang, Kai-Wei and Huang, Minlie and Kailkhura, Bhavya and Lin, Xue and Hsieh, Cho-Jui},\n  journal={Advances in Neural Information Processing Systems},\n  volume={33},\n  year={2020}\n}\n\n@article{salman2019convex,\n  title={A Convex Relaxation Barrier to Tight Robustness Verification of Neural Networks},\n  author={Salman, Hadi and Yang, Greg and Zhang, Huan and Hsieh, Cho-Jui and Zhang, Pengchuan},\n  journal={Advances in Neural Information Processing Systems},\n  volume={32},\n  pages={9835--9846},\n  year={2019}\n}\n\n@inproceedings{xu2021fast,\n    title={{Fast and Complete}: Enabling Complete Neural Network Verification with Rapid and Massively Parallel Incomplete Verifiers},\n    author={Kaidi Xu and Huan Zhang and Shiqi Wang and Yihan Wang and Suman Jana and Xue Lin and Cho-Jui Hsieh},\n    booktitle={International Conference on Learning Representations},\n    year={2021},\n    url={https://openreview.net/forum?id=nVZtXBI6LNn}\n}\n\n@article{wang2021beta,\n  title={{Beta-CROWN}: Efficient bound propagation with per-neuron split constraints for complete and incomplete neural network verification},\n  author={Wang, Shiqi and Zhang, Huan and Xu, Kaidi and Lin, Xue and Jana, Suman and Hsieh, Cho-Jui and Kolter, J Zico},\n  journal={Advances in Neural Information Processing Systems},\n  volume={34},\n  year={2021}\n}\n\n@InProceedings{zhang22babattack,\n  title = \t {A Branch and Bound Framework for Stronger Adversarial Attacks of {R}e{LU} Networks},\n  author =       {Zhang, Huan and Wang, Shiqi and Xu, Kaidi and Wang, Yihan and Jana, Suman and Hsieh, Cho-Jui and Kolter, Zico},\n  booktitle = \t {Proceedings of the 39th International Conference on Machine Learning},\n  volume = \t {162},\n  pages = \t {26591--26604},\n  year = \t {2022},\n}\n\n@article{zhang2022general,\n  title={General Cutting Planes for Bound-Propagation-Based Neural Network Verification},\n  author={Zhang, Huan and Wang, Shiqi and Xu, Kaidi and Li, Linyi and Li, Bo and Jana, Suman and Hsieh, Cho-Jui and Kolter, J Zico},\n  journal={Advances in Neural Information Processing Systems},\n  year={2022}\n}\n\n@inproceedings{kotha2023provably,\n author = {Kotha, Suhas and Brix, Christopher and Kolter, J. Zico and Dvijotham, Krishnamurthy and Zhang, Huan},\n booktitle = {Advances in Neural Information Processing Systems},\n editor = {A. Oh and T. Neumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},\n pages = {80270--80290},\n publisher = {Curran Associates, Inc.},\n title = {Provably Bounding Neural Network Preimages},\n url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/fe061ec0ae03c5cf5b5323a2b9121bfd-Paper-Conference.pdf},\n volume = {36},\n year = {2023}\n}\n\n@inproceedings{zhou2024scalable,\n  title={Scalable Neural Network Verification with Branch-and-bound Inferred Cutting Planes},\n  author={Zhou, Duo and Brix, Christopher and Hanasusanto, Grani A and Zhang, Huan},\n  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},\n  year={2024}\n}\n\n@inproceedings{shi2024genbab,\n  title={Neural Network Verification with Branch-and-Bound for General Nonlinearities},\n  author={Shi, Zhouxing and Jin, Qirui and Kolter, Zico and Jana, Suman and Hsieh, Cho-Jui and Zhang, Huan},\n  booktitle={International Conference on Tools and Algorithms for the Construction and Analysis of Systems},\n  year={2025}\n}\n\n@inproceedings{zhou2025clip,\n  title={Clip-and-Verify: Linear Constraint-Driven Domain Clipping for Accelerating Neural Network Verification},\n  author={Zhou, Duo and Chavez, Jorge and Chen, Hesun and Hanasusanto, Grani A and Zhang, Huan},\n  booktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\n  year={2025}\n}\n",
        "description": null
      }
    ],
    "original_format": "html",
    "word_count": 2691
  }
}