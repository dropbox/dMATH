{
  "id": "robustbench",
  "name": "RobustBench",
  "category": "adversarial_testing",
  "subcategory": "benchmarking",

  "description": "Standardized benchmark for adversarial robustness",
  "long_description": "RobustBench is a standardized benchmark for adversarial robustness. It provides a leaderboard, model zoo, and evaluation tools for measuring model robustness.",

  "capabilities": ["robustness_benchmark", "model_zoo", "standardized_evaluation"],
  "property_types": ["robustness"],
  "input_languages": ["python"],
  "output_formats": ["robustness_metrics"],

  "installation": {
    "methods": [{"type": "pip", "command": "pip install robustbench"}],
    "dependencies": ["torch", "torchvision"],
    "platforms": ["linux", "macos", "windows"]
  },

  "documentation": {
    "official": "https://robustbench.github.io/",
    "tutorial": "https://github.com/RobustBench/robustbench#readme",
    "api_reference": "https://robustbench.github.io/",
    "examples": "https://github.com/RobustBench/robustbench"
  },

  "tactics": [
    {"name": "evaluate", "description": "Evaluate model", "syntax": "benchmark(model, ...)", "when_to_use": "For standardized eval", "examples": []}
  ],

  "error_patterns": [],

  "integration": {"dashprove_backend": true, "usl_property_types": ["robustness"], "cli_command": "dashprove verify --backend robustbench"},

  "performance": {"typical_runtime": "hours", "scalability": "Good", "memory_usage": "GPU dependent"},

  "comparisons": {"similar_tools": ["autoattack"], "advantages": ["Standardized", "Leaderboard"], "disadvantages": ["ImageNet focus"]},

  "metadata": {"version": "1.1", "last_updated": "2025-12-22", "maintainer": "RobustBench Team", "license": "MIT"}
}
