{
  "id": "textattack",
  "name": "TextAttack",
  "category": "adversarial_testing",
  "subcategory": "nlp",

  "description": "Framework for adversarial attacks on NLP models",
  "long_description": "TextAttack is a Python framework for adversarial attacks, adversarial training, and data augmentation in NLP. It provides attacks, transformations, constraints, and search methods.",

  "capabilities": ["text_attacks", "adversarial_training", "data_augmentation"],
  "property_types": ["robustness"],
  "input_languages": ["python"],
  "output_formats": ["adversarial_text"],

  "installation": {
    "methods": [{"type": "pip", "command": "pip install textattack"}],
    "dependencies": ["transformers", "torch"],
    "platforms": ["linux", "macos", "windows"]
  },

  "documentation": {
    "official": "https://textattack.readthedocs.io/",
    "tutorial": "https://textattack.readthedocs.io/en/latest/1start/basic-Intro.html",
    "api_reference": "https://textattack.readthedocs.io/en/latest/apidoc/textattack.html",
    "examples": "https://github.com/QData/TextAttack/tree/master/examples"
  },

  "tactics": [
    {"name": "textfooler", "description": "TextFooler attack", "syntax": "TextFoolerJin2019.build()", "when_to_use": "For NLP attacks", "examples": []}
  ],

  "error_patterns": [],

  "integration": {"dashprove_backend": true, "usl_property_types": ["nlp_robustness"], "cli_command": "dashprove verify --backend textattack"},

  "performance": {"typical_runtime": "minutes", "scalability": "Good", "memory_usage": "Moderate"},

  "comparisons": {"similar_tools": ["art", "openattack"], "advantages": ["NLP focused", "Many attacks"], "disadvantages": ["NLP only"]},

  "metadata": {"version": "0.3.9", "last_updated": "2025-12-22", "maintainer": "QData", "license": "MIT"}
}
