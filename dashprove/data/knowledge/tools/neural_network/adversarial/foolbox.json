{
  "id": "foolbox",
  "name": "Foolbox",
  "category": "adversarial_testing",
  "subcategory": "attacks",

  "description": "Python toolbox for adversarial attacks",
  "long_description": "Foolbox is a Python toolbox to create adversarial examples. It's framework-agnostic and works with PyTorch, TensorFlow, JAX, and NumPy models.",

  "capabilities": ["adversarial_attacks", "framework_agnostic", "batch_attacks"],
  "property_types": ["robustness"],
  "input_languages": ["python"],
  "output_formats": ["adversarial_examples"],

  "installation": {
    "methods": [{"type": "pip", "command": "pip install foolbox"}],
    "dependencies": ["numpy", "eagerpy"],
    "platforms": ["linux", "macos", "windows"]
  },

  "documentation": {
    "official": "https://foolbox.readthedocs.io/",
    "tutorial": "https://foolbox.readthedocs.io/en/stable/getting-started.html",
    "api_reference": "https://foolbox.readthedocs.io/en/stable/modules/attacks.html",
    "examples": "https://github.com/bethgelab/foolbox/tree/master/examples"
  },

  "tactics": [
    {"name": "linfpgd", "description": "L-inf PGD attack", "syntax": "LinfPGD()", "when_to_use": "For bounded perturbations", "examples": []}
  ],

  "error_patterns": [],

  "integration": {"dashprove_backend": true, "usl_property_types": ["robustness"], "cli_command": "dashprove verify --backend foolbox"},

  "performance": {"typical_runtime": "fast", "scalability": "Good", "memory_usage": "Low"},

  "comparisons": {"similar_tools": ["art", "cleverhans"], "advantages": ["Clean API", "Framework agnostic"], "disadvantages": ["Attacks only"]},

  "metadata": {"version": "3.3.3", "last_updated": "2025-12-22", "maintainer": "Bethge Lab", "license": "MIT"}
}
