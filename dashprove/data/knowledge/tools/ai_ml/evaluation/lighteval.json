{
  "id": "lighteval",
  "name": "LightEval",
  "category": "ml_evaluation",
  "subcategory": "llm_benchmarking",

  "description": "Lightweight LLM evaluation framework by Hugging Face",
  "long_description": "LightEval is a lightweight, extensible framework for evaluating LLMs developed by Hugging Face. Designed to be faster and more flexible than lm-evaluation-harness, it supports all major benchmarks with easy customization and integration with the HF ecosystem.",

  "capabilities": [
    "llm_benchmarking",
    "custom_tasks",
    "accelerate_integration",
    "nanotron_support",
    "parallel_evaluation",
    "metric_computation",
    "few_shot_evaluation"
  ],
  "property_types": ["accuracy", "perplexity", "exact_match"],
  "input_languages": ["python"],
  "output_formats": ["json", "wandb"],

  "installation": {
    "methods": [
      {"type": "pip", "command": "pip install lighteval"},
      {"type": "source", "command": "pip install git+https://github.com/huggingface/lighteval"}
    ],
    "dependencies": ["transformers", "accelerate", "datasets"],
    "platforms": ["linux", "macos"]
  },

  "documentation": {
    "official": "https://github.com/huggingface/lighteval",
    "tutorial": "https://github.com/huggingface/lighteval#quick-start",
    "api_reference": "https://github.com/huggingface/lighteval/tree/main/src/lighteval",
    "examples": "https://github.com/huggingface/lighteval/tree/main/examples"
  },

  "tactics": [
    {
      "name": "run_eval",
      "description": "Run benchmark evaluation",
      "syntax": "lighteval accelerate --model_args <args> --tasks <tasks>",
      "when_to_use": "To evaluate on standard benchmarks",
      "examples": ["lighteval accelerate \\\n  --model_args 'pretrained=meta-llama/Llama-2-7b-hf' \\\n  --tasks 'leaderboard|mmlu|5|1'"]
    },
    {
      "name": "custom_task",
      "description": "Create custom evaluation task",
      "syntax": "class CustomTask(LightevalTask):",
      "when_to_use": "For custom benchmarks",
      "examples": ["from lighteval.tasks import LightevalTask\n\nclass MyTask(LightevalTask):\n    def __init__(self):\n        super().__init__(\n            name='my_task',\n            metric=['accuracy']\n        )"]
    },
    {
      "name": "nanotron",
      "description": "Evaluate Nanotron models",
      "syntax": "lighteval nanotron --checkpoint-config-path <path>",
      "when_to_use": "For distributed model evaluation",
      "examples": ["lighteval nanotron \\\n  --checkpoint-config-path checkpoints/config.yaml \\\n  --tasks 'leaderboard|arc|5|1'"]
    },
    {
      "name": "parallel_eval",
      "description": "Multi-GPU evaluation",
      "syntax": "accelerate launch lighteval",
      "when_to_use": "For large model evaluation",
      "examples": ["accelerate launch --multi_gpu --num_processes 8 \\\n  -m lighteval accelerate \\\n  --model_args 'pretrained=model,tensor_parallel_size=8'"]
    }
  ],

  "error_patterns": [
    {
      "pattern": "Task.*not found",
      "meaning": "Invalid task name",
      "common_causes": ["Wrong task format", "Task not registered"],
      "fixes": ["Use format: suite|task|fewshot|truncate"]
    },
    {
      "pattern": "CUDA.*out of memory",
      "meaning": "GPU memory exceeded",
      "common_causes": ["Model too large", "Batch too large"],
      "fixes": ["Reduce batch size", "Use tensor parallelism"]
    },
    {
      "pattern": "accelerate.*not configured",
      "meaning": "Accelerate not set up",
      "common_causes": ["Missing accelerate config"],
      "fixes": ["Run: accelerate config"]
    }
  ],

  "integration": {
    "dashprove_backend": true,
    "usl_property_types": ["accuracy", "benchmark"],
    "cli_command": "dashprove verify --backend lighteval"
  },

  "performance": {
    "typical_runtime": "Minutes to hours",
    "scalability": "Excellent with accelerate",
    "memory_usage": "Model-dependent"
  },

  "comparisons": {
    "similar_tools": ["lm-evaluation-harness", "openai-evals", "bigbench"],
    "advantages": [
      "Fast evaluation",
      "HF ecosystem native",
      "Easy customization",
      "Nanotron support",
      "Active development"
    ],
    "disadvantages": [
      "Fewer built-in tasks",
      "Less community adoption",
      "Documentation still growing"
    ]
  },

  "metadata": {
    "version": "0.4.0",
    "last_updated": "2025-12-22",
    "maintainer": "Hugging Face",
    "license": "MIT"
  }
}
