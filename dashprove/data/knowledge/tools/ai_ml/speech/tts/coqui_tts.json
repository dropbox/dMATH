{
  "id": "coqui_tts",
  "name": "Coqui TTS",
  "category": "speech_synthesis",
  "subcategory": "tts",

  "description": "Deep learning text-to-speech library",
  "long_description": "Coqui TTS is a deep learning toolkit for Text-to-Speech synthesis. It provides pre-trained models in multiple languages, easy training of custom voices, and production-ready inference. Supports VITS, Tacotron2, Glow-TTS, and other architectures.",

  "capabilities": [
    "text_to_speech",
    "voice_cloning",
    "multi_speaker",
    "multi_language",
    "emotion_control",
    "prosody_control"
  ],
  "property_types": ["mos", "rtf", "naturalness"],
  "input_languages": ["python"],
  "output_formats": ["wav", "mp3"],

  "installation": {
    "methods": [
      {"type": "pip", "command": "pip install TTS"},
      {"type": "pip_dev", "command": "pip install TTS[all]"}
    ],
    "dependencies": ["torch", "librosa", "scipy"],
    "platforms": ["linux", "macos", "windows"]
  },

  "documentation": {
    "official": "https://tts.readthedocs.io/",
    "tutorial": "https://tts.readthedocs.io/en/latest/tutorial_for_nervous_beginners.html",
    "api_reference": "https://tts.readthedocs.io/en/latest/tts.html",
    "examples": "https://github.com/coqui-ai/TTS/tree/dev/recipes"
  },

  "tactics": [
    {
      "name": "synthesize",
      "description": "Generate speech from text",
      "syntax": "tts.tts(text)",
      "when_to_use": "For text-to-speech",
      "examples": ["from TTS.api import TTS\n\ntts = TTS('tts_models/en/ljspeech/vits')\ntts.tts_to_file(\n    text='Hello world!',\n    file_path='output.wav'\n)"]
    },
    {
      "name": "voice_clone",
      "description": "Clone voice from audio",
      "syntax": "tts.tts_with_vc(text, speaker_wav)",
      "when_to_use": "For voice cloning",
      "examples": ["tts = TTS('tts_models/multilingual/multi-dataset/xtts_v2')\ntts.tts_to_file(\n    text='Hello!',\n    speaker_wav='reference.wav',\n    file_path='cloned.wav'\n)"]
    },
    {
      "name": "multi_speaker",
      "description": "Use different speakers",
      "syntax": "speaker=speaker_name",
      "when_to_use": "For multi-speaker models",
      "examples": ["tts = TTS('tts_models/en/vctk/vits')\ntts.tts_to_file(\n    text='Hello!',\n    speaker='p225',\n    file_path='output.wav'\n)"]
    },
    {
      "name": "evaluate_mos",
      "description": "Calculate MOS score",
      "syntax": "UTMOS / NISQA",
      "when_to_use": "For quality evaluation",
      "examples": ["# Using UTMOS for MOS prediction\nimport torch\nfrom speechmos import UTMOS\n\nmodel = UTMOS()\nmos = model.score(audio_tensor, sample_rate)"]
    }
  ],

  "error_patterns": [
    {
      "pattern": "Model.*not found",
      "meaning": "Invalid model name",
      "common_causes": ["Wrong model path"],
      "fixes": ["List models: tts --list_models"]
    },
    {
      "pattern": "Audio.*length",
      "meaning": "Reference too short/long",
      "common_causes": ["Bad reference audio"],
      "fixes": ["Use 3-10 second reference"]
    },
    {
      "pattern": "CUDA.*memory",
      "meaning": "GPU memory exceeded",
      "common_causes": ["Large model"],
      "fixes": ["Use CPU", "Smaller batch"]
    }
  ],

  "integration": {
    "dashprove_backend": true,
    "usl_property_types": ["mos", "naturalness"],
    "cli_command": "dashprove verify --backend coqui-tts"
  },

  "performance": {
    "typical_runtime": "Real-time on GPU",
    "scalability": "Good",
    "memory_usage": "2-8GB"
  },

  "comparisons": {
    "similar_tools": ["nemo_tts", "espeak", "pyttsx3"],
    "advantages": [
      "High quality voices",
      "Voice cloning",
      "Multi-language",
      "Easy to use",
      "Active development"
    ],
    "disadvantages": [
      "Large models",
      "Coqui company shutdown",
      "Some models deprecated"
    ]
  },

  "metadata": {
    "version": "0.22.0",
    "last_updated": "2025-12-22",
    "maintainer": "Community",
    "license": "MPL-2.0"
  }
}
