{
  "id": "aif360",
  "name": "AI Fairness 360",
  "category": "ai_ml_fairness",
  "subcategory": "bias_detection",
  "description": "IBM toolkit for detecting and mitigating bias in ML models",
  "long_description": "AI Fairness 360 (AIF360) is an open-source toolkit from IBM Research containing over 70 fairness metrics and 10 bias mitigation algorithms. It helps examine, report, and mitigate discrimination and bias in machine learning models throughout the AI application lifecycle.",
  "capabilities": [
    "bias_detection",
    "fairness_metrics",
    "pre_processing_mitigation",
    "in_processing_mitigation",
    "post_processing_mitigation",
    "demographic_parity",
    "equalized_odds",
    "individual_fairness",
    "dataset_analysis"
  ],
  "property_types": [
    "fairness",
    "bias"
  ],
  "input_languages": [
    "python",
    "scikit-learn"
  ],
  "output_formats": [
    "metrics",
    "reports",
    "mitigated_data"
  ],
  "installation": {
    "methods": [
      {
        "type": "pip",
        "command": "pip install aif360"
      },
      {
        "type": "source",
        "url": "https://github.com/Trusted-AI/AIF360"
      }
    ],
    "dependencies": [
      "python",
      "numpy",
      "scikit-learn"
    ],
    "platforms": [
      "linux",
      "macos",
      "windows"
    ]
  },
  "documentation": {
    "official": "https://aif360.mybluemix.net/",
    "tutorial": "https://aif360.mybluemix.net/resources",
    "api_reference": "https://aif360.readthedocs.io/",
    "examples": "https://github.com/Trusted-AI/AIF360/tree/master/examples"
  },
  "tactics": [
    {
      "name": "dataset_metric",
      "description": "Compute dataset bias metrics",
      "syntax": "BinaryLabelDatasetMetric(dataset, ...)",
      "when_to_use": "Before training to understand data bias",
      "examples": [
        "metric = BinaryLabelDatasetMetric(dataset, privileged_groups=[{'sex': 1}])\nprint(metric.disparate_impact())"
      ]
    },
    {
      "name": "classification_metric",
      "description": "Compute model fairness metrics",
      "syntax": "ClassificationMetric(dataset, predictions, ...)",
      "when_to_use": "After training to measure model fairness",
      "examples": [
        "metric = ClassificationMetric(test, pred, privileged_groups=[{'sex': 1}])\nprint(metric.equal_opportunity_difference())"
      ]
    },
    {
      "name": "reweighing",
      "description": "Pre-processing: reweight training data",
      "syntax": "Reweighing(privileged_groups=..., unprivileged_groups=...)",
      "when_to_use": "Mitigating bias before training",
      "examples": [
        "rw = Reweighing(privileged_groups=priv, unprivileged_groups=unpriv)\ntransformed = rw.fit_transform(train)"
      ]
    },
    {
      "name": "calibrated_eq_odds",
      "description": "Post-processing: calibrated equalized odds",
      "syntax": "CalibratedEqOddsPostprocessing(...)",
      "when_to_use": "Mitigating bias after training",
      "examples": [
        "cpp = CalibratedEqOddsPostprocessing(privileged_groups=priv)\nfair_pred = cpp.fit_predict(test, pred)"
      ]
    }
  ],
  "error_patterns": [
    {
      "pattern": "Disparate impact < 0.8",
      "meaning": "Significant disparity between groups",
      "common_causes": [
        "Biased training data",
        "Biased features"
      ],
      "fixes": [
        "Apply mitigation algorithm",
        "Rebalance data"
      ]
    },
    {
      "pattern": "Equal opportunity difference > 0.1",
      "meaning": "Unequal true positive rates",
      "common_causes": [
        "Model discrimination"
      ],
      "fixes": [
        "Apply post-processing calibration"
      ]
    }
  ],
  "integration": {
    "dashprove_backend": true,
    "usl_property_types": [
      "fairness"
    ],
    "cli_command": "dashprove verify --backend aif360"
  },
  "performance": {
    "typical_runtime": "Seconds to minutes",
    "scalability": "Handles large datasets",
    "memory_usage": "Moderate"
  },
  "comparisons": {
    "similar_tools": [
      "fairlearn",
      "aequitas",
      "fairness_indicators"
    ],
    "advantages": [
      "70+ metrics",
      "10 algorithms",
      "Comprehensive toolkit",
      "IBM support"
    ],
    "disadvantages": [
      "Complex API",
      "Steep learning curve"
    ]
  },
  "metadata": {
    "version": "0.5.0",
    "last_updated": "2025-12-20",
    "maintainer": "IBM Research",
    "license": "Apache-2.0"
  }
}
