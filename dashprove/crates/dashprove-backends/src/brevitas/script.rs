//! Brevitas script generation and output parsing

use super::config::BrevitasConfig;
use crate::counterexample::StructuredCounterexample;
use crate::traits::{BackendError, VerificationStatus};
use dashprove_usl::typecheck::TypedSpec;

/// Generate a Brevitas quantization verification script
pub fn generate_brevitas_script(
    _spec: &TypedSpec,
    config: &BrevitasConfig,
) -> Result<String, BackendError> {
    let weight_bit_width = config.weight_bit_width.as_str();
    let weight_bits = config.weight_bit_width.as_int().unwrap_or(8);
    let activation_bit_width = config.activation_bit_width.as_str();
    let activation_bits = config.activation_bit_width.as_int().unwrap_or(32);
    let scaling_mode = config.scaling_mode.as_str();
    let quant_method = config.quant_method.as_str();
    let export_format = config.export_format.as_str();
    let calibration_samples = config.calibration_samples;

    Ok(format!(
        r#"#!/usr/bin/env python3
"""
Brevitas quantization verification script
Generated by DashProve

Validates model quantization correctness with Brevitas.
"""

import sys
import json
import time
import numpy as np

try:
    import brevitas
    import brevitas.nn as qnn
    from brevitas.quant import Int8WeightPerTensorFloat, Int8ActPerTensorFloat
    from brevitas.quant import Int4WeightPerTensorFloat
except ImportError as e:
    print(f"BREVITAS_ERROR: Missing Brevitas: {{e}}")
    print("BREVITAS_ERROR: Install with: pip install brevitas")
    sys.exit(1)

# Require PyTorch
try:
    import torch
    import torch.nn as nn
except ImportError as e:
    print(f"BREVITAS_ERROR: PyTorch required: {{e}}")
    sys.exit(1)


class FloatModel(nn.Module):
    """Float reference model."""
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, 3, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(16)
        self.relu1 = nn.ReLU()
        self.conv2 = nn.Conv2d(16, 32, 3, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(32)
        self.relu2 = nn.ReLU()
        self.pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Linear(32, 10, bias=False)

    def forward(self, x):
        x = self.relu1(self.bn1(self.conv1(x)))
        x = self.relu2(self.bn2(self.conv2(x)))
        x = self.pool(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x


def create_quant_model(weight_bits, activation_bits):
    """Create quantized model with Brevitas layers."""

    # Select appropriate quantizers
    if weight_bits <= 4:
        weight_quant = Int4WeightPerTensorFloat
    else:
        weight_quant = Int8WeightPerTensorFloat

    act_quant = Int8ActPerTensorFloat

    class QuantModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.conv1 = qnn.QuantConv2d(
                3, 16, 3, padding=1, bias=False,
                weight_quant=weight_quant,
                weight_bit_width=weight_bits
            )
            self.bn1 = nn.BatchNorm2d(16)
            self.relu1 = qnn.QuantReLU(act_quant=act_quant, bit_width=activation_bits)
            self.conv2 = qnn.QuantConv2d(
                16, 32, 3, padding=1, bias=False,
                weight_quant=weight_quant,
                weight_bit_width=weight_bits
            )
            self.bn2 = nn.BatchNorm2d(32)
            self.relu2 = qnn.QuantReLU(act_quant=act_quant, bit_width=activation_bits)
            self.pool = nn.AdaptiveAvgPool2d(1)
            self.fc = qnn.QuantLinear(
                32, 10, bias=False,
                weight_quant=weight_quant,
                weight_bit_width=weight_bits
            )

        def forward(self, x):
            x = self.relu1(self.bn1(self.conv1(x)))
            x = self.relu2(self.bn2(self.conv2(x)))
            x = self.pool(x)
            x = x.view(x.size(0), -1)
            x = self.fc(x)
            return x

    return QuantModel()


def main():
    weight_bit_width = "{weight_bit_width}"
    weight_bits = {weight_bits}
    activation_bit_width = "{activation_bit_width}"
    activation_bits = {activation_bits}
    scaling_mode = "{scaling_mode}"
    quant_method = "{quant_method}"
    export_format = "{export_format}"
    calibration_samples = {calibration_samples}

    # Create float reference model
    float_model = FloatModel()
    float_model.eval()

    # Get original model size
    original_size = sum(p.numel() * p.element_size() for p in float_model.parameters())
    total_params = sum(p.numel() for p in float_model.parameters())

    # Generate test input
    np.random.seed(42)
    torch.manual_seed(42)
    test_input = torch.randn(1, 3, 32, 32)

    # Get float model output
    with torch.no_grad():
        float_output = float_model(test_input).numpy()

    # Create and calibrate quantized model
    try:
        start_time = time.perf_counter()

        quant_model = create_quant_model(weight_bits, activation_bits)

        # Copy weights from float model
        quant_model.conv1.weight.data = float_model.conv1.weight.data.clone()
        quant_model.conv2.weight.data = float_model.conv2.weight.data.clone()
        quant_model.fc.weight.data = float_model.fc.weight.data.clone()
        quant_model.bn1.load_state_dict(float_model.bn1.state_dict())
        quant_model.bn2.load_state_dict(float_model.bn2.state_dict())

        quant_model.eval()

        # Calibration pass
        for _ in range(calibration_samples):
            calib_input = torch.randn(1, 3, 32, 32)
            with torch.no_grad():
                _ = quant_model(calib_input)

        quantization_time = time.perf_counter() - start_time

        # Get quantized model output
        with torch.no_grad():
            quant_output = quant_model(test_input).numpy()

        # Calculate output difference
        output_diff = np.max(np.abs(float_output - quant_output))
        output_mse = np.mean((float_output - quant_output) ** 2)

        # Calculate compression ratio
        avg_bits = (weight_bits + activation_bits) / 2.0
        compression_ratio = 32.0 / avg_bits

        status = "success"
        error_message = None

    except Exception as e:
        status = "error"
        error_message = str(e)
        quantization_time = 0.0
        output_diff = float('inf')
        output_mse = float('inf')
        compression_ratio = 1.0
        quant_model = None

    # Benchmark if successful
    if status == "success" and quant_model is not None:
        latencies = []
        for _ in range(100):
            start = time.perf_counter()
            with torch.no_grad():
                _ = quant_model(test_input)
            latencies.append((time.perf_counter() - start) * 1000)

        latencies = np.array(latencies)
        mean_lat = float(np.mean(latencies))
        std_lat = float(np.std(latencies))
        p50_lat = float(np.percentile(latencies, 50))
        p95_lat = float(np.percentile(latencies, 95))
    else:
        mean_lat = std_lat = p50_lat = p95_lat = 0.0

    print("BREVITAS_RESULT_START")
    result = {{
        "status": status,
        "weight_bit_width": weight_bit_width,
        "activation_bit_width": activation_bit_width,
        "weight_bits": weight_bits,
        "activation_bits": activation_bits,
        "scaling_mode": scaling_mode,
        "quant_method": quant_method,
        "export_format": export_format,
        "calibration_samples": calibration_samples,
        "original_size_bytes": original_size,
        "total_params": total_params,
        "compression_ratio": compression_ratio,
        "output_max_diff": float(output_diff) if status == "success" else None,
        "output_mse": float(output_mse) if status == "success" else None,
        "quantization_time_s": quantization_time,
        "latency_ms": {{
            "mean": mean_lat,
            "std": std_lat,
            "p50": p50_lat,
            "p95": p95_lat
        }},
        "brevitas_version": brevitas.__version__,
        "error": error_message
    }}
    print(json.dumps(result, indent=2))
    print("BREVITAS_RESULT_END")

    if status == "success":
        print(f"\\nBREVITAS_SUMMARY: Compression ratio: {{compression_ratio:.1f}}x")
        print(f"BREVITAS_SUMMARY: Output max diff: {{output_diff:.6f}}")
        print(f"BREVITAS_SUMMARY: Output MSE: {{output_mse:.6f}}")
        print(f"BREVITAS_SUMMARY: Mean latency: {{mean_lat:.3f}}ms")

        if output_diff < 0.1 and output_mse < 0.01:
            print("BREVITAS_STATUS: VERIFIED")
        elif output_diff < 0.5:
            print("BREVITAS_STATUS: PARTIALLY_VERIFIED")
        else:
            print("BREVITAS_STATUS: NOT_VERIFIED")
    else:
        print(f"BREVITAS_ERROR: {{error_message}}")


if __name__ == "__main__":
    main()
"#
    ))
}

/// Parse Brevitas output
pub fn parse_brevitas_output(
    stdout: &str,
    stderr: &str,
) -> (VerificationStatus, Option<StructuredCounterexample>) {
    if stdout.contains("BREVITAS_ERROR:") || stderr.contains("BREVITAS_ERROR:") {
        let error_msg = stdout
            .lines()
            .chain(stderr.lines())
            .find(|l| l.contains("BREVITAS_ERROR:"))
            .map(|l| l.replace("BREVITAS_ERROR:", "").trim().to_string())
            .unwrap_or_else(|| "Unknown Brevitas error".to_string());
        return (VerificationStatus::Unknown { reason: error_msg }, None);
    }

    if let Some(json_str) =
        extract_json_result(stdout, "BREVITAS_RESULT_START", "BREVITAS_RESULT_END")
    {
        if let Ok(result) = serde_json::from_str::<serde_json::Value>(&json_str) {
            let status = result["status"].as_str().unwrap_or("error");
            let output_diff = result["output_max_diff"].as_f64().unwrap_or(1.0);
            let output_mse = result["output_mse"].as_f64().unwrap_or(1.0);

            if status == "error" {
                let error = result["error"]
                    .as_str()
                    .unwrap_or("Unknown error")
                    .to_string();
                return (VerificationStatus::Unknown { reason: error }, None);
            }

            let counterexample =
                crate::counterexample::build_quantization_counterexample(&result, "Brevitas");

            if output_diff < 0.1 && output_mse < 0.01 {
                return (VerificationStatus::Proven, None);
            } else if output_diff < 0.5 {
                return (
                    VerificationStatus::Partial {
                        verified_percentage: 90.0,
                    },
                    counterexample,
                );
            } else {
                return (VerificationStatus::Disproven, counterexample);
            }
        }
    }

    if stdout.contains("BREVITAS_STATUS: VERIFIED") {
        (VerificationStatus::Proven, None)
    } else if stdout.contains("BREVITAS_STATUS: PARTIALLY_VERIFIED") {
        (
            VerificationStatus::Partial {
                verified_percentage: 90.0,
            },
            None,
        )
    } else if stdout.contains("BREVITAS_STATUS: NOT_VERIFIED") {
        (VerificationStatus::Disproven, None)
    } else {
        (
            VerificationStatus::Unknown {
                reason: "Could not parse Brevitas output".to_string(),
            },
            None,
        )
    }
}

fn extract_json_result(output: &str, start_marker: &str, end_marker: &str) -> Option<String> {
    if let Some(start) = output.find(start_marker) {
        let after_start = &output[start + start_marker.len()..];
        if let Some(end) = after_start.find(end_marker) {
            return Some(after_start[..end].trim().to_string());
        }
    }
    None
}
