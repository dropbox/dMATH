//! NNV script generation and output parsing

use super::config::NnvConfig;
use crate::counterexample::StructuredCounterexample;
use crate::traits::{BackendError, VerificationStatus};
use dashprove_usl::ast::{ComparisonOp, Expr, Property};
use dashprove_usl::typecheck::TypedSpec;

/// Generate an NNV verification script from USL spec
pub fn generate_nnv_script(spec: &TypedSpec, config: &NnvConfig) -> Result<String, BackendError> {
    let epsilon = extract_epsilon_from_spec(spec).unwrap_or(config.epsilon);
    let model_path = extract_model_path_from_spec(spec)
        .or_else(|| config.model_path.as_ref().map(|p| p.display().to_string()))
        .unwrap_or_else(|| "model.onnx".to_string());
    let method = config.method.as_str();
    let num_workers = config.num_workers;
    let use_gpu = if config.use_gpu { "True" } else { "False" };

    Ok(format!(
        r#"#!/usr/bin/env python3
"""
NNV neural network verification script
Generated by DashProve
"""

import sys
import json
import numpy as np

try:
    import nnv
    from nnv import NeuralNetwork
    from nnv.set import Star, Zonotope
    from nnv.specification import VerificationSpecification
except ImportError as e:
    print(f"NNV_ERROR: Missing dependency: {{e}}")
    print("NNV_ERROR: Install with: pip install nnv")
    sys.exit(1)

def load_network(model_path: str):
    """Load a neural network for NNV verification."""
    try:
        # NNV supports ONNX models
        if model_path.endswith('.onnx'):
            network = NeuralNetwork.from_onnx(model_path)
        else:
            # Try to load as generic format
            network = NeuralNetwork.load(model_path)
        return network
    except Exception as e:
        print(f"NNV_ERROR: Failed to load network: {{e}}")
        return None

def create_test_network():
    """Create a simple test network for demonstration."""
    # Create a simple 2-layer ReLU network
    import torch
    import torch.nn as nn

    model = nn.Sequential(
        nn.Linear(2, 4),
        nn.ReLU(),
        nn.Linear(4, 2)
    )

    # Initialize with small weights for testability
    with torch.no_grad():
        model[0].weight.fill_(0.5)
        model[0].bias.fill_(0.1)
        model[2].weight.fill_(0.3)
        model[2].bias.fill_(0.0)

    return model

def create_input_set(center, epsilon, method="{method}"):
    """Create input set for verification."""
    input_dim = len(center)

    if method == "star":
        # Star set: center + basis * alpha, subject to constraints
        basis = np.eye(input_dim) * epsilon
        constraints_A = np.vstack([np.eye(input_dim), -np.eye(input_dim)])
        constraints_b = np.ones(2 * input_dim)
        return Star(center, basis, constraints_A, constraints_b)
    elif method == "zonotope":
        # Zonotope: center + generators * alpha
        generators = np.eye(input_dim) * epsilon
        return Zonotope(center, generators)
    else:
        # Default to interval bounds
        lb = center - epsilon
        ub = center + epsilon
        return (lb, ub)

def verify_robustness(network, input_set, true_label, method="{method}"):
    """Verify local robustness around input."""
    try:
        # Compute reachable set
        if method == "star":
            output_set = network.reach_star(input_set)
        elif method == "zonotope":
            output_set = network.reach_zonotope(input_set)
        else:
            # Interval arithmetic
            lb, ub = input_set
            output_lb, output_ub = network.reach_interval(lb, ub)
            output_set = (output_lb, output_ub)

        # Check if classification is preserved
        if method in ["star", "zonotope"]:
            # For set representations, check if true_label always has max output
            is_verified = output_set.is_max_index(true_label)
            if not is_verified:
                counterexample = output_set.find_counterexample(true_label)
            else:
                counterexample = None
        else:
            # For intervals, check if lower bound of true class > upper bound of others
            output_lb, output_ub = output_set
            is_verified = True
            counterexample = None
            for i in range(len(output_lb)):
                if i != true_label:
                    if output_lb[true_label] <= output_ub[i]:
                        is_verified = False
                        # Counterexample: point where other class could be higher
                        counterexample = (output_lb + output_ub) / 2
                        break

        return is_verified, output_set, counterexample
    except Exception as e:
        print(f"NNV_INFO: Verification error: {{e}}")
        return None, None, None

def main():
    model_path = "{model_path}"
    epsilon = {epsilon}
    method = "{method}"
    num_workers = {num_workers}
    use_gpu = {use_gpu}

    # Try to load network
    network = load_network(model_path)

    if network is None:
        # Use test network for demonstration
        print("NNV_INFO: Using synthetic test network")
        network = create_test_network()
        input_dim = 2
        output_dim = 2
    else:
        input_dim = network.input_shape[0]
        output_dim = network.output_shape[0]

    # Create test inputs
    np.random.seed(42)
    num_samples = 10
    test_inputs = np.random.rand(num_samples, input_dim).astype(np.float32)

    # Verification results
    verified_count = 0
    total_count = num_samples
    counterexamples = []

    for i, x in enumerate(test_inputs):
        # Get true label
        try:
            if hasattr(network, 'forward'):
                import torch
                with torch.no_grad():
                    output = network(torch.tensor(x).unsqueeze(0))
                    true_label = output.argmax().item()
            else:
                output = network.evaluate(x)
                true_label = np.argmax(output)
        except Exception as e:
            print(f"NNV_INFO: Forward pass error: {{e}}")
            true_label = 0

        # Create input set
        input_set = create_input_set(x, epsilon, method)

        # Verify
        is_verified, output_set, cex = verify_robustness(network, input_set, true_label, method)

        if is_verified is None:
            # Verification failed, count as unknown
            continue
        elif is_verified:
            verified_count += 1
        else:
            if cex is not None:
                counterexamples.append({{
                    "sample_index": i,
                    "original_input": x.tolist(),
                    "true_label": int(true_label),
                    "counterexample": cex.tolist() if isinstance(cex, np.ndarray) else str(cex)
                }})

    # Calculate verification rate
    verification_rate = verified_count / total_count if total_count > 0 else 0.0

    # Output results
    print("NNV_RESULT_START")
    result = {{
        "verified_count": verified_count,
        "total_count": total_count,
        "verification_rate": float(verification_rate),
        "epsilon": float(epsilon),
        "method": method,
        "input_dim": int(input_dim),
        "output_dim": int(output_dim),
        "num_counterexamples": len(counterexamples)
    }}

    if counterexamples:
        result["counterexample"] = counterexamples[0]

    print(json.dumps(result, indent=2))
    print("NNV_RESULT_END")

    # Print summary
    print(f"\\nNNV_SUMMARY: Verified {{verified_count}}/{{total_count}} samples ({{verification_rate:.2%}})")
    print(f"NNV_SUMMARY: Method: {{method}}, Epsilon: {{epsilon}}")

    # Determine status
    if verification_rate >= 0.99:
        print("NNV_STATUS: VERIFIED")
    elif verification_rate >= 0.90:
        print("NNV_STATUS: PARTIALLY_VERIFIED")
    else:
        print("NNV_STATUS: NOT_VERIFIED")

if __name__ == "__main__":
    main()
"#
    ))
}

/// Extract epsilon value from USL spec properties
fn extract_epsilon_from_spec(spec: &TypedSpec) -> Option<f64> {
    for prop in &spec.spec.properties {
        let expr = match prop {
            Property::Invariant(inv) => Some(&inv.body),
            Property::Theorem(thm) => Some(&thm.body),
            Property::Security(sec) => Some(&sec.body),
            Property::Probabilistic(prob) => Some(&prob.condition),
            _ => None,
        };
        if let Some(e) = expr {
            if let Some(eps) = extract_epsilon(e) {
                return Some(eps);
            }
        }
    }
    None
}

/// Extract epsilon from expression
fn extract_epsilon(expr: &Expr) -> Option<f64> {
    match expr {
        Expr::Compare(lhs, op, rhs) => {
            if let Expr::Var(name) = lhs.as_ref() {
                let lower = name.to_lowercase();
                if (lower.contains("epsilon") || lower == "eps")
                    && matches!(op, ComparisonOp::Le | ComparisonOp::Lt)
                {
                    return extract_numeric_value(rhs);
                }
            }
            if let Expr::Var(name) = rhs.as_ref() {
                let lower = name.to_lowercase();
                if (lower.contains("epsilon") || lower == "eps")
                    && matches!(op, ComparisonOp::Ge | ComparisonOp::Gt)
                {
                    return extract_numeric_value(lhs);
                }
            }
            if matches!(op, ComparisonOp::Le | ComparisonOp::Lt) {
                if let Some(val) = extract_numeric_value(rhs) {
                    if val > 0.0 && val < 1.0 {
                        return Some(val);
                    }
                }
            }
            extract_epsilon(lhs).or_else(|| extract_epsilon(rhs))
        }
        Expr::And(lhs, rhs) | Expr::Or(lhs, rhs) | Expr::Implies(lhs, rhs) => {
            extract_epsilon(lhs).or_else(|| extract_epsilon(rhs))
        }
        Expr::Not(inner) | Expr::Neg(inner) => extract_epsilon(inner),
        Expr::Binary(lhs, _, rhs) => extract_epsilon(lhs).or_else(|| extract_epsilon(rhs)),
        Expr::ForAll { body, .. }
        | Expr::Exists { body, .. }
        | Expr::ForAllIn { body, .. }
        | Expr::ExistsIn { body, .. } => extract_epsilon(body),
        Expr::FieldAccess(obj, _) => extract_epsilon(obj),
        Expr::MethodCall { receiver, args, .. } => {
            extract_epsilon(receiver).or_else(|| args.iter().find_map(extract_epsilon))
        }
        Expr::App(_, args) => args.iter().find_map(extract_epsilon),
        Expr::Var(_) | Expr::Int(_) | Expr::Float(_) | Expr::String(_) | Expr::Bool(_) => None,
    }
}

/// Extract numeric value from expression
fn extract_numeric_value(expr: &Expr) -> Option<f64> {
    match expr {
        Expr::Float(f) => Some(*f),
        Expr::Int(i) => Some(*i as f64),
        Expr::Neg(inner) => extract_numeric_value(inner).map(|v| -v),
        _ => None,
    }
}

/// Extract model path from USL spec
fn extract_model_path_from_spec(spec: &TypedSpec) -> Option<String> {
    for typedef in &spec.spec.types {
        for field in &typedef.fields {
            let lower = field.name.to_lowercase();
            if lower.contains("model") || lower.contains("network") {
                if let dashprove_usl::ast::Type::Named(name) = &field.ty {
                    if name.to_lowercase().contains("path")
                        || name.to_lowercase().contains("string")
                    {
                        return Some(field.name.clone());
                    }
                }
            }
        }
    }
    None
}

/// Parse NNV script output
pub fn parse_nnv_output(
    stdout: &str,
    stderr: &str,
) -> (VerificationStatus, Option<StructuredCounterexample>) {
    // Check for errors
    if stdout.contains("NNV_ERROR:") || stderr.contains("NNV_ERROR:") {
        let error_msg = stdout
            .lines()
            .chain(stderr.lines())
            .find(|l| l.contains("NNV_ERROR:"))
            .map(|l| l.replace("NNV_ERROR:", "").trim().to_string())
            .unwrap_or_else(|| "Unknown NNV error".to_string());

        return (VerificationStatus::Unknown { reason: error_msg }, None);
    }

    // Parse JSON result
    if let Some(json_str) = extract_json_result(stdout) {
        if let Ok(result) = serde_json::from_str::<serde_json::Value>(&json_str) {
            let verification_rate = result["verification_rate"].as_f64().unwrap_or(0.0);

            // Use the robustness helper to build a structured counterexample
            let counterexample =
                crate::counterexample::build_nn_verification_counterexample(&result, "NNV");

            // Determine status based on verification rate
            if verification_rate >= 0.99 {
                return (VerificationStatus::Proven, None);
            } else if verification_rate >= 0.90 {
                return (
                    VerificationStatus::Partial {
                        verified_percentage: verification_rate * 100.0,
                    },
                    counterexample,
                );
            } else {
                return (VerificationStatus::Disproven, counterexample);
            }
        }
    }

    // Fallback: parse status line
    if stdout.contains("NNV_STATUS: VERIFIED") {
        (VerificationStatus::Proven, None)
    } else if stdout.contains("NNV_STATUS: PARTIALLY_VERIFIED") {
        (
            VerificationStatus::Partial {
                verified_percentage: 90.0,
            },
            None,
        )
    } else if stdout.contains("NNV_STATUS: NOT_VERIFIED") {
        (VerificationStatus::Disproven, None)
    } else {
        (
            VerificationStatus::Unknown {
                reason: "Could not parse NNV output".to_string(),
            },
            None,
        )
    }
}

/// Extract JSON result from output
fn extract_json_result(output: &str) -> Option<String> {
    let start_marker = "NNV_RESULT_START";
    let end_marker = "NNV_RESULT_END";

    if let Some(start) = output.find(start_marker) {
        let after_start = &output[start + start_marker.len()..];
        if let Some(end) = after_start.find(end_marker) {
            return Some(after_start[..end].trim().to_string());
        }
    }
    None
}
