//! ART script generation and output parsing

use super::config::ArtConfig;
use crate::counterexample::StructuredCounterexample;
use crate::traits::{BackendError, VerificationStatus};
use dashprove_usl::ast::{ComparisonOp, Expr, Property};
use dashprove_usl::typecheck::TypedSpec;

/// Generate an ART evaluation script from USL spec
pub fn generate_art_script(spec: &TypedSpec, config: &ArtConfig) -> Result<String, BackendError> {
    let epsilon = extract_epsilon_from_spec(spec).unwrap_or(config.epsilon);
    let model_path = extract_model_path_from_spec(spec)
        .or_else(|| config.model_path.as_ref().map(|p| p.display().to_string()))
        .unwrap_or_else(|| "model.pt".to_string());

    let attack_module = config.attack_type.art_module();
    let attack_class = config.attack_type.art_class();
    let num_samples = config.num_samples;
    let max_iter = config.max_iter;
    let norm = &config.norm;

    Ok(format!(
        r#"#!/usr/bin/env python3
"""
ART adversarial robustness evaluation script
Generated by DashProve
"""

import sys
import json
import numpy as np

try:
    import art
    from art.estimators.classification import PyTorchClassifier
    from {attack_module} import {attack_class}
except ImportError as e:
    print(f"ART_ERROR: Missing dependency: {{e}}")
    sys.exit(1)

def load_model(model_path: str):
    """Load a PyTorch model for ART evaluation."""
    import torch
    import torch.nn as nn

    # Try to load the model
    try:
        model = torch.load(model_path, map_location='cpu')
        if isinstance(model, dict):
            # State dict - need model architecture
            print("ART_ERROR: Model is a state dict, need full model")
            return None
        model.eval()
        return model
    except Exception as e:
        print(f"ART_ERROR: Failed to load model: {{e}}")
        return None

def create_test_data(num_samples: int = {num_samples}):
    """Create synthetic test data for evaluation."""
    # Generate random images (CIFAR-10 like: 32x32x3)
    np.random.seed(42)
    x_test = np.random.rand(num_samples, 3, 32, 32).astype(np.float32)
    y_test = np.random.randint(0, 10, num_samples)
    return x_test, y_test

def main():
    model_path = "{model_path}"
    epsilon = {epsilon}
    num_samples = {num_samples}
    max_iter = {max_iter}
    norm_type = "{norm}"

    # Try to load model (or use dummy for testing)
    model = load_model(model_path)

    if model is None:
        # Use a simple test model for demonstration
        import torch
        import torch.nn as nn
        model = nn.Sequential(
            nn.Flatten(),
            nn.Linear(3 * 32 * 32, 256),
            nn.ReLU(),
            nn.Linear(256, 10)
        )
        model.eval()
        print("ART_INFO: Using synthetic test model")

    # Create classifier wrapper
    import torch
    import torch.nn as nn
    classifier = PyTorchClassifier(
        model=model,
        loss=nn.CrossEntropyLoss(),
        input_shape=(3, 32, 32),
        nb_classes=10,
        clip_values=(0.0, 1.0)
    )

    # Generate test data
    x_test, y_test = create_test_data(num_samples)

    # Get clean accuracy
    predictions = np.argmax(classifier.predict(x_test), axis=1)
    clean_accuracy = np.mean(predictions == y_test)

    # Create attack
    if "{attack_class}" == "FastGradientMethod":
        attack = {attack_class}(estimator=classifier, eps={epsilon}, norm=np.inf if "{norm}" == "inf" else float("{norm}"))
    elif "{attack_class}" == "ProjectedGradientDescent":
        attack = {attack_class}(estimator=classifier, eps={epsilon}, max_iter={max_iter}, norm=np.inf if "{norm}" == "inf" else float("{norm}"))
    elif "{attack_class}" == "AutoProjectedGradientDescent":
        attack = {attack_class}(estimator=classifier, eps={epsilon}, max_iter={max_iter}, norm=np.inf if "{norm}" == "inf" else float("{norm}"))
    elif "{attack_class}" == "DeepFool":
        attack = {attack_class}(classifier=classifier, max_iter={max_iter})
    elif "{attack_class}" == "CarliniL2Method":
        attack = {attack_class}(classifier=classifier, max_iter={max_iter})
    else:
        attack = {attack_class}(estimator=classifier)

    # Generate adversarial examples
    x_adv = attack.generate(x=x_test)

    # Get adversarial accuracy
    adv_predictions = np.argmax(classifier.predict(x_adv), axis=1)
    adv_accuracy = np.mean(adv_predictions == y_test)

    # Find adversarial examples (where prediction changed)
    adv_indices = np.where(predictions != adv_predictions)[0]

    # Calculate perturbation stats
    perturbations = x_adv - x_test
    max_perturbation = np.max(np.abs(perturbations))
    mean_perturbation = np.mean(np.abs(perturbations))

    # Calculate robustness metrics
    robust_accuracy = adv_accuracy
    attack_success_rate = 1.0 - (adv_accuracy / max(clean_accuracy, 1e-10))

    # Output results in parseable format
    print("ART_RESULT_START")
    result = {{
        "clean_accuracy": float(clean_accuracy),
        "adversarial_accuracy": float(adv_accuracy),
        "robust_accuracy": float(robust_accuracy),
        "attack_success_rate": float(attack_success_rate),
        "num_adversarial_examples": int(len(adv_indices)),
        "max_perturbation": float(max_perturbation),
        "mean_perturbation": float(mean_perturbation),
        "epsilon": float(epsilon),
        "attack_type": "{attack_class}",
        "num_samples": int(num_samples)
    }}

    # Add first adversarial example if found
    if len(adv_indices) > 0:
        idx = adv_indices[0]
        result["adversarial_example"] = {{
            "original_input": x_test[idx].flatten()[:10].tolist(),  # First 10 values
            "adversarial_input": x_adv[idx].flatten()[:10].tolist(),
            "original_prediction": int(predictions[idx]),
            "adversarial_prediction": int(adv_predictions[idx]),
            "true_label": int(y_test[idx]),
            "perturbation_norm": float(np.linalg.norm(perturbations[idx].flatten(), ord=np.inf))
        }}

    print(json.dumps(result, indent=2))
    print("ART_RESULT_END")

    # Print summary
    print(f"\\nART_SUMMARY: Clean accuracy: {{clean_accuracy:.2%}}, Robust accuracy: {{robust_accuracy:.2%}}")
    print(f"ART_SUMMARY: Attack success rate: {{attack_success_rate:.2%}}, Found {{len(adv_indices)}} adversarial examples")

    # Determine if model is robust at given epsilon
    if attack_success_rate < 0.01:
        print("ART_STATUS: ROBUST")
    elif attack_success_rate < 0.10:
        print("ART_STATUS: PARTIALLY_ROBUST")
    else:
        print("ART_STATUS: NOT_ROBUST")

if __name__ == "__main__":
    main()
"#
    ))
}

/// Extract epsilon value from USL spec properties
fn extract_epsilon_from_spec(spec: &TypedSpec) -> Option<f64> {
    for prop in &spec.spec.properties {
        let expr = match prop {
            Property::Invariant(inv) => Some(&inv.body),
            Property::Theorem(thm) => Some(&thm.body),
            Property::Security(sec) => Some(&sec.body),
            Property::Probabilistic(prob) => Some(&prob.condition),
            _ => None,
        };
        if let Some(e) = expr {
            if let Some(eps) = extract_epsilon(e) {
                return Some(eps);
            }
        }
    }
    None
}

/// Extract epsilon from expression
fn extract_epsilon(expr: &Expr) -> Option<f64> {
    match expr {
        // Direct comparison: epsilon <= 0.01
        Expr::Compare(lhs, op, rhs) => {
            // Check if left side is epsilon variable
            if let Expr::Var(name) = lhs.as_ref() {
                let lower = name.to_lowercase();
                if (lower.contains("epsilon") || lower == "eps")
                    && matches!(op, ComparisonOp::Le | ComparisonOp::Lt)
                {
                    return extract_numeric_value(rhs);
                }
            }
            // Check if right side is epsilon variable (reversed comparison)
            if let Expr::Var(name) = rhs.as_ref() {
                let lower = name.to_lowercase();
                if (lower.contains("epsilon") || lower == "eps")
                    && matches!(op, ComparisonOp::Ge | ComparisonOp::Gt)
                {
                    return extract_numeric_value(lhs);
                }
            }
            // Check for abs comparison: |x - x0| <= eps
            if matches!(op, ComparisonOp::Le | ComparisonOp::Lt) {
                if let Some(val) = extract_numeric_value(rhs) {
                    if val > 0.0 && val < 1.0 {
                        return Some(val);
                    }
                }
            }
            // Recurse into both sides
            extract_epsilon(lhs).or_else(|| extract_epsilon(rhs))
        }
        // Logical operators - recurse
        Expr::And(lhs, rhs) | Expr::Or(lhs, rhs) | Expr::Implies(lhs, rhs) => {
            extract_epsilon(lhs).or_else(|| extract_epsilon(rhs))
        }
        Expr::Not(inner) | Expr::Neg(inner) => extract_epsilon(inner),
        Expr::Binary(lhs, _, rhs) => extract_epsilon(lhs).or_else(|| extract_epsilon(rhs)),
        Expr::ForAll { body, .. }
        | Expr::Exists { body, .. }
        | Expr::ForAllIn { body, .. }
        | Expr::ExistsIn { body, .. } => extract_epsilon(body),
        Expr::FieldAccess(obj, _) => extract_epsilon(obj),
        Expr::MethodCall { receiver, args, .. } => {
            extract_epsilon(receiver).or_else(|| args.iter().find_map(extract_epsilon))
        }
        Expr::App(_, args) => args.iter().find_map(extract_epsilon),
        // Literals don't contain epsilon
        Expr::Var(_) | Expr::Int(_) | Expr::Float(_) | Expr::String(_) | Expr::Bool(_) => None,
    }
}

/// Extract numeric value from expression
fn extract_numeric_value(expr: &Expr) -> Option<f64> {
    match expr {
        Expr::Float(f) => Some(*f),
        Expr::Int(i) => Some(*i as f64),
        Expr::Neg(inner) => extract_numeric_value(inner).map(|v| -v),
        _ => None,
    }
}

/// Extract model path from USL spec
fn extract_model_path_from_spec(spec: &TypedSpec) -> Option<String> {
    // Look for model path in type fields
    for typedef in &spec.spec.types {
        for field in &typedef.fields {
            let lower = field.name.to_lowercase();
            if lower.contains("model") || lower.contains("network") {
                // Check if it's a string type field that might contain a path
                if let dashprove_usl::ast::Type::Named(name) = &field.ty {
                    if name.to_lowercase().contains("path")
                        || name.to_lowercase().contains("string")
                    {
                        return Some(field.name.clone());
                    }
                }
            }
        }
    }
    None
}

/// Parse ART script output
pub fn parse_art_output(
    stdout: &str,
    stderr: &str,
) -> (VerificationStatus, Option<StructuredCounterexample>) {
    // Check for errors
    if stdout.contains("ART_ERROR:") || stderr.contains("ART_ERROR:") {
        let error_msg = stdout
            .lines()
            .chain(stderr.lines())
            .find(|l| l.contains("ART_ERROR:"))
            .map(|l| l.replace("ART_ERROR:", "").trim().to_string())
            .unwrap_or_else(|| "Unknown ART error".to_string());

        return (VerificationStatus::Unknown { reason: error_msg }, None);
    }

    // Parse JSON result
    if let Some(json_str) = extract_json_result(stdout) {
        if let Ok(result) = serde_json::from_str::<serde_json::Value>(&json_str) {
            let attack_success_rate = result["attack_success_rate"].as_f64().unwrap_or(1.0);
            let robust_accuracy = result["robust_accuracy"].as_f64().unwrap_or(0.0);

            // Build counterexample if adversarial examples were found
            let counterexample =
                crate::counterexample::build_adversarial_attack_counterexample(&result, "ART");

            // Determine status based on attack success rate
            if attack_success_rate < 0.01 {
                return (VerificationStatus::Proven, None);
            } else if attack_success_rate < 0.10 {
                return (
                    VerificationStatus::Partial {
                        verified_percentage: robust_accuracy * 100.0,
                    },
                    counterexample,
                );
            } else {
                return (VerificationStatus::Disproven, counterexample);
            }
        }
    }

    // Fallback: parse status line
    if stdout.contains("ART_STATUS: ROBUST") {
        (VerificationStatus::Proven, None)
    } else if stdout.contains("ART_STATUS: PARTIALLY_ROBUST") {
        (
            VerificationStatus::Partial {
                verified_percentage: 90.0,
            },
            None,
        )
    } else if stdout.contains("ART_STATUS: NOT_ROBUST") {
        (VerificationStatus::Disproven, None)
    } else {
        (
            VerificationStatus::Unknown {
                reason: "Could not parse ART output".to_string(),
            },
            None,
        )
    }
}

/// Extract JSON result from output
fn extract_json_result(output: &str) -> Option<String> {
    let start_marker = "ART_RESULT_START";
    let end_marker = "ART_RESULT_END";

    if let Some(start) = output.find(start_marker) {
        let after_start = &output[start + start_marker.len()..];
        if let Some(end) = after_start.find(end_marker) {
            return Some(after_start[..end].trim().to_string());
        }
    }
    None
}
