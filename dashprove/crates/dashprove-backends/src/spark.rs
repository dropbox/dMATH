//! SPARK Ada verification backend
//!
//! SPARK is a formally defined subset of Ada with tools for proving
//! properties including absence of runtime errors and functional correctness.
//!
//! See: <https://www.adacore.com/about-spark>
//!
//! # Features
//!
//! - **Contract-based**: Pre/postconditions, invariants
//! - **Information flow**: Data/flow dependency contracts
//! - **Absence of runtime errors**: Division by zero, overflow, etc.
//! - **Functional correctness**: Full functional proofs
//!
//! # Requirements
//!
//! Install SPARK via GNAT Community or GNAT Pro:
//! ```bash
//! # Download GNAT Community from https://www.adacore.com/download
//! # gnatprove is included in the SPARK toolset
//! ```

use crate::counterexample::{FailedCheck, SourceLocation, StructuredCounterexample};
use crate::traits::{
    BackendError, BackendId, BackendResult, HealthStatus, PropertyType, VerificationBackend,
    VerificationStatus,
};
use async_trait::async_trait;
use dashprove_usl::typecheck::TypedSpec;
use std::path::PathBuf;
use std::process::Stdio;
use std::time::{Duration, Instant};
use tempfile::TempDir;
use tokio::process::Command;
use tracing::debug;

/// Proof level for SPARK
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum SparkProofLevel {
    #[default]
    Bronze, // Absence of runtime errors
    Silver,   // + Key integrity properties
    Gold,     // + Full functional correctness
    Platinum, // + Advanced properties
}

/// Configuration for SPARK backend
#[derive(Debug, Clone)]
pub struct SparkConfig {
    /// Path to gnatprove binary
    pub gnatprove_path: Option<PathBuf>,
    /// Timeout for verification
    pub timeout: Duration,
    /// Proof level
    pub level: SparkProofLevel,
    /// Number of parallel provers
    pub jobs: Option<u32>,
    /// Extra arguments
    pub extra_args: Vec<String>,
}

impl Default for SparkConfig {
    fn default() -> Self {
        Self {
            gnatprove_path: None,
            timeout: Duration::from_secs(120),
            level: SparkProofLevel::default(),
            jobs: None,
            extra_args: vec![],
        }
    }
}

/// SPARK Ada verification backend
pub struct SparkBackend {
    config: SparkConfig,
}

impl Default for SparkBackend {
    fn default() -> Self {
        Self::new()
    }
}

impl SparkBackend {
    pub fn new() -> Self {
        Self {
            config: SparkConfig::default(),
        }
    }

    pub fn with_config(config: SparkConfig) -> Self {
        Self { config }
    }

    async fn detect(&self) -> Result<PathBuf, String> {
        if let Some(ref path) = self.config.gnatprove_path {
            if path.exists() {
                return Ok(path.clone());
            }
        }
        for name in ["gnatprove", "spark"] {
            if let Ok(path) = which::which(name) {
                return Ok(path);
            }
        }
        Err("SPARK/gnatprove not found. Install GNAT Community or GNAT Pro".to_string())
    }

    fn generate_ada_code(&self, spec: &TypedSpec) -> String {
        let mut code = String::new();
        code.push_str("-- Generated by DashProve\n");
        code.push_str("pragma SPARK_Mode (On);\n\n");
        code.push_str("package Verification with SPARK_Mode is\n\n");

        for (i, prop) in spec.spec.properties.iter().enumerate() {
            let prop_name = prop.name();
            code.push_str(&format!("   -- Property: {}\n", prop_name));
            code.push_str(&format!(
                "   function Property_{} (X : Integer) return Boolean\n",
                i
            ));
            code.push_str("      with Post => Property_'Result = True;\n\n");
        }

        if spec.spec.properties.is_empty() {
            code.push_str("   function Trivial return Boolean\n");
            code.push_str("      with Post => Trivial'Result = True;\n\n");
        }

        code.push_str("end Verification;\n\n");
        code.push_str("package body Verification with SPARK_Mode is\n\n");

        for (i, _) in spec.spec.properties.iter().enumerate() {
            code.push_str(&format!(
                "   function Property_{} (X : Integer) return Boolean is\n",
                i
            ));
            code.push_str("   begin\n");
            code.push_str("      return True;\n");
            code.push_str(&format!("   end Property_{};\n\n", i));
        }

        if spec.spec.properties.is_empty() {
            code.push_str("   function Trivial return Boolean is\n");
            code.push_str("   begin\n");
            code.push_str("      return True;\n");
            code.push_str("   end Trivial;\n\n");
        }

        code.push_str("end Verification;\n");
        code
    }

    fn generate_project_file(&self) -> String {
        let mut gpr = String::new();
        gpr.push_str("project Verification is\n");
        gpr.push_str("   for Source_Dirs use (\".\");\n");
        gpr.push_str("   for Object_Dir use \"obj\";\n");
        gpr.push_str("   package Prove is\n");
        gpr.push_str("      for Proof_Switches (\"Ada\") use (\"-j0\", \"--timeout=30\");\n");
        gpr.push_str("   end Prove;\n");
        gpr.push_str("end Verification;\n");
        gpr
    }

    fn parse_output(
        &self,
        stdout: &str,
        stderr: &str,
        success: bool,
    ) -> (VerificationStatus, Vec<String>) {
        let combined = format!("{}\n{}", stdout, stderr);
        let mut diagnostics = Vec::new();
        let mut proved = 0;
        let mut failed = 0;

        for line in combined.lines() {
            let trimmed = line.trim();
            if trimmed.contains("proved") || trimmed.contains("PROVED") {
                proved += 1;
                diagnostics.push(format!("✓ {}", trimmed));
            }
            // Check for actual errors, but exclude "0 error" which indicates success
            let is_error = (trimmed.contains("error") || trimmed.contains("ERROR"))
                && !trimmed.contains("0 error")
                && !trimmed.contains("0 ERROR");
            if trimmed.contains("not proved") || trimmed.contains("NOT PROVED") || is_error {
                failed += 1;
                diagnostics.push(format!("✗ {}", trimmed));
            }
            if trimmed.contains("Summary") || trimmed.contains("flow") {
                diagnostics.push(trimmed.to_string());
            }
        }

        if failed > 0 {
            return (VerificationStatus::Disproven, diagnostics);
        }
        if combined.contains("0 error") || (proved > 0 && failed == 0) {
            return (VerificationStatus::Proven, diagnostics);
        }
        if success && !combined.contains("not proved") {
            return (VerificationStatus::Proven, diagnostics);
        }
        (
            VerificationStatus::Unknown {
                reason: "Could not parse output".to_string(),
            },
            diagnostics,
        )
    }

    fn parse_counterexample(stdout: &str, stderr: &str) -> StructuredCounterexample {
        let mut ce = StructuredCounterexample::new();
        ce.raw = Some(format!("{}\n{}", stdout, stderr));
        ce.failed_checks = Self::extract_failed_checks(ce.raw.as_ref().unwrap());
        ce
    }

    fn extract_failed_checks(output: &str) -> Vec<FailedCheck> {
        let mut checks = Vec::new();
        for line in output.lines() {
            if line.contains("not proved") || line.contains("error") {
                let check_type = if line.contains("precondition") {
                    "spark_precondition"
                } else if line.contains("postcondition") {
                    "spark_postcondition"
                } else if line.contains("overflow") {
                    "spark_overflow"
                } else if line.contains("range") {
                    "spark_range"
                } else {
                    "spark_vc"
                };
                checks.push(FailedCheck {
                    check_id: check_type.to_string(),
                    description: line.to_string(),
                    location: Self::parse_location(line),
                    function: None,
                });
            }
        }
        checks
    }

    fn parse_location(line: &str) -> Option<SourceLocation> {
        // SPARK format: "file.ads:line:col: message"
        if let Some(colon) = line.find(':') {
            let file = &line[..colon];
            if file.ends_with(".ads") || file.ends_with(".adb") {
                let rest = &line[colon + 1..];
                if let Some(next_colon) = rest.find(':') {
                    if let Ok(line_num) = rest[..next_colon].parse::<u32>() {
                        return Some(SourceLocation {
                            file: file.to_string(),
                            line: line_num,
                            column: None,
                        });
                    }
                }
            }
        }
        None
    }
}

#[async_trait]
impl VerificationBackend for SparkBackend {
    fn id(&self) -> BackendId {
        BackendId::SPARK
    }

    fn supports(&self) -> Vec<PropertyType> {
        vec![PropertyType::Contract, PropertyType::Invariant]
    }

    async fn verify(&self, spec: &TypedSpec) -> Result<BackendResult, BackendError> {
        let start = Instant::now();
        let gnatprove_path = self.detect().await.map_err(BackendError::Unavailable)?;

        let temp_dir = TempDir::new().map_err(|e| {
            BackendError::VerificationFailed(format!("Failed to create temp dir: {}", e))
        })?;

        // Create obj directory
        let obj_dir = temp_dir.path().join("obj");
        std::fs::create_dir_all(&obj_dir).ok();

        let ada_file = temp_dir.path().join("verification.ads");
        let gpr_file = temp_dir.path().join("verification.gpr");
        let ada_code = self.generate_ada_code(spec);
        let gpr_code = self.generate_project_file();

        debug!("Generated Ada code:\n{}", ada_code);
        tokio::fs::write(&ada_file, &ada_code)
            .await
            .map_err(|e| BackendError::VerificationFailed(format!("Failed to write: {}", e)))?;
        tokio::fs::write(&gpr_file, &gpr_code)
            .await
            .map_err(|e| BackendError::VerificationFailed(format!("Failed to write: {}", e)))?;

        let mut cmd = Command::new(&gnatprove_path);
        cmd.arg("-P")
            .arg(&gpr_file)
            .arg("--level=2")
            .stdout(Stdio::piped())
            .stderr(Stdio::piped())
            .current_dir(temp_dir.path());

        if let Some(jobs) = self.config.jobs {
            cmd.arg(format!("-j{}", jobs));
        }
        for arg in &self.config.extra_args {
            cmd.arg(arg);
        }

        let output = tokio::time::timeout(self.config.timeout, cmd.output())
            .await
            .map_err(|_| BackendError::Timeout(self.config.timeout))?
            .map_err(|e| BackendError::VerificationFailed(format!("Failed to run: {}", e)))?;

        let stdout = String::from_utf8_lossy(&output.stdout).to_string();
        let stderr = String::from_utf8_lossy(&output.stderr).to_string();
        let (status, diagnostics) = self.parse_output(&stdout, &stderr, output.status.success());

        let counterexample = if matches!(status, VerificationStatus::Disproven) {
            Some(Self::parse_counterexample(&stdout, &stderr))
        } else {
            None
        };

        Ok(BackendResult {
            backend: BackendId::SPARK,
            status,
            proof: None,
            counterexample,
            diagnostics,
            time_taken: start.elapsed(),
        })
    }

    async fn health_check(&self) -> HealthStatus {
        match self.detect().await {
            Ok(_) => HealthStatus::Healthy,
            Err(r) => HealthStatus::Unavailable { reason: r },
        }
    }
}

#[cfg(kani)]
mod kani_proofs {
    use super::*;

    // ===== SparkProofLevel defaults =====

    #[kani::proof]
    fn verify_proof_level_default_bronze() {
        let level = SparkProofLevel::default();
        assert!(matches!(level, SparkProofLevel::Bronze));
    }

    // ===== SparkConfig defaults =====

    #[kani::proof]
    fn verify_config_defaults_timeout() {
        let config = SparkConfig::default();
        assert!(config.timeout == Duration::from_secs(120));
    }

    #[kani::proof]
    fn verify_config_defaults_options() {
        let config = SparkConfig::default();
        assert!(config.gnatprove_path.is_none());
        assert!(matches!(config.level, SparkProofLevel::Bronze));
        assert!(config.jobs.is_none());
        assert!(config.extra_args.is_empty());
    }

    // ===== Backend construction =====

    #[kani::proof]
    fn verify_backend_new_uses_defaults() {
        let backend = SparkBackend::new();
        assert!(backend.config.timeout == Duration::from_secs(120));
        assert!(matches!(backend.config.level, SparkProofLevel::Bronze));
    }

    #[kani::proof]
    fn verify_backend_default_matches_new() {
        let b1 = SparkBackend::new();
        let b2 = SparkBackend::default();
        assert!(b1.config.timeout == b2.config.timeout);
    }

    #[kani::proof]
    fn verify_backend_with_config_preserves_values() {
        let config = SparkConfig {
            gnatprove_path: Some(PathBuf::from("/usr/bin/gnatprove")),
            timeout: Duration::from_secs(60),
            level: SparkProofLevel::Gold,
            jobs: Some(4),
            extra_args: vec!["--test".to_string()],
        };
        let backend = SparkBackend::with_config(config);
        assert!(backend.config.timeout == Duration::from_secs(60));
        assert!(matches!(backend.config.level, SparkProofLevel::Gold));
        assert!(backend.config.jobs == Some(4));
    }

    // ===== ID and supports =====

    #[kani::proof]
    fn verify_backend_id() {
        let backend = SparkBackend::new();
        assert!(matches!(backend.id(), BackendId::SPARK));
    }

    #[kani::proof]
    fn verify_supports_contract_invariant() {
        let backend = SparkBackend::new();
        let supported = backend.supports();
        assert!(supported.contains(&PropertyType::Contract));
        assert!(supported.contains(&PropertyType::Invariant));
        assert!(supported.len() == 2);
    }

    // ===== Output parsing =====

    #[kani::proof]
    fn verify_parse_output_proved() {
        let backend = SparkBackend::new();
        let (status, _) = backend.parse_output("Summary: 10 VCs proved, 0 error", "", true);
        assert!(matches!(status, VerificationStatus::Proven));
    }

    #[kani::proof]
    fn verify_parse_output_not_proved() {
        let backend = SparkBackend::new();
        let (status, _) = backend.parse_output("postcondition not proved", "", false);
        assert!(matches!(status, VerificationStatus::Disproven));
    }

    #[kani::proof]
    fn verify_parse_output_error() {
        let backend = SparkBackend::new();
        let (status, _) = backend.parse_output("error: proof failed", "", false);
        assert!(matches!(status, VerificationStatus::Disproven));
    }

    // ===== Location parsing =====

    #[kani::proof]
    fn verify_parse_location_ads() {
        let loc = SparkBackend::parse_location("verification.ads:10:5: error");
        assert!(loc.is_some());
    }

    #[kani::proof]
    fn verify_parse_location_adb() {
        let loc = SparkBackend::parse_location("verification.adb:20:3: warning");
        assert!(loc.is_some());
    }

    #[kani::proof]
    fn verify_parse_location_invalid() {
        let loc = SparkBackend::parse_location("not a location");
        assert!(loc.is_none());
    }

    // ===== Failed checks extraction =====

    #[kani::proof]
    fn verify_extract_failed_checks_precondition() {
        let output = "precondition not proved";
        let checks = SparkBackend::extract_failed_checks(output);
        assert!(checks.iter().any(|c| c.check_id == "spark_precondition"));
    }

    #[kani::proof]
    fn verify_extract_failed_checks_postcondition() {
        let output = "postcondition error";
        let checks = SparkBackend::extract_failed_checks(output);
        assert!(checks.iter().any(|c| c.check_id == "spark_postcondition"));
    }

    #[kani::proof]
    fn verify_extract_failed_checks_overflow() {
        let output = "overflow not proved";
        let checks = SparkBackend::extract_failed_checks(output);
        assert!(checks.iter().any(|c| c.check_id == "spark_overflow"));
    }

    #[kani::proof]
    fn verify_extract_failed_checks_range() {
        let output = "range error";
        let checks = SparkBackend::extract_failed_checks(output);
        assert!(checks.iter().any(|c| c.check_id == "spark_range"));
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn backend_id() {
        assert_eq!(SparkBackend::new().id(), BackendId::SPARK);
    }

    #[test]
    fn default_config() {
        let config = SparkConfig::default();
        assert_eq!(config.level, SparkProofLevel::Bronze);
    }

    #[test]
    fn supports_contracts() {
        let backend = SparkBackend::new();
        let supported = backend.supports();
        assert!(supported.contains(&PropertyType::Contract));
        assert!(supported.contains(&PropertyType::Invariant));
    }

    #[test]
    fn parse_proved_output() {
        let backend = SparkBackend::new();
        let (status, _) = backend.parse_output("Summary: 10 VCs proved, 0 error", "", true);
        assert!(matches!(status, VerificationStatus::Proven));
    }

    #[test]
    fn parse_failed_output() {
        let backend = SparkBackend::new();
        let (status, _) = backend.parse_output("postcondition not proved", "", false);
        assert!(matches!(status, VerificationStatus::Disproven));
    }

    #[test]
    fn generate_ada_empty_spec() {
        use dashprove_usl::ast::Spec;
        use std::collections::HashMap;
        let backend = SparkBackend::new();
        let spec = TypedSpec {
            spec: Spec {
                types: vec![],
                properties: vec![],
            },
            type_info: HashMap::new(),
        };
        let code = backend.generate_ada_code(&spec);
        assert!(code.contains("package Verification"));
        assert!(code.contains("Trivial"));
    }

    #[test]
    fn parse_location() {
        let loc = SparkBackend::parse_location("verification.ads:10:5: error");
        assert!(loc.is_some());
        let loc = loc.unwrap();
        assert_eq!(loc.file, "verification.ads");
        assert_eq!(loc.line, 10);
    }
}
