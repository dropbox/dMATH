{
  "id": "evidently",
  "name": "Evidently",
  "category": "ai_ml",
  "subcategory": "data_quality",

  "description": "ML model monitoring and data drift detection toolkit",
  "long_description": "Evidently is an open-source Python library for evaluating, testing, and monitoring ML models from validation to production. It generates interactive reports and dashboards for data drift, model performance, and data quality. Supports both batch and real-time monitoring.",

  "capabilities": [
    "data_drift_detection",
    "model_performance_monitoring",
    "data_quality_testing",
    "target_drift_detection",
    "interactive_reports",
    "test_suites",
    "custom_metrics",
    "dashboard_ui"
  ],
  "property_types": ["data_drift", "model_performance", "data_quality"],
  "input_languages": ["python"],
  "output_formats": ["html_report", "json", "dashboard"],

  "installation": {
    "methods": [
      {"type": "pip", "command": "pip install evidently"},
      {"type": "source", "url": "https://github.com/evidentlyai/evidently"}
    ],
    "dependencies": ["pandas", "scikit-learn"],
    "platforms": ["linux", "macos", "windows"]
  },

  "documentation": {
    "official": "https://www.evidentlyai.com/",
    "tutorial": "https://docs.evidentlyai.com/",
    "api_reference": "https://docs.evidentlyai.com/reference/",
    "examples": "https://github.com/evidentlyai/evidently/tree/main/examples"
  },

  "tactics": [
    {
      "name": "report",
      "description": "Generate analysis report",
      "syntax": "Report(metrics=[DataDriftPreset()]).run(reference, current)",
      "when_to_use": "Analyzing data changes",
      "examples": ["report = Report(metrics=[DataDriftPreset()]); report.run(ref_data, cur_data)"]
    },
    {
      "name": "test_suite",
      "description": "Run automated tests",
      "syntax": "TestSuite(tests=[TestColumnDrift()]).run(ref, cur)",
      "when_to_use": "CI/CD data validation",
      "examples": ["suite = TestSuite(tests=[DataStabilityTestPreset()]); suite.run(ref, cur)"]
    },
    {
      "name": "dashboard",
      "description": "Create monitoring dashboard",
      "syntax": "workspace.create_project(name)",
      "when_to_use": "Continuous monitoring",
      "examples": ["project = workspace.create_project('monitoring')"]
    },
    {
      "name": "drift_detect",
      "description": "Detect feature drift",
      "syntax": "Report(metrics=[ColumnDriftMetric(column)])",
      "when_to_use": "Checking specific feature",
      "examples": ["report = Report([ColumnDriftMetric('age')]); report.run(ref, cur)"]
    }
  ],

  "error_patterns": [
    {
      "pattern": "Drift detected",
      "meaning": "Data distribution changed",
      "common_causes": ["Data source change", "Concept drift"],
      "fixes": ["Investigate cause", "Retrain model", "Update pipeline"]
    },
    {
      "pattern": "Test failed",
      "meaning": "Data quality test did not pass",
      "common_causes": ["Data quality issue", "Schema change"],
      "fixes": ["Fix data quality", "Adjust thresholds"]
    }
  ],

  "integration": {
    "dashprove_backend": true,
    "usl_property_types": ["data_quality"],
    "cli_command": "dashprove verify --backend evidently"
  },

  "performance": {
    "typical_runtime": "Seconds to minutes",
    "scalability": "Good for production data",
    "memory_usage": "Moderate"
  },

  "comparisons": {
    "similar_tools": ["deepchecks", "whylogs", "great_expectations"],
    "advantages": [
      "Beautiful interactive reports",
      "Good drift detection",
      "Easy to use",
      "Monitoring dashboard"
    ],
    "disadvantages": [
      "Less comprehensive than GE",
      "Newer project"
    ]
  },

  "metadata": {
    "version": "0.4.15",
    "last_updated": "2025-12-20",
    "maintainer": "Evidently AI",
    "license": "Apache-2.0"
  }
}
