{
  "id": "fairlearn",
  "name": "Fairlearn",
  "category": "ai_ml_fairness",
  "subcategory": "bias_mitigation",

  "description": "Assess and improve fairness of machine learning models",
  "long_description": "Fairlearn is a Python toolkit for assessing and improving the fairness of AI systems. It provides metrics to assess group fairness and algorithms to mitigate unfairness in classification and regression scenarios. Developed by Microsoft Research.",

  "capabilities": [
    "fairness_metrics",
    "bias_detection",
    "bias_mitigation",
    "threshold_optimization",
    "reductions",
    "postprocessing"
  ],
  "property_types": ["fairness", "disparity"],
  "input_languages": ["python"],
  "output_formats": ["metrics", "dashboard", "report"],

  "installation": {
    "methods": [
      {"type": "pip", "command": "pip install fairlearn"}
    ],
    "dependencies": ["scikit-learn", "pandas"],
    "platforms": ["linux", "macos", "windows"]
  },

  "documentation": {
    "official": "https://fairlearn.org/",
    "tutorial": "https://fairlearn.org/main/quickstart.html",
    "api_reference": "https://fairlearn.org/main/api_reference/",
    "examples": "https://fairlearn.org/main/auto_examples/"
  },

  "tactics": [
    {
      "name": "MetricFrame",
      "description": "Compute metrics by group",
      "syntax": "MetricFrame(metrics, y_true, y_pred, sensitive_features=sf)",
      "when_to_use": "To assess fairness across groups",
      "examples": ["mf = MetricFrame(metrics={'accuracy': accuracy_score}, y_true=y, y_pred=preds, sensitive_features=sf)"]
    },
    {
      "name": "ExponentiatedGradient",
      "description": "In-processing fairness constraint",
      "syntax": "ExponentiatedGradient(estimator, constraints)",
      "when_to_use": "To train fair model",
      "examples": ["mitigator = ExponentiatedGradient(LogisticRegression(), DemographicParity())"]
    },
    {
      "name": "ThresholdOptimizer",
      "description": "Post-processing threshold adjustment",
      "syntax": "ThresholdOptimizer(estimator, constraints)",
      "when_to_use": "To adjust existing model",
      "examples": ["postproc = ThresholdOptimizer(estimator=model, constraints='demographic_parity')"]
    },
    {
      "name": "demographic_parity_difference",
      "description": "Measure selection rate disparity",
      "syntax": "demographic_parity_difference(y_true, y_pred, sensitive_features=sf)",
      "when_to_use": "To measure demographic parity",
      "examples": ["dpd = demographic_parity_difference(y, preds, sensitive_features=sf)"]
    }
  ],

  "error_patterns": [
    {
      "pattern": "Infeasible constraints",
      "meaning": "Cannot satisfy fairness constraints",
      "common_causes": ["Too strict constraints", "Data limitation"],
      "fixes": ["Relax constraints", "Collect more balanced data"]
    },
    {
      "pattern": "Empty group",
      "meaning": "Sensitive group has no samples",
      "common_causes": ["Data sparsity"],
      "fixes": ["Combine groups", "Collect more data"]
    }
  ],

  "integration": {
    "dashprove_backend": true,
    "usl_property_types": ["fairness", "disparity"],
    "cli_command": "dashprove verify --backend fairlearn"
  },

  "performance": {
    "typical_runtime": "seconds to minutes",
    "scalability": "Handles typical ML datasets",
    "memory_usage": "Moderate"
  },

  "comparisons": {
    "similar_tools": ["aif360", "aequitas", "what-if-tool"],
    "advantages": [
      "Good scikit-learn integration",
      "Clear documentation",
      "Active development"
    ],
    "disadvantages": [
      "Focus on tabular data",
      "Limited deep learning support"
    ]
  },

  "metadata": {
    "version": "0.10.0",
    "last_updated": "2025-12-20",
    "maintainer": "Microsoft",
    "license": "MIT"
  }
}
