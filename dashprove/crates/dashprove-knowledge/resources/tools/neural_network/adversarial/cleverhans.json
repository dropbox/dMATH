{
  "id": "cleverhans",
  "name": "CleverHans",
  "category": "neural_network",
  "subcategory": "adversarial",

  "description": "Library for adversarial example generation and defense benchmarking",
  "long_description": "CleverHans is a Python library for constructing adversarial examples and evaluating machine learning models' vulnerability to adversarial attacks. Originally developed at Google Brain and OpenAI, it provides implementations of many attack methods including FGSM, PGD, C&W, and more.",

  "capabilities": [
    "fgsm_attack",
    "pgd_attack",
    "carlini_wagner_attack",
    "deepfool_attack",
    "elastic_net_attack",
    "model_evaluation",
    "defense_testing"
  ],
  "property_types": ["adversarial_robustness", "attack_success_rate"],
  "input_languages": ["tensorflow", "jax"],
  "output_formats": ["adversarial_examples", "attack_metrics"],

  "installation": {
    "methods": [
      {"type": "pip", "command": "pip install cleverhans"},
      {"type": "source", "url": "https://github.com/cleverhans-lab/cleverhans"}
    ],
    "dependencies": ["tensorflow", "numpy", "scipy"],
    "platforms": ["linux", "macos", "windows"]
  },

  "documentation": {
    "official": "https://github.com/cleverhans-lab/cleverhans",
    "tutorial": "https://github.com/cleverhans-lab/cleverhans/tree/master/tutorials",
    "api_reference": "https://cleverhans.readthedocs.io/",
    "examples": "https://github.com/cleverhans-lab/cleverhans/tree/master/examples"
  },

  "tactics": [
    {
      "name": "fgsm",
      "description": "Fast Gradient Sign Method attack",
      "syntax": "fast_gradient_method(model, x, eps, norm)",
      "when_to_use": "Quick untargeted adversarial examples",
      "examples": ["adv_x = fast_gradient_method(model, x, eps=0.3, norm=np.inf)"]
    },
    {
      "name": "pgd",
      "description": "Projected Gradient Descent attack",
      "syntax": "projected_gradient_descent(model, x, eps, eps_iter, nb_iter)",
      "when_to_use": "Strong iterative attack",
      "examples": ["adv_x = projected_gradient_descent(model, x, eps=0.3, eps_iter=0.01, nb_iter=40)"]
    },
    {
      "name": "cw",
      "description": "Carlini & Wagner L2 attack",
      "syntax": "carlini_wagner_l2(model, x, targeted, y_target)",
      "when_to_use": "Finding minimal perturbation",
      "examples": ["adv_x = carlini_wagner_l2(model, x, targeted=True, y_target=target)"]
    },
    {
      "name": "evaluate",
      "description": "Evaluate model robustness",
      "syntax": "evaluate(model, x_test, y_test, attack)",
      "when_to_use": "Benchmarking defense effectiveness",
      "examples": ["acc = evaluate_adversarial(model, test_data, attack=pgd)"]
    }
  ],

  "error_patterns": [
    {
      "pattern": "gradient is None",
      "meaning": "Cannot compute adversarial gradient",
      "common_causes": ["Non-differentiable operation", "Detached tensor"],
      "fixes": ["Ensure model is differentiable", "Check gradient tape"]
    },
    {
      "pattern": "attack failed",
      "meaning": "Could not find adversarial example",
      "common_causes": ["Robust model", "Too small epsilon"],
      "fixes": ["Increase epsilon", "Try stronger attack"]
    }
  ],

  "integration": {
    "dashprove_backend": true,
    "usl_property_types": ["adversarial_robustness"],
    "cli_command": "dashprove verify --backend cleverhans"
  },

  "performance": {
    "typical_runtime": "Milliseconds (FGSM) to seconds (C&W) per sample",
    "scalability": "Good for batch attacks",
    "memory_usage": "Moderate"
  },

  "comparisons": {
    "similar_tools": ["foolbox", "art", "advertorch"],
    "advantages": [
      "Historical significance (reference implementations)",
      "Well-tested implementations",
      "Good JAX support"
    ],
    "disadvantages": [
      "Less actively maintained",
      "Fewer attack types than ART"
    ]
  },

  "metadata": {
    "version": "4.0.0",
    "last_updated": "2025-12-20",
    "maintainer": "CleverHans Lab",
    "license": "MIT"
  }
}
